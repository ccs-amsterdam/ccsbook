\section{Authentication, cookies, and sessions}
\label{sec:authentication}

\subsection{Authentication and APIs}
\label{sec:authapi}
When we introduced APIs in \refsec{apis}, we used an example of an
API where you did not need to authenticate yourself. As we have seen,
using such an API is as simple as sending an HTTP request to an
endpoint and getting a response (usually, a JSON object) back. And
indeed, there are plenty of interesting APIs (think for instance of
open governemnt APIs) that work this way.

While this has obvious advantages for you, it also has some serious
dowmsides from the perspective of the API provider as well as from
a security and privacy standpoint. The more confidential the data is,
the more likely it is that the API provider needs to know who you
are in order to determine which data you are allowed to retrieve;
and even if the data are not confidential, authentication may be
used to limit the number of requests that an individual can make
in a given time frame.

In its most simple form, you just need to provide a unique key that
identifies you as a user. For instance, \refex{textrazor} shows how
such a key can be passed along as HTTP header, essentially as
additional information next to the URL that you want to retrieve (see
also \refsec{authweb}). The example shows a call to an endpoint
of a commercial API for natural language processing to inform how
many requests we have made today.

\pyrex[output=py,input=both, caption={Passing a key as HTTP request header to authenticate at an API endpoint}]{chapter13/textrazor}

As you see, using an API that requires authentication by passing a key
as a HTTP header is hardly more complicated than using APIs that do
not require authentication such as outlined in \refsec{apis}.
However, many APIs use more complex protocols for authentication.

The most popular one is called OAuth, and it is used by many APIs
provided by major players such as Google, Facebook, Twitter, Github,
LinkedIn, etc. Here, you have a client ID and a client secret
(sometimes also called consumer key and consumer secret) and an
access token with associated access token secret. The first pair
authenticates you as a user, the second pair authenticates the
specific ``app'' (i.e., your script). Once authenticated, your
script can then interact with the API. While it is possible to
directy work with OAuth HTTP requests using \pkg{requests\_oauthlib}
(Python) or \pkg{httr} (R), chances are relatively low that you
have to do so, unless you plan on really developing your own app
or even your own API: For all popular API's, so-called wrappers,
packages that provide a simpler interface to the API, are available
on pypi and CRAN. Still, all of these require to have at least
a consumer key and a consumer secret. The access token sometimes
is generated via a web interface where you manage your account
(e.g., in the case of Twitter), or can be aquired by your script
itself, which then will redirect the user to a website in which
they are asked to authenticate the app. The nice thing about this
is that it only needs to happen once: Once your app is authenticated,
it can keep making requests.




\subsection{Authentication and webpages}
\label{sec:authweb}
In this section, we briefly discuss different approaches for dealing
with websites where you need to log on, accept something (e.g., a
so-called cookie wall), or have to otherwise authenticate yourself.
One approach can be the use of a web testing framework like Selenium
(see \refsec{selenium}): You let your script literally open a browser
and, for instance, fill in your login information.

However, the sometimes, that's not necessary and we can still use simpler
and more efficent webscraping without invoking a browser. As we have already
seen in \refsec{parsehtml}, when making an HTTP request, we can transmit
additional information, such as the so-called user-agent string. In a
similar way, we can pass other information, such as cookies.

In the developer tools of your browser (which we already used to determine
XPATHs and CSS selectors), you can look up which cookies a specific website
has placed. For instance, you could inspect all cookies \emph{before} you
logged on (or passed a cookie wall) and again inspect them afterwards to
determine what has changed. With this kind of reverse-engeneering, you
can find out what cookies you need to manually set.

In \refex{cookiewall}, we illustrate this for a specific page (at the
time of writing of our book). Here, by inspecting the cookies in Firefox,
we found out that clicking ``Accept'' on the cookie wall landing page
caused a cookie with the name |cpc| and the value |10| to be set. We
therefore then proceeded as followed. Also, during the first visit,
a couple of other cookies seemed to be set, the functionality of which
we did not care. In \refex{cookiewall}, we therefore start a \emph{session}
and try to download the page. We know that this will only show us the
cookie wall -- but it will also generate the necessary cookies. We then
store these cookies, and add the cookie that we want to be set (|cpc=10|)
to this cookie jar. Now, we have all cookies that we need for future
requests. They will stay there for the whole session.

If we only want to get a single page, we may not need to start a session
to remeber the cookies and all, and we can just directly pass the single
cookie we care about to a request instead (\refex{cookiewall2}).




\pyrex[output=py,input=py, caption={Explicitly setting a cookie to circumvent a cookie wall}]{chapter13/cookiewall}
\pyrex[output=none,input=py, caption={Shorter version of \refex{cookiewall} for single requests}]{chapter13/cookiewall2}





