\section{Re-using code}
\label{sec:code}

Coding is like speaking a language. This means that you have a vocabulary, syntax rules, and expressions; and that you think of sentences, words and letters. Using the proper words and grammar, you can build from scratch any idea your background and imagination allow you, which is a wonderful thing. However, language it self, as well as expressions, ideas and more abstract constructs seldom come originally from you, which is also great because you do not have to deeply think of every element before talking and expressing any common or innovative thought. Instead, you use pre-existing rules, ideas, perceptions and many different narratives to create your own messages to interact with the world. It's the same with coding: You almost never start from scratch.

Of course you \emph{can} code anything you want from the very beginning, even just using 0's and 1's!
When reading through the previous chapters, maybe you even started to think that complex operations will be very exhausting and will take a really a long time. After all, from the basic operations we did to a useful statistical
model seems like a long way to go.

This fear is completely understandable, but it is far away from being realistic for most practitioners. Computational scientists, data analysts, and developers normally re-use earlier code in order to achieve their goals quicker and more efficiently. This practice has many advantages in terms of time and resources, because you will certainly spend less efforts to conduct a task if you use the work made by others and do not have to re-invent the wheel.


% I (Damian) changed this a bit; I just had a plagiarism case where someone literally copy pasted everything (!) from one single file on github and handed it in as an own assignment  ... :-(

%Differently to humanities and social sciences, in most of the computational routines this "copy-and-paste" practices do not represent an offence for intellectual property, but on the contrary, an extended practice of collaboration. It is also true that at certain levels you will come across the discussion between software property, technological patents or intellectual rights against the open-source model, but in general you will mostly find a collaboration and additive spirit when using coding for research.

Of course, you should give credit where credit is due, but it is not uncommon to paste code snippets from others into your own code and adapt them. This is especially true for standard operations, for which there are only so-many ways to do achieve the desired result.

There are different ways to re-use earlier code. One is to copy and adapt raw lines of code written by someone else or by yourself in the past. In fact, there many online repositories where you can find previous code, such as Github, BitBucket, GitLab, SourceForge, OSON or SubVersion, from where anyone can pull documented code examples (see \refsec{practices}). When conducting computational analysis you will spend a significant part of your time in some these repositories trying understand what others have done and figuring out how can use it your own work.

Another way is to build or import functions that summarizes many lines of code into a simpler command, as we explained in \refsec{functions}. The functions are indeed powerful strategies to re-use the code since you do not have to write over and over again complex lines of code that have to be used in different moments. Packages are probably the most elegant approach to recycle the work made by other colleagues. In \refsec{installing} you already learnt how to install a package and you did probably noticed how easy it is to bring many pre-build functionalities onto your workspace. You can also write and publish your own package in the future to help your colleagues to write less code and to be more efficient in their daily job (see also \refsec{publishingsource})!

%As you may imagine, in the above-mentioned repositories you will get not only raw code, but also scripts that include many functions, or even complete packages. This means that re-using code is not a linear or well-organized task. On the contrary, you will be back and forth looking for previous code and adapting yours iteratively.

A lot of questions can arise here: What to re-use? When to use a function written by someone else instead of writing the code yourself? Which scripts and sources are trustworthy? Which is the best package to choose? How many packages should we use within the same project? Should we care about package versions? And must we know every package that is released in our field? There are of course multiple answers to these questions and it will be probably a matter of practice how to obtain the most appropriate ones. In general, we can say that one premise is to re-use and share code as much as you can. This idea is limited by constraints of quality, availability, parsimony, update and expertise. In other words, when recycling code we should think of the reputation of the source, the difficulty to access it, the risk of having an excessive and messy number of inputs, the need to use the last developments with your colleagues and the fact that you will not be able to know-it-all.

Let's take an example. Imagine you want to compute the Levenshtein distance between two
strings. That's a pretty straightforward metric that answers the question: ``How many
edits (removing/changing/editing characters) do I need to transform string1 into string2?''.
It can be used for plagiarism detection, but may be interesting for us to determine, for instance,
whether a newspaper copied some content from somewhere else, even if small changes have been
applied. You could now try to write some code to calculate that (and we are sure you could
do that if you invested some time in it!), but it is such a common problem that it
has been solved multiple times before. You could, for instance,  look up some
functions that are known to solve the problem and copy-paste them into your code. You can find
a large number of different implementations for both Python and R here:
\url{https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein\_distance}.
You can then choose and copy-paste the one which one is most appropriate for you. One that is very fast, because
you want to compare a huge set of strings? One that is easy to understand? One that uses
only a few lines of code to not distract the reader?
Alternatively, if you look for available packages for Python and R, you see that there are
multiple packages that you can install with \fn{install.packages} (R) or \fn{pip} (Python)
and then import. If you go for that route, you don't need
to care about the internal workings and can ``abstract away'' and outsorce the problem -- on the other
hand, the users of your code now have one more dependency to install before they can
use your code.

In the case of package selection, you will probably feel that the decision-making process is challenging and that it is too risky to spend time selecting and learning a package that would later not be useful. And you are right to think so: even if you have to  \textit{flirt} with many libraries and even become a \textit{early adopter}, you will finally pay attention to what your community is using at the very moment in order to take a decision of to invest your time. 

Just to mention an example, the authors of this book had several intensive discussions of which packages to mention and use in the proposed exercises, an issue that became complex given the variety of topics addressed in the handbook. In the case of text analysis, a library such as \fn{NLTK} for Python was incredibly popular among computational analysts until few years ago becoming a package of reference in the field, but it has -- at least for some applications -- been overpassed by friendly and sophisticated new packages for natural language processing like \fn{SpaCy}. So, which should we have included in this book? The one which is well-known (with excellent documentation by the way) and still used by thousands of practitioners and students around the world?, or the one which is penetrating the market because of its easiness and advantages? Moreover, by choosing the second option, are we sure a more trendy package is going to be stable in time or is it going to be crossed out by a different one in just few months?  

There isn't the one golden way of how to re-use code and packages, but this dynamic scenario also depicts an exciting and provocative field that forces us to keep ourselves updated.
