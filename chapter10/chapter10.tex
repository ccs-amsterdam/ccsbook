\chapter{Processing text}
\label{chap:protext}


\begin{abstract}{Abstract}
Many data sets that are relevant for social science consist of textual data, from political discussions and newspaper archives to open-ended survey questions and reviews. This chapter gives an introduction in dealing with textual data using base R and Python, as well as packages such as \pkg{Quanteda} and \pkg{SpaCyr} in R, or \pkg{NLTK} and \pkg{SpaCy} in Python, and shows how to solve common problems encountered when reading and processing text. 
\end{abstract}

\keywords{Text representation, text cleaning, regular expressions}

\begin{objectives}
\item Understand how text is represented in the computer
\item Be able to clean up and alter text
\item Understand and be able to use regular expressions 
\end{objectives}


\newpage
\begin{feature}
  This chapter introduces the packages for handling textual data.
  For R, this is mainly the \pkg{stringr} package (included in \tidyverse).
  In python, most functions are built-in, but will show how to use these functions in \pkg{pandas} and also introduce the \pkg{regex} alternative to built-in regular expressions.
You can install these packages with the code below if needed  (see \refsec{installing} for more details):

\doublecodex{chapter10/chapter10install}

\noindent After installing, you need to import (activate) the packages every session:

\doublecodex{chapter10/chapter10library}

\end{feature}

\input{chapter10/readtext}

\input{chapter10/regular}



