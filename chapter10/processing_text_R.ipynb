{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10. Proccesing text\n",
    "## Notebook for R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Reading and cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "snippet:clean"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'&lt;p&gt;&lt;b&gt;Communication&lt;/b&gt; (from Latin &lt;i&gt;communicare&lt;/i&gt;, meaning to share)'"
      ],
      "text/latex": [
       "'<p><b>Communication</b> (from Latin <i>communicare</i>, meaning to share)'"
      ],
      "text/markdown": [
       "'&lt;p&gt;&lt;b&gt;Communication&lt;/b&gt; (from Latin &lt;i&gt;communicare&lt;/i&gt;, meaning to share)'"
      ],
      "text/plain": [
       "<p><b>Communication</b> (from Latin <i>communicare</i>, meaning to share)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'communication from latin communicare meaning to share'"
      ],
      "text/latex": [
       "'communication from latin communicare meaning to share'"
      ],
      "text/markdown": [
       "'communication from latin communicare meaning to share'"
      ],
      "text/plain": [
       "communication from latin communicare meaning to share"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(glue)\n",
    "library(magrittr)\n",
    "my_wiki_text = \"<p><b>Communication</b> (from Latin <i>communicare</i>, meaning to share)\"\n",
    "glue(my_wiki_text)\n",
    "\n",
    "my_wiki_text %<>% gsub(\"<p>\", \" \", .) %>% gsub(\"<b>\", \" \", .) %>% gsub(\"</b>\", \" \", .) %>% gsub(\"<i>\", \" \", .) %>% gsub(\"</i>\", \" \", .) \n",
    "my_wiki_text_2 = gsub('[[:punct:]]','',my_wiki_text) #Remove punctuation\n",
    "my_wiki_text_2 = tolower(my_wiki_text_2) #Convert to lower case\n",
    "my_wiki_text_2 = trimws(gsub(\"\\\\s+\", \" \", my_wiki_text_2)) #Remove double spaces \n",
    "glue(my_wiki_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "snippet:cleanextra"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Communication  (from Latin  communicare , meaning to share)'</span>"
      ],
      "text/latex": [
       "'Communication  (from Latin  communicare , meaning to share)'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Communication  (from Latin  communicare , meaning to share)'</span>"
      ],
      "text/plain": [
       "Communication  (from Latin  communicare , meaning to share)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(stringi)\n",
    "my_wiki_text_3 = stri_replace_all(my_wiki_text, \"\", regex = \"<.+?>\")\n",
    "my_wiki_text_3 = stri_trim(my_wiki_text_3)\n",
    "glue(my_wiki_text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "snippet:regex"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'  Communication  (from Latin  communicare , meaning to share)'</span>"
      ],
      "text/latex": [
       "'  Communication  (from Latin  communicare , meaning to share)'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'  Communication  (from Latin  communicare , meaning to share)'</span>"
      ],
      "text/plain": [
       "  Communication  (from Latin  communicare , meaning to share)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_wiki_text_4 = gsub(pattern = \"<.*?>\", replacement = \"\", x = my_wiki_text)\n",
    "glue(my_wiki_text_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "snippet:regex2"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'&lt;@born_in_america: My second favorite color is green, I must acknowlege my friends for that!&gt;, &lt;@born_in_britain: My second favourite colour is red, I must aknowledge my friends for that!&gt;'"
      ],
      "text/latex": [
       "'<@born\\_in\\_america: My second favorite color is green, I must acknowlege my friends for that!>, <@born\\_in\\_britain: My second favourite colour is red, I must aknowledge my friends for that!>'"
      ],
      "text/markdown": [
       "'&lt;@born_in_america: My second favorite color is green, I must acknowlege my friends for that!&gt;, &lt;@born_in_britain: My second favourite colour is red, I must aknowledge my friends for that!&gt;'"
      ],
      "text/plain": [
       "<@born_in_america: My second favorite color is green, I must acknowlege my friends for that!>, <@born_in_britain: My second favourite colour is red, I must aknowledge my friends for that!>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'&lt;@born_in_america: My second favorite color is green, I must acknowledge my friends for that!&gt;, &lt;@born_in_britain: My second favorite color is red, I must acknowledge my friends for that!&gt;'"
      ],
      "text/latex": [
       "'<@born\\_in\\_america: My second favorite color is green, I must acknowledge my friends for that!>, <@born\\_in\\_britain: My second favorite color is red, I must acknowledge my friends for that!>'"
      ],
      "text/markdown": [
       "'&lt;@born_in_america: My second favorite color is green, I must acknowledge my friends for that!&gt;, &lt;@born_in_britain: My second favorite color is red, I must acknowledge my friends for that!&gt;'"
      ],
      "text/plain": [
       "<@born_in_america: My second favorite color is green, I must acknowledge my friends for that!>, <@born_in_britain: My second favorite color is red, I must acknowledge my friends for that!>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets = \"<@born_in_america: My second favorite color is green, I must acknowlege my friends for that!>, <@born_in_britain: My second favourite colour is red, I must aknowledge my friends for that!>\"\n",
    "tweets_unified = gsub(pattern = \"acknowlege|aknowledge\" , replacement = \"acknowledge\", x = tweets)\n",
    "tweets_unified = gsub(pattern = \"col.+?r\", replacement = \"color\", x = tweets_unified)\n",
    "tweets_unified = gsub(pattern = \"fav.+?rite\" , replacement = \"favorite\", x = tweets_unified)\n",
    "glue(tweets)\n",
    "glue(tweets_unified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "snippet:regex3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"@born_in_america\" \"@born_in_britain\"\n"
     ]
    }
   ],
   "source": [
    "users = unlist(strsplit(tweets, \" \"))\n",
    "users = gsub(\"[^[:alnum:]@_]\", \"\", users[grep(\"(^|[^@\\\\w])@(\\\\w{1,15})\\\\b\", users)])\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": [
     "snippet:tokens"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens from 1 document.\n",
      "text1 :\n",
      " [1] \"<\"                \"@born_in_america\" \":\"                \"My\"              \n",
      " [5] \"second\"           \"favorite\"         \"color\"            \"is\"              \n",
      " [9] \"green\"            \",\"                \"I\"                \"must\"            \n",
      "[13] \"acknowlege\"       \"my\"               \"friends\"          \"for\"             \n",
      "[17] \"that\"             \"!\"                \">\"                \",\"               \n",
      "[21] \"<\"                \"@born_in_britain\" \":\"                \"My\"              \n",
      "[25] \"second\"           \"favourite\"        \"colour\"           \"is\"              \n",
      "[29] \"red\"              \",\"                \"I\"                \"must\"            \n",
      "[33] \"aknowledge\"       \"my\"               \"friends\"          \"for\"             \n",
      "[37] \"that\"             \"!\"                \">\"               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'c(text1 = 39)'"
      ],
      "text/latex": [
       "'c(text1 = 39)'"
      ],
      "text/markdown": [
       "'c(text1 = 39)'"
      ],
      "text/plain": [
       "c(text1 = 39)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens from 1 document.\n",
      "text1 :\n",
      " [1] \"@born_in_america\" \"second\"           \"favorite\"         \"color\"           \n",
      " [5] \"green\"            \"must\"             \"acknowlege\"       \"friends\"         \n",
      " [9] \"@born_in_britain\" \"second\"           \"favourite\"        \"colour\"          \n",
      "[13] \"red\"              \"must\"             \"aknowledge\"       \"friends\"         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'c(text1 = 16)'"
      ],
      "text/latex": [
       "'c(text1 = 16)'"
      ],
      "text/markdown": [
       "'c(text1 = 16)'"
      ],
      "text/plain": [
       "c(text1 = 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(quanteda)\n",
    "tokens = tokens(tweets)\n",
    "print(tokens)\n",
    "glue(ntoken(tweets))\n",
    "\n",
    "filtered_tokens = tokens_remove(tokens(tweets, remove_punct = TRUE), stopwords(\"english\"))\n",
    "print(filtered_tokens)\n",
    "glue(ntoken(filtered_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": [
     "snippet:stem"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens from 1 document.\n",
       "text1 :\n",
       "[1] \"Build\"  \"Build\"  \"awesom\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_wordstem(tokens(\"Buildings Builds awesome\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": [
     "snippet:nlp"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy is already initialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in spacy_parse.character(tweets):\n",
      "“lemmatization may not work properly in model 'en_core_web_sm'”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'Number of tokens: 39'"
      ],
      "text/latex": [
       "'Number of tokens: 39'"
      ],
      "text/markdown": [
       "'Number of tokens: 39'"
      ],
      "text/plain": [
       "Number of tokens: 39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(spacyr)\n",
    "spacy_initialize( model = \"en_core_web_sm\", python_executable = NULL, virtualenv = NULL,\n",
    "condaenv = NULL, ask = FALSE, refresh_settings = FALSE, save_profile = FALSE, check_env = TRUE, entity = TRUE)\n",
    "doc = spacy_parse(tweets)\n",
    "glue(\"Number of tokens: \", nrow(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": [
     "snippet:poslemma"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  token lemma pos\n",
      "8    is    be AUX\n",
      "     token  lemma  pos\n",
      "15 friends friend NOUN\n"
     ]
    }
   ],
   "source": [
    "print(doc[8,4:6])\n",
    "print(doc[15,4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "tags": [
     "snippet:nounchunks"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Number of noun chunks: 7'"
      ],
      "text/latex": [
       "'Number of noun chunks: 7'"
      ],
      "text/markdown": [
       "'Number of noun chunks: 7'"
      ],
      "text/plain": [
       "Number of noun chunks: 7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Noun chunk 4: my friends'"
      ],
      "text/latex": [
       "'Noun chunk 4: my friends'"
      ],
      "text/markdown": [
       "'Noun chunk 4: my friends'"
      ],
      "text/plain": [
       "Noun chunk 4: my friends"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noun_chunks = spacy_extract_nounphrases(tweets)\n",
    "glue(\"Number of noun chunks: \", nrow(noun_chunks))\n",
    "glue(\"Noun chunk 4: \", noun_chunks[4, \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "tags": [
     "snippet:dependency"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in spacy_parse.character(\"My second favorite color is green\", dependency = TRUE):\n",
      "“lemmatization may not work properly in model 'en_core_web_sm'”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     token dep_rel\n",
      "1       My    poss\n",
      "2   second    amod\n",
      "3 favorite    amod\n",
      "4    color   nsubj\n",
      "5       is    ROOT\n",
      "6    green   acomp\n"
     ]
    }
   ],
   "source": [
    "docp = spacy_parse(\"My second favorite color is green\", dependency = TRUE)\n",
    "print(select(docp,token,dep_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "tags": [
     "snippet:ner"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in spacy_parse.character(\"Madrid will host Olympic Games in 2032, Pedro Sanchez announced\"):\n",
      "“lemmatization may not work properly in model 'en_core_web_sm'”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  doc_id sentence_id        entity entity_type\n",
      "1  text1           1        Madrid         GPE\n",
      "2  text1           1 Olympic_Games         ORG\n",
      "3  text1           1          2032        DATE\n",
      "4  text1           1 Pedro_Sanchez      PERSON\n"
     ]
    }
   ],
   "source": [
    "headline= spacy_parse(\"Madrid will host Olympic Games in 2032, Pedro Sanchez announced\")\n",
    "print(entity_extract(headline, type = \"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
