\section{Regular expressions}
\label{sec:regular}

A \concept{regular expression} or \emph{regex} is a powerful language to locate strings that conform a given pattern. For instance, we can extract usernames or email-addresses from text, or normalize spelling variations and improve the cleaning methods covered in the previous section. Specifically, regular expressions are a sequence of characters that we can use to design a pattern and then use this pattern to \emph{find} strings (identify or extract) and also \emph{replace} those strings by new ones. 

Regular expressions look complicated, and in fact they take some getting used to initially.
For example, a relatively simple (and not quite correct) expression to match an email address is \verb|[\w\.-]+@[\w\.-]+\.\w\w+|,
which doesn't look like anything at all unless you know what you are looking for.
The good news is that regular express syntax is the same in R and Python (and many other languages),
so once you learn regular expressions you will have acquried a powerful and versatile tool for text processing. 

%We will show how you can use regexes to preprocess text. The good thing is that regular expression syntax can be similar in R and Python and once you learn how to write a pattern in one language it is easy to do the same in the other.  However they are not identical! Even it is out of the scope of this book, you can trace the specific standards of each language and its different versions. You will come across with some standards of the Portable Operating System Interface (POSIX), such as the Basic Regular Expressions (BRE) or Extended Regular Expressions (ERE), or also with the Perl Compatible Regular Expressions (PCRE).  By default the R function \fn{grep} uses ERE but you can set a parameter (\verb|perl = TRUE|) to work with PCRE, and in the case of Python \fn{re} module regexes match operations similar to PCRE as a default.

%% \note{\textbf{Python: re versus regex}
%%   In python, people generally use the \pkg{re} package for regular expressions.
%%   In this book we will use the \pkg{regex} package, however.
%%   This modules has the same functions and arguments as the \pkg{re} module,
%%   but it has better support for unicode, which is very important when dealing with non-western text.
%%   However, for almost all examples you can also use the \pkg{re} module if prefered.
%%   }

In the next section, we will first review general expression syntax without reference to running them in Python or R.
Subsequently, you will see how you can apply these expression to inspect and clean texts in both languages.

\subsection{Regular expression syntax}

At its core, regular expressions are patters for matching sequences of characters.
In the simplest case, a regular letter just matches that letter, so the pattern `cat' matches the text `cat'.
Next, there are various wildcards, or ways to match different letters.
For example, the period (\verb|.|) matches any character, so \verb|c.t| matches both `cat' and `cot'.
You can place mulitple letters between square brackets to create a \concept{character class} that matches all the specified letters, so \verb|c[au]t| matches `cat' and `cut', but not `cot'.
There are also a number of pre-defined classes, such as \verb|\w| which matches `word characters' (letters, digits, and (curiously) underscores).

Finally, for each character or group of characters you can specify how often it should occur.
For example, \verb|a+| means one or more a's while \verb|a?| means zero or one a, so \verb|lo+l| matches `lol', `lool', etc.,
and \verb|lo?l| matches `lol' or `ll'.
This raises the question, of course, of how to look for actual occurrences of a plus, question mark, or period.
The solution is to \concept{escape} these special symbols by placing a backslash (\verb|\|) before them:
\verb|a\+| matches the literal text `a+', and \verb|\\w| (with a double backslash) matches the literal text `\textbackslash w'. 

Now, we can have another look at the example emails address pattern given above.
The first part, \verb|[\w\.-]| creates a character class containing word characters, (literal) periods, and dashes.
Thus, \verb|[\w\.-]+@[\w\.-]+| means one or more letters, digits, underscores, periods, or dashes, followed by an at sign,
followed by one or more letters, digits, etc.
Finally, the last part \verb|\.\w\w+| means a literal period, a word character, and one or more word characters.
In other words, we are looking for a name (possibly contining dashes or periods) before the at sign,
followed by a domain, followed by a top level domain (like \verb|.com|) of at least two characters.

In essence, thinking in terms of what you want to match and how often
you want to match it is all there is to regular expressions.
However, it will take some practice to get comfortable with turning something sensible (such as an email address) into a correct regular expression pattern.
The next subsection will explain regular expression syntax in more detail, followed by an explanation of grouping,
and in the final subsection we will see how to use these regular expressions in R and Python to do text cleaning. 

\newcommand{\fnregexnote}{\footnote{Note that this is not a full review of everything that is possible with regular expressions, but this includes the most used options and should be enough for the majority of cases. Moreover, if you descend into the more specialized aspects of regular expressions (with beautiful names such as `negative lookbehind assertions') you will also run into differences between Python, R, and other languages, while the features used in this chapter should function in most implementations you come across unless specifically noted.}}



\input{chapter10/tabregex}

In \reftab{regex} you will find an overview of the most important parts of regular expression syntax.\fnregexnote
The first part shows a number of common specifiers for determining what to match, e.g. letters, digits, etc.,
followed by the quantifiers available to determine how often something should be matched.
These quantifiers always follow a specifier, i.e. you first say what you're looking for, and then how many of those you need.
Note that by default quantifiers are greedy, meaning they match as many characters as possible.
For example, \verb|<.*>| will match everything between angle brackets, but if you have something like `<p>a paragraph</p>'
it will happily match everything from the first opening bracket to the last closing bracket.
By appending a question mark (\verb|?|) to the quantifier, it becomes non-greedy.
so, \verb|<.*?>| will match the individual `<p>' and `</p>' substrings. 

The third section discusses other constructs.
\concept[Capture Groups]{Groups} are formed using parentheses \verb|()| and are useful in at least three ways. 
First, by default a quantifier applies to the letter directly before it, so \verb|no+| matches `no', `nooo', etc.
If you group a number of characters you can apply a quantifier to the group. So, \verb|that's (not)? good| matches either `that's not good' or `that's good'.
Second, when using a vertical bar (\textbar) to have multiple options, you very often want to put them into a group so you can use it as part of a larger pattern.
For example, \verb!a (great|fantastic)? victory! matches either `a victory', `a great victory', or `a fantastic victory'.
Third, as will be discussed below in \refsec{regextract}, you can use groups to capture (extract) a specific part of a string, e.g. to get only the domain part of a web address. 

The other important construct are \concept{character classes}, formed using square brackets \verb|[]|.
Within a character class, you can specify a number of different characters that you want to match, using a dash (\verb|-|) to indicate a range.
You can add as many characters as you want: \verb|[A-F0-9]| matches digits and capital letters A through F.
You can also invert this selection using an initial caret: \verb|[^a-z]| matches everything except for lowercase Latin letters.
Finally, you sometimes need to match a control character  (e.g. \verb!+!, \verb|?|, \verb|\|). Since those characters have a special meaning within a regular expressing, they cannot be used directly. The solution is to add a backslash (\verb|\|) behind them to \concept{escape} them:
\verb|.| matches any character, but \verb|\.| matches an actual period. \verb|\\| matches an actual backslash.

\subsection{Example patterns}

Using the syntax explained in the previous section, we can now make patterns for common tasks in cleaning and analysing text.
\reftab{regexample} list a number of regular expressions for common tasks such as finding dates or stripping HTML artefacts.

\input{chapter10/tabregexample}

We start with a number of relatively simple patterns for Zip codes and phone numbers.
Starting with the simplest example, US Zip codes are simply five consecutive numbers.
Next, a US phone number can be written down as three groups of numbers separated by parentheses,
where the first group is made optional for local phone numbers using parentheses to group these numbers so the question mark applies to the whole group. 
Next, Dutch postal codes are simply 4 numbers followed by 2 letters, and we allow an optional space in between.
Similarly simple, dates in ISO format are 3 groups of numbers separated by dashes.
German dates follow a different order, use periods as separator, and allow for single-digit day and month numbers.
Note that these patterns do not check for the validity of dates.
A simple addition would be to restrict months to 01-12, e.g. using \verb!(0[1-9]|1[0-2])!.
However, in general validation is better left to specialized libraries, as properly validitaing the day number would require taking the month (and leap years) into account. 

A slightly more complicated pattern is the one given for international phone numbers.
They always start with a plus sign and contain at least 8 numbers, but can contain dashes and spaces depending on the country.
So, after the literal \verb|+| (which we need to escape since \verb|+| is a control character),
we look for 7 or more numbers, optionally followed by a single dash or space, and end with a single number.
This allows dashes and spaces at any position except the start and end, but does not allow for e.g. double dashes.
It also makes sure that there are at least 8 numbers regardless of how many dashses or spaces there are.

The final four examples are patters for common notations found online.  
For URLs, we look for \ttt{http://} or \ttt{https://} and take everything until the next space or end of the string.
For email addresses, we define a character class for letters, periods, or dashes and look for it before and after the at-sign.
Then, there needs to be at least one period and a top level domain containing only letters.
Note that the dash within the character class does not need to be escaped because it is the final character in the class, so it cannot form a range.
For HTML tags and character escapes, we anchor the start (\verb|<| and \verb|&|) and end (\verb|>| and \verb|;|) and allow any characters except for the ending character in between
using an inverted character class.

Note that these example patterns would also match if the text is enclosed in a larger text.
For example, the zip code pattern would happily match the first 5 numbers of a 10-digit number.
If you want to check that an input value is a valid zip code (or email address, etc.),
you probably want to check that it only contains that code by surrounding it with start-of-text and end-of-text markers: \verb|^\d{5}$|.
If you want to extract e.g. zip codes from a longer document, it is often useful to surround them with word boundary markers: \verb|\b\d{5}\b|.

Please note that many of those patterns are not necessarily fully complete and correct, especially the final patterns for online notations.
For example, email addresses can contain plus signs in the first part, but not in the domain name, while domain names are not allowed to start with a dash -- a completely correct regular expression to match email addresses is over 400 characters long!
Even worse, a complete HTML tag expression is probably not even possible because as a regular expression as they can contain comments and nested escapes within attributes.
For a better way to deal with analysing HTML, please see \refchap{scraping}. In the end, patterns like these are fine for a (somewhat) noisy analysis of (often also somewhat noisy) source texts as long as you understand the limitations. 
        
\section{Using regular expressions in Python and R}

Now that you hopefully have a firm grasp of regular expression syntax,
it is relatively easy to use these patterns in Python or R (or most other languages).
\reftab{regexample} lists the commands for four of the most common use cases:
identifying matching texts, removing and replacing all matching text, extracting matched groups, and splitting texts.

\input{chapter10/tabregexcmd}

For R, we again use the functions from the \pkg{stringr} package.
For Python, you can use either the \pkg{re} or \pkg{regex} package,
which both support the same functions and syntax so you can just import one or the other.
The \pkg{re} package is more common, but does not support unicode character properties (\verb!\p!).
We also list the corresponding commands for \pandas, which are run on a whole column instead of a single text 
(but note that \pandas\ does not support unicode character properties.)

Finally, a small but important note about \concept{escaping} special characters by placing a backslash (\verb|\|) before them.
The regular expression patterns are used \emph{within} another language (in this case, Python or R), but these languages have their own
special characters which are also escaped. In Python, you can create a \concept{raw string} by putting a single \verb|r| before the opening quotation mark:
\verb|r"\d+"| creates the regular expression pattern \verb|\d|.
From version 4.0 (released in spring 2020), R has a similar construct: \verb|r"(\d+)"|. In R, the parentheses are part of the string delimiters, but you can use more parentheses within the string without a problem.
The only think you cannot include in a string is the closing sequence \verb|)"|, but as you are also allowed to use square or curly brackets instead of parentheses and single instead of double quotes to delimit the raw string you can generally avoid this problem:
to create the pattern \verb!"(cat|dog)"! (i.e. cat or dog enclosed in quotation marks), you can use \verb!r"{"(cat|dog)"}"! or \verb!r'("(cat|dog)")'! (or even more legible: \verb!r'{"(cat|dog)"}'!). 

Unfortunately, in earlier versions of R (and in any case if you don't use raw strings), you need to escape special characters twice:
first for the regular expression, and then for R. So, the pattern \verb|\d| becomes \verb|"\\d+"|. To match a literal backslash you would use the pattern \verb|\\|,
which would then be represented in R as \verb|"\\\\"|!

\refex{clean} uses regular expressions to clean a single text, by removing HTML tags and punctuation,
normalizing whitespace, and also uses string commands for converting to lower case and trimming leading and trailing spaces.

\pyrex[caption=Using regular expressions to clean a text]{chapter10/clean}

Finally, \refex{cleanpandas} shows how you can run the various commands on a whole column of text rather than on individual strings,
using  a small set of made-up tweets to showcase various operations.
First, we determine whether a pattern occurs, in this case for detecting hash-tags
This is very useful for e.g. subsetting a data frame to only rows that contain this pattern.
Next, we count how many at-mentions are contained in the text, where we require that the character before the mention needs to be either whitespace or the start of the string (\verb|^|), to exclude email addresses and other non-mentions that do contain at signs.
Then, we extract the (first) url found in the text, if any, using the pattern discussed above.
Finally, we extract the plain text of the tweet in two chained operations:
First, we remove every word starting with an at-sign, hash, or http, removing everything up to the next whitespace character.
Then, we replace everything that is not a letter by a single space. 


\pyrex[output=r,format=table,caption=Using regular expressions on a data frame]{chapter10/cleanpandas}

\subsection{Splitting and Joining strings, and extracting multiple matches}

So far, the operations we used all took a single string object and returned a single value,
either a cleaned version of the string or e.g. a boolean indicating whether there is a match.
This is convenient when using data frames, as you can transform a single column into another column.
There are three common operations, however, that complicate matters:
You can \emph{split} a string into multiple substrings, or \emph{extract} multiple matches from a string,
and you can \emph{join} multiple matches together.

\pyrex[caption=Splitting\, extracting\, and joining a single text]{chapter10/split}

\refex{split} shows the 'easier' case of splitting up a single text and joining the result back together.
We show three different ways to split: using a fixed pattern to split on (in this case, a comma plus space);
using a regular expression (in this case, any punctuation followed by any space);
and by matching the items we are interested in (letters) rather than the separator.
Finally, we join these items together again using \fn{join} (Python) and \fn{str\_c} (R).

One thing to note in the previous example is the use of the index \verb|[[1]]| to select the first element in a list.
This is needed because in R, splitting a text actually splits all the given texts, returning a \cls{list} containing all the matches for each input text.
If there is only a single input text, it still returns a list, so we select the first element of the list.

In many cases, however, you are not working on a single text but rather on a series of texts loaded into a data frame,
from tweets to news aritcles and open survey questions.
In the example above, we extracted only the first url from each tweet.
If we would want to extract e.g. all hash tags from each tweet, we cannot simply add a `tags' column,
as there can be multiple tags in each tweet.
Essentially, the problem is that the urls per tweet are now nested in each row,
creating a non-rectangular data structure.

Although there are multiple ways of dealing with this,
if you are working with data frames our advice is to normalize the data structure to a long format.
In the example, that would mean that each tweet is now represented by multiple rows,
namely one for each hash tag.
\refex{splitlong} shows how this can be achieved in both R and pandas. 
One thing to note is that in pandas,
\verb!t.str.extractall! automatically returns the desired long format,
but it is essential that the index of the data frame actually contains the identifier (in this case, the tweet (status) id).
\verb!t.str.split!, however, returns a data frame with a column containing lists,
similar to how both R functions return a list containing character vectors.
We can normalize this to a long data frame using \fn{t.explode} (pandas) and \fn{pivot\_longer} (R).
After this, we can use all regular data frame operations, for example to join and summarize the data.

A final thing to note is that in while you normally use a function like \fn{mean} to summarize the values in a group,
you can also join strings together as a summarization.
The only requirement for a summarization function is that it returns a single value for a group of values,
which of course is exactly what joining a mulitple string together does.
This is shown in the final line of the example, where we split a tweet into words and then reconstruct the tweet from the individual words.




\begin{ccsexample}
\doublecodex{chapter10/splitlong1}
\codexoutputtable{chapter10/splitlong1.r}
\doublecodex{chapter10/splitlong2}
\codexoutputtable{chapter10/splitlong2.r}
\doublecodex{chapter10/splitlong3}
\codexoutputtable{chapter10/splitlong3.r}
  \caption{Applying split and extract\_all on text columns'}\label{ex:splitlong}
\end{ccsexample}
