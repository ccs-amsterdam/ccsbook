\section{Regular expressions}
\label{sec:regular}

A \concept{regular expression} or \emph{regex} is a powerful language to locate strings that conform a given pattern. For instance, we can extract usernames or email-addresses from text, or normalize spelling variations and improve the cleaning methods covered in the previous section. Specifically, regular expressions are a sequence of characters that we can use to design a pattern and then use this pattern to \emph{find} strings (identify or extract) and also \emph{replace} those strings by new ones. 

Regular expressions look complicated, and in fact they take some getting used to initially.
For example, a relatively simple (and not quite correct) expression to match an email address is \verb|[\w\.-]+@[\w\.-]+\.\w\w+|,
which doesn't look like anything at all unless you know what you are looking for.
The good news is that regular express syntax is the same in R and Python (and many other languages),
so once you learn regular expressions you will have acquried a powerful and versatile tool for text processing. 

%We will show how you can use regexes to preprocess text. The good thing is that regular expression syntax can be similar in R and Python and once you learn how to write a pattern in one language it is easy to do the same in the other.  However they are not identical! Even it is out of the scope of this book, you can trace the specific standards of each language and its different versions. You will come across with some standards of the Portable Operating System Interface (POSIX), such as the Basic Regular Expressions (BRE) or Extended Regular Expressions (ERE), or also with the Perl Compatible Regular Expressions (PCRE).  By default the R function \fn{grep} uses ERE but you can set a parameter (\verb|perl = TRUE|) to work with PCRE, and in the case of Python \fn{re} module regexes match operations similar to PCRE as a default.

%% \note{\textbf{Python: re versus regex}
%%   In python, people generally use the \pkg{re} package for regular expressions.
%%   In this book we will use the \pkg{regex} package, however.
%%   This modules has the same functions and arguments as the \pkg{re} module,
%%   but it has better support for unicode, which is very important when dealing with non-western text.
%%   However, for almost all examples you can also use the \pkg{re} module if prefered.
%%   }

In the next section, we will first review general expression syntax without reference to running them in Python or R.
Subsequently, you will see how you can apply these expression to inspect and clean texts in both languages.

\subsection{Regular expression syntax}

At its core, regular expressions are patters for matching sequences of characters.
In the simplest case, a regular letter just matches that letter, so the pattern `cat' matches the text `cat'.
Next, there are various wildcards, or ways to match different letters.
For example, the period (\verb|.|) matches any character, so \verb|c.t| matches both `cat' and `cot'.
You can place mulitple letters between square brackets to create a \concept{character class} that matches all the specified letters, so \verb|c[au]t| matches `cat' and `cut', but not `cot'.
There are also a number of pre-defined classes, such as \verb|\w| which matches `word characters' (letters, digits, and (curiously) underscores).

Finally, for each character or group of characters you can specify how often it should occur.
For example, \verb|a+| means one or more a's while \verb|a?| means zero or one a, so \verb|lo+l| matches `lol', `lool', etc.,
and \verb|lo?l| matches `lol' or `ll'.
This raises the question, of course, of how to look for actual occurrences of a plus, question mark, or period.
The solution is to \concept{escape} these special symbols by placing a backslash (\verb|\|) before them:
\verb|a\+| matches the literal text `a+', and \verb|\\w| (with a double backslash) matches the literal text `\textbackslash w'. 

Now, we can have another look at the example emails address pattern given above.
The first part, \verb|[\w\.-]| creates a character class containing word characters, (literal) periods, and dashes.
Thus, \verb|[\w\.-]+@[\w\.-]+| means one or more letters, digits, underscores, periods, or dashes, followed by an at sign,
followed by one or more letters, digits, etc.
Finally, the last part \verb|\.\w\w+| means a literal period, a word character, and one or more word characters.
In other words, we are looking for a name (possibly contining dashes or periods) before the at sign,
followed by a domain, followed by a top level domain (like \verb|.com|) of at least two characters.

In essence, thinking in terms of what do you want to match and how often do you want to match that is all there is to regular expressions.
However, it will take some practice to get comfortable with turning something sensible (such as an email address) into a correct regular expression pattern.
The next subsection will explain regular expression syntax in more detail, followed by an explanation of grouping,
and in the final subsection we will see how to use these regular expressions in R and Python to do text cleaning. 

\newcommand{\fnregexnote}{\footnote{Note that this is not a full review of everything that is possible with regular expressions, but this includes the most used options and should be enough for the majority of cases. Moreover, if you descend into the more specialized aspects of regular expressions (with beautiful names such as `negative lookbehind assertions') you will also run into differences between Python, R, and other languages, while the features used in this chapter should function in most implementations you come across unless specifically noted.}}



\input{chapter10/tabregex}

In \reftab{regex} you will find an overview of the most important parts of regular expression syntax.\fnregexnote
The first part shows a number of common specifiers for determining what to match, e.g. letters, digits, etc.,
followed by the quantifiers available to determine how often something should be matched.
These quantifiers always follow a specifier, i.e. you first say what you're looking for, and then how many of those you need.
Note that by default quantifiers are greedy, meaning they match as many characters as possible.
For example, \verb|<.*>| will match everything between angle brackets, but if you have something like `<p>a paragraph</p>'
it will happily match everything from the first opening bracket to the last closing bracket.
By appending a question mark (\verb|?|) to the quantifier, it becomes non-greedy.
so, \verb|<.*?>| will match the individual `<p>' and `</p>' substrings. 

The third section discusses other constructs.
\concept[Capture Groups]{Groups} are formed using parentheses \verb|()| and are useful in at least three ways. 
First, by default a quantifier applies to the letter directly before it, so \verb|no+| matches `no', `nooo', etc.
If you group a number of characters you can apply a quantifier to the group. So, \verb|that's (not)? good| matches either `that's not good' or `that's good'.
Second, when using a vertical bar (\textbar) to have multiple options, you very often want to put them into a group so you can use it as part of a larger pattern.
For example, \verb!a (great|fantastic)? victory! matches either `a victory', `a great victory', or `a fantastic victory'.
Third, as will be discussed below in \refsec{regextract}, you can use groups to capture (extract) a specific part of a string, e.g. to get only the domain part of a web address. 

The other important construct are \concept{character classes}, formed using square brackets \verb|[]|.
Within a character class, you can specify a number of different characters that you want to match, using a dash (\verb|-|) to indicate a range.
You can add as many characters as you want: \verb|[A-F0-9]| matches digits and capital letters A though F.
You can also invert this selection using an initial caret: \verb|[^a-z]| matches everything except for lowercase lating letters.
Finally, you sometimes need to match a control character  (e.g. \verb!+!, \verb|?|, \verb|\|). Since those characters have a special meaning within a regular expressing, they cannot be use directly. The solution is to add a backslash (\verb|\|) behind them to \concept{escape} them:
\verb|.| matches any character, but \verb|\.| matches an actual period. \verb|\\| matches an actual backslash.

\subsection{Example patterns}

Using the syntax explained in the previous section, we can now make patterns for common tasks in cleaning and analysing text.
\reftab{regexample} list a number of regular expressions for common tasks such as finding dates or stripping HTML artefacts.

\input{chapter10/tabregexample}

We start with a number of relatively simple patterns for Zip codes and phone numbers.
Starting with the simplest example, US Zip codes are simply five consecutive numbers.
Next, a US phone number can be written down as three groups of numbers separated by parentheses,
where the first group is made optional for local phone numbers using parentheses to group these numbers so the question mark applies to the whole group. 
Next, Dutch postal codes are simply 4 numbers followed by 2 letters, and we allow an optional space in between.
Similarly simple, dates in ISO format are 3 groups of numbers separated by dashes.
German dates follow a different order, use periods as separator, and allow for single-digit day and month numbers.
Note that these patterns do not check for the validity of dates.
A simple addition would be to restrict months to 01-12, e.g. using \verb!(0[1-9]|1[0-2])!.
However, in general validation is better left to specialized libraries, as properly validitaing the day number would require taking the month (and leap years) into account. 

A slightly more complicated pattern is the one given for international phone numbers.
They always start with a plus sign and contain at least 8 numbers, but can contain dashes and spaces depending on the country.
So, after the literal \verb|+| (which we need to escape since \verb|+| is a control character),
we look for 7 or more numbers, optionally followed by a single dash or space, and end with a single number.
This allows dashes and spaces at any position except the start and end, but does not allow for e.g. double dashes.
It also makes sure that there are at least 8 numbers regardless of how many dashses or spaces there are.

The final four examples are patters for common notations found online.  
For URLs, we look for \ttt{http://} or \ttt{https://} and take everything until the next space or end of the string.
For email addresses, we define a character class for letters, periods, or dashes and look for it before and after the at-sign.
Then, there needs to at least one period and a top level domain containing only letters.
Note that the dash within the character class does not need to be escaped because it is the final character in the class, so it cannot form a range.
For HTML tags and character escapes, we anchor the start (\verb|<| and \verb|&|) and end (\verb|>| and \verb|;|) and allow any characters except for the ending character in between
using an inverted character class.

Note that these example patterns would also match if the text is enclosed in a larger text.
For example, the zip code pattern would happily match the first 5 numbers of a 10-digit number.
If you want to check that an input value is a valid zip code (or email address, etc.),
you probably want to check that it only contains that code by surrounding it with start-of-text and end-of-text markers: \verb|^\d{5}$|.
If you want to extract e.g. zip codes from a longer document, it is often useful to surround them with word boundary markers: \verb|\b\d{5}\b|.

Please note that many of those patterns are not necessarily fully complete and correct, especially the final patterns for online notations.
For example, email addresses can contain plus signs in the first part, but not in the domain name, while domain names are not allowed to start with a dash -- a completely correct regular expression to match email addresses is over 400 characters long!
Even worse, a complete HTML tag expression is probably not even possible because as a regular expression as they can contain comments and nested escapes within attributes.
For a better way to deal with analysing HTML, please see \refchap{scraping}. In the end, patterns like these are fine for a (somewhat) noisy analysis of (often also somewhat noisy) source texts as long as you understand the limitations. 
        
\subsection{Using regular expressions in Python and R}

Now that you hopefully have a firm grasp of regular expression syntax,
it is relatively easy to use these patterns in Python or R (or most other languages).
\reftab{regexcmd} lists the commands for four of the most common use cases:
identifying matching texts, removing and replacing all matching text, extracting matched groups, and splitting texts.

\input{chapter10/tabregexcmd}

For R, we again use the functions from the \pkg{stringr} package.
For python, you can use either the \pkg{re} or \pkg{regex} package,
which both support the same functions and syntax so you can just import one or the other.
The \pkg{re} package is more common, but does not support unicode character properties (\verb!\p!).

Finally, a small but important note about \concept{escaping} special characters by placing a backslash (\verb|\|) before them.
The regular expression patterns are used \emph{within} another language (in this case, Python or R), but these languages have their own
special characters which are also escaped. In Python, you can create a \concept{raw string} by putting a single \verb|r| before the opening quotation mark:
\verb|r"\d+"| creates the regular expression pattern \verb|\d|.
From version 4.0 (released in spring 2020), R has a similar construct: \verb|r"(\d+)"|. In R, the parentheses are part of the string delimiters, but you can use more parentheses within the string without a problem.
The only think you cannot include in a string is the closing sequence \verb|)"|, but as you are also allowed to use square or curly brackets instead of parentheses and single instead of double quotes to delimit the raw string you can generally avoid this problem:
to create the pattern \verb!"(cat|dog)"! (i.e. cat or dog enclosed in quotation marks), you can use \verb!r"{"(cat|dog)"}"! or \verb!r'("(cat|dog)")'! (or even more legible: \verb!r'{"(cat|dog)"}'!). 

Unfortunately, in earlier versions of R (and in any case if you don't use raw strings), you need to escape special characters twice:
first for the regular expression, and then for R. So, the pattern \verb|\d| becomes \verb|"\\d+"|. To match a literal backslash you would use the pattern \verb|\\|,
which would then be represented in R as \verb|"\\\\"|!



\pyrex[output=both,caption=Using regular expressions to remove hltm tags]{chapter10/regex}

These regular expression can also help us to normalize our text to avoid misspellings or unify different spellings. Think for example of the word \emph{acknowledge}, which is one of the most common misspelled terms in English with non-existing terms such as \emph{acknowlege} or \emph{aknowledge}. Or you may also think of words with different correct spellings, such as \emph{color} or \emph{favorite} in the US and \emph{colour} or \emph{favourite} in the UK, that you need to unify in order to focus your analysis on the same concept they represent. In \refex{regex2} you will see how to conduct this tasks using \verb+.+, \verb|+|, \verb+?+ and also \verb+|+.

\pyrex[output=both,caption=Using regular expressions to unify spellings]{chapter10/regex2}

You can also use this approach to extract strings of the text based on a pattern. Imagine for example you want to get the Twitter usernames included in the object \texttt{tweets} and you know its structure a priori: they all begin with the character \texttt{@}. \refex{regex3} show you how you can deploy this task using regexes. In the case of R you can first generate a list of words (with \fn{unlist} and \fn{strsplit}) and then apply the regular expression rules (obtain the strings with \texttt{@}) with functions \fn{gsub} and \fn{grep}. In the Python example, we do not initially convert the complete string to a list of words, but use the \fn{compile} method of \fn{re} with the regex syntax and then the function \fn{findall} to get the list of usernames.

\pyrex[output=both,caption=Using regular expressions to extract usernames of tweets]{chapter10/regex3}	

There are infinite combinations of regular expression syntaxes and base functions in R and Python that can help you in many tasks to clean your texts from noise. Once you get used to this jargon it will be easy to apply it to different kinds of operations and make your life easier.
