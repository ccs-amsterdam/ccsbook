{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10. Proccesing text\n",
    "## Notebook for R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 NLP (removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": [
     "snippet:tokens"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens from 1 document.\n",
      "text1 :\n",
      " [1] \"<\"                \"@born_in_america\" \":\"                \"My\"              \n",
      " [5] \"second\"           \"favorite\"         \"color\"            \"is\"              \n",
      " [9] \"green\"            \",\"                \"I\"                \"must\"            \n",
      "[13] \"acknowlege\"       \"my\"               \"friends\"          \"for\"             \n",
      "[17] \"that\"             \"!\"                \">\"                \",\"               \n",
      "[21] \"<\"                \"@born_in_britain\" \":\"                \"My\"              \n",
      "[25] \"second\"           \"favourite\"        \"colour\"           \"is\"              \n",
      "[29] \"red\"              \",\"                \"I\"                \"must\"            \n",
      "[33] \"aknowledge\"       \"my\"               \"friends\"          \"for\"             \n",
      "[37] \"that\"             \"!\"                \">\"               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'c(text1 = 39)'"
      ],
      "text/latex": [
       "'c(text1 = 39)'"
      ],
      "text/markdown": [
       "'c(text1 = 39)'"
      ],
      "text/plain": [
       "c(text1 = 39)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens from 1 document.\n",
      "text1 :\n",
      " [1] \"@born_in_america\" \"second\"           \"favorite\"         \"color\"           \n",
      " [5] \"green\"            \"must\"             \"acknowlege\"       \"friends\"         \n",
      " [9] \"@born_in_britain\" \"second\"           \"favourite\"        \"colour\"          \n",
      "[13] \"red\"              \"must\"             \"aknowledge\"       \"friends\"         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'c(text1 = 16)'"
      ],
      "text/latex": [
       "'c(text1 = 16)'"
      ],
      "text/markdown": [
       "'c(text1 = 16)'"
      ],
      "text/plain": [
       "c(text1 = 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(quanteda)\n",
    "tokens = tokens(tweets)\n",
    "print(tokens)\n",
    "glue(ntoken(tweets))\n",
    "\n",
    "filtered_tokens = tokens_remove(tokens(tweets, remove_punct = TRUE), stopwords(\"english\"))\n",
    "print(filtered_tokens)\n",
    "glue(ntoken(filtered_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": [
     "snippet:stem"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokens from 1 document.\n",
       "text1 :\n",
       "[1] \"Build\"  \"Build\"  \"awesom\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_wordstem(tokens(\"Buildings Builds awesome\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": [
     "snippet:nlp"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spaCy is already initialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in spacy_parse.character(tweets):\n",
      "“lemmatization may not work properly in model 'en_core_web_sm'”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "'Number of tokens: 39'"
      ],
      "text/latex": [
       "'Number of tokens: 39'"
      ],
      "text/markdown": [
       "'Number of tokens: 39'"
      ],
      "text/plain": [
       "Number of tokens: 39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(spacyr)\n",
    "spacy_initialize( model = \"en_core_web_sm\", python_executable = NULL, virtualenv = NULL,\n",
    "condaenv = NULL, ask = FALSE, refresh_settings = FALSE, save_profile = FALSE, check_env = TRUE, entity = TRUE)\n",
    "doc = spacy_parse(tweets)\n",
    "glue(\"Number of tokens: \", nrow(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": [
     "snippet:poslemma"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  token lemma pos\n",
      "8    is    be AUX\n",
      "     token  lemma  pos\n",
      "15 friends friend NOUN\n"
     ]
    }
   ],
   "source": [
    "print(doc[8,4:6])\n",
    "print(doc[15,4:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "tags": [
     "snippet:nounchunks"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Number of noun chunks: 7'"
      ],
      "text/latex": [
       "'Number of noun chunks: 7'"
      ],
      "text/markdown": [
       "'Number of noun chunks: 7'"
      ],
      "text/plain": [
       "Number of noun chunks: 7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Noun chunk 4: my friends'"
      ],
      "text/latex": [
       "'Noun chunk 4: my friends'"
      ],
      "text/markdown": [
       "'Noun chunk 4: my friends'"
      ],
      "text/plain": [
       "Noun chunk 4: my friends"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noun_chunks = spacy_extract_nounphrases(tweets)\n",
    "glue(\"Number of noun chunks: \", nrow(noun_chunks))\n",
    "glue(\"Noun chunk 4: \", noun_chunks[4, \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "tags": [
     "snippet:dependency"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in spacy_parse.character(\"My second favorite color is green\", dependency = TRUE):\n",
      "“lemmatization may not work properly in model 'en_core_web_sm'”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     token dep_rel\n",
      "1       My    poss\n",
      "2   second    amod\n",
      "3 favorite    amod\n",
      "4    color   nsubj\n",
      "5       is    ROOT\n",
      "6    green   acomp\n"
     ]
    }
   ],
   "source": [
    "docp = spacy_parse(\"My second favorite color is green\", dependency = TRUE)\n",
    "print(select(docp,token,dep_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "tags": [
     "snippet:ner"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in spacy_parse.character(\"Madrid will host Olympic Games in 2032, Pedro Sanchez announced\"):\n",
      "“lemmatization may not work properly in model 'en_core_web_sm'”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  doc_id sentence_id        entity entity_type\n",
      "1  text1           1        Madrid         GPE\n",
      "2  text1           1 Olympic_Games         ORG\n",
      "3  text1           1          2032        DATE\n",
      "4  text1           1 Pedro_Sanchez      PERSON\n"
     ]
    }
   ],
   "source": [
    "headline= spacy_parse(\"Madrid will host Olympic Games in 2032, Pedro Sanchez announced\")\n",
    "print(entity_extract(headline, type = \"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
