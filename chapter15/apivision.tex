\section{Using existing libraries and APIs}
\label{sec:apivisions}

In the last sections we have shown you how to deal with multimedia contents with special attention to image classification using state-of-the-art libraries. With these tools you can build from scratch most of the analyses and also use some pre-defined models to execute classification tasks. However, given its complexity, it might happen that you decide to use other existing libraries that directly implements multimedia analysis or to connect to commercial services to deploy certain tasks remotely using their APIs. There is a vast variety of available libraries and APIs, which we cannot cover in this book, but we will briefly mention some of them that may be useful in the computational analysis of communication.

One example in the field of visual analytics is the \textit{optical character recognition} (OCR). It is true that you can train your own models to deploy multi-class classification and predict every letter, number or symbol in an image, but it will be task that will take you a lot of effort. Instead, there are specialized libraries in both R and Python such as \pkg{tesseract} that deploy this task in seconds with high accuracy. It is still possible that you will have apply some pre-processing to the input images in order to put them on shape. This means that you may need to use packages such as \pkg{PIL} or \pkg{Magick} to improve the quality of the image by cropping it or by reducing the background noise.  In the case of PDFs files you will have to convert the first into images and then apply OCR.

In the case of more complex audio and image documents you can use more sophisticated services provided by private companies (i.e. Google, Amazon, Microsoft, etc.). These commercial services have already deployed their own machine learning models with very good results. Some times you can even customize some of their models, but as a rule their internal features and configuration are not transparent to the user. Moreover, these services offer friendly APIs and normally a free quota to deploy your first exercises.

To work with audio files, many social researchers might need to convert long conversations, radio programs or interviews to plain text. For this propose, \textit{Google Cloud} offer the service \textit{Speech-to-Text}\footnote{https://cloud.google.com/speech-to-text}  that remotely transcribe the audio to a text format supporting multiple languages (more than 125!). With this service you can remotely use the advanced deep learning models created by Google Platform from your own local computer (you must have an account and connect with the proper packages such as \pkg{googleLanguageR} or \pkg{google-cloud-language} in Python).


In addition we mention commercial providers (e.g., Google Vision) that offer APIs that return tags for uploaded images, which makes image recognition available for everyone. We discuss how to use such services, their advantages and limitations.

