\chapter{Where to go next}
\label{chap:wherenext}

\begin{abstract}{Abstract}
This chapter summarizes the main learning goals of the book, and outlines possible next steps. Special attention is payed to an ethical application of computational methods, as well as to the importance of open and transparent science.
\end{abstract}

\keywords{summary, open science, ethics}


\begin{objectives}
\item Reflect on the learning goals of the book
\item Point out avenues for future study
\item Highlight ethical considerations for applying the techniques covered in the book
\item Relate the techniques covered in the book to Open Science practices
\end{objectives}

\begin{feature}
This concluding chapter provides a broad overview of what was covered so far, and what interesting avenues to explore next are. It gives pointers to resources to learn more about topics such as programming, statistical modeling or deep learning. It also discusses considerations regarding ethics and open science.

\end{feature}



\section{How far have we come?}
In this book, we introduced you to the computational analysis of communication. In Chapter~\ref{chap:introduction}, we tried to convince you that the computational analysis of communication is a worthwhile endeavour. But we also highlighted that there is much more than this book can cover.
So here we are now. Maybe you skipped some chapters, maybe you did some additional reading or followed some online tutorials, and maybe you completed your first small project that involved some of techniques we covered. Time to recap.

You now have some knowledge of programming. We hope that this has opened new doors for you, and allows you to use a wealth of libraries, tutorials, and tools that may make your life easier, your research more productive, and your analyses better.

You have learned how to handle new types of data. Not only traditional tabular datasets, but also textual data, semi-structured data, and to some extend network data and images.

You can apply machine-learning frameworks. You know about both unsupervised and supervised approaches, and can decide on how they can be useful for finding answers to your research questions.

Finally, you have got at least a first impression of some cool techniques like neural networks and services such as databases, containers, and cloud computing. We hope that being aware of them will help you to make an informed decision whether they may be good tools to dive into for your upcoming projects.



\section{Where to go next?}
But what should you learn next?

Most importantly, we cannot stress enough that it should be the research question that is guiding, not the method. You shouldn't use the newest neural network module just because it's cool, when counting occurrences of a simple regular expression does the trick. But this also goes the other way around: If a new method performs much better than an old one, you should learn it! For too long, for instance, people have relied on simple bag-of-words sentiment analyses with off-the-shelf dictionaries, simply because they were easy to use -- despite better alternatives being available.

Having said that, we will nevertheless try to give some general recommendations for what to learn next.

\paragraph{Become better at programming} In this book, we tried to find a compromise between teaching programming concepts necessary to apply our methods on the one hand, and not getting overly technical on the other hand. After all, for many social scientists, programming is a means to an end, not a goal in itself. But as you progress, a deeper understanding of some programming concepts will make it easier for you to tailor everything according to your needs, and will -- again -- open new doors. There are countless books and online tutorials on ``Programming in [Language of your choice]''. In fact, in this "bilingual" book we have shown you how to program with R and Python (the most used languages by data scientists), but there are other programming languages that might also deserve your attention (e.g. Java, Scala, Julia, etc.) if you become a computational scientist. 


\paragraph{Learn how to write libraries} A very specific yet widely applicable skill we'd encourage you to learn is writing own packages (``modules'' or ``libraries''). One of the nice things about computational analyses is that they are very much compatible with an Open Science approach. Sharing what you have done is much easier if everything you did is already documented in some code that you can share. But you can go one step further: Of course it is nice if people can reproduce exactly your analysis, but it would be even nicer if they -- additionally -- could use your code to run analyses using their own data? If you thought about a great way to compute some statistic, why not make it easy for others to do the same? Writing your code in such a way and then publishing it on CRAN or pypi so that others can install it.

\paragraph{Get inspiration for new types of studies} Try to think a bit out of the box and beyond classical surveys, experiments, and content analyses to design new studies. Books like ``Bit by Bit'' \cite{Salganik2019} may help you with this. You can also take a look at other scientific disciplines such as computational biology that has reinvented its methods, questions and hypotheses. Keep in mind that computational methods have an impact on the theoretical and empirical discussions of communication processes, which in turn will arise novel type of studies. The emerging scientific fields (Computational Communication Science, Computational Social Sciences, Digital Humanities...) will also serve as an incentive for your imagination.

\paragraph{Get a deeper understanding of deep learning} For many tasks in the computational analysis of communication, classical machine learning approaches (like regression or support vector machines) work just fine. In fact, there is no need to always jump on the latest band wagon of the newest technique. If a simple logistic regression achieves an F1-score of 88.1, and the most fancy neural network achievs an 88.5 -- would it be worth the extra effort and the loss of explainability? It depends on your use case, but probably not. Nevertheless, by now, we can be fairly certain that neural networks are here to stay. We could only give a limited introduction in this book, but state-of-the-art analysis of especially images, but also text cannot do without it any more. Even though you may not train such models yourself all the time, but may use, for instance, pre-trained word embeddings or use packages like \pkg{spacy} that have been trained using neural networks, it seems worthwhile to understand these techniques better. Also here, a lot of online tutorials exist for frameworks such as \fn{keras} or \fn{tensorflow}, but also thorough books that provide a sound understanding of the underlying models \cite{goldberg2017}.


\paragraph{Learn more about statistical models} Not everything in the computational analysis of communication is machine learning. We used the analogy of the mouse trap (where we only care about the performance, not the underlying mechanism) versus better understanding before, and argued that often, we may use machine learning as a ``mouse trap'' to enrich our data -- even if we are ultimately interested in explaining some other process. For instance, we may want to use machine learning as one step in a workflow to predict the topic of social media messages, and then use a conventional statistical approach to understand which factors explain how often the message has been shared. Such data, though, often have different characteristics than data that you may encounter in surveys or experiments. In this case, for instance, the number of shares is a so-called count variable: it can take only positive integers, and thus has a lower bound (0) but no upper bound. That's very different than normally distributed data and requires regression models such as negative binomial regression. That's not difficult to do, but worth to read up on. Similarly, multilevel modelling will often be appropriate for the data you work with. Being familiar with this and other techniques (such as mediation and moderation analysis, or even structural equation modeling) will allow you to make better choices. On a different note, you may want to familiarize yourself with Bayesian statistics -- a framework that is very different from the so-called frequentist approach that you probably know from your statistics courses.


And, last but not least: Have fun! At least for us, that is one of the most important parts: Don't forget to enjoy the skills you gained, and create projects that you enjoy!



\input{chapter18/ethics}
