{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import parse, fromstring\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "# we only use pandas to show you the scraped data\n",
    "import pandas as pd  \n",
    "from lxml.html import parse\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import (\n",
    "    WebDriverWait)\n",
    "from selenium.webdriver.support import (\n",
    "    expected_conditions as EC)\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "snippet:htmlparse1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n",
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n"
     ]
    }
   ],
   "source": [
    "tree=parse(urlopen(\n",
    "    \"https://cssbook.net/d/eat/index.html\"))\n",
    "\n",
    "# get the restaurant names via XPATH \n",
    "print([e.text_content().strip() for e in \n",
    "       tree.xpath(\"//h3\")])\n",
    "\n",
    "# get the restaurant names via CSS Selector\n",
    "print([e.text_content().strip() for e in\n",
    "       tree.getroot().cssselect(\"h3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "snippet:htmlparse2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending `/text()` to the XPATH gives you exactly the text that is in the element itself, including line-breaks that happen to be in the source code:\n",
      "[' ', '\\n      ', '\\n      ', '\\n    ', ' ', '\\n      ', '\\n      ', '\\n    ', ' ', '\\n      ', '\\n      ', '\\n    ']\n",
      "\n",
      "Using the `text` property of theelements in the list of elements that are matched by the XPATH expression gives you the text of the elements themselves without the line breaks: \n",
      "[' ', ' ', ' ']\n",
      "\n",
      "Using the `text_content()` method instead returns the text of the element *and the text of its children*:\n",
      "['  Pizzeria Roma \\n       Here you can get ... ... \\n       Read the full review here\\n    ', '  Trattoria Napoli \\n       Another restaurant ... ... \\n       Read the full review here\\n    ', '  Curry King \\n       Some description. \\n       Read the full review here\\n    ']\n",
      "\n",
      "The same but using CSS Selectors (note the .getroot() method, because the selectors can only be applied to HTML elements, not to DOM trees): \n",
      "['  Pizzeria Roma \\n       Here you can get ... ... \\n       Read the full review here\\n    ', '  Trattoria Napoli \\n       Another restaurant ... ... \\n       Read the full review here\\n    ', '  Curry King \\n       Some description. \\n       Read the full review here\\n    ']\n"
     ]
    }
   ],
   "source": [
    "# three ways of extracting text\n",
    "print(\"Appending `/text()` to the XPATH gives you \"\n",
    "      \"exactly the text that is in the element \"\n",
    "      \"itself, including line-breaks that happen \"\n",
    "      \"to be in the source code:\" )\n",
    "print(tree.xpath(\n",
    "    \"//div[@class='restaurant']/text()\"))\n",
    "\n",
    "print(\"\\nUsing the `text` property of the\"\n",
    "      \"elements in the list of elements that are \"\n",
    "      \"matched by the XPATH expression gives you \"\n",
    "      \"the text of the elements themselves \"\n",
    "      \"without the line breaks: \")\n",
    "print([e.text for e in tree.xpath(\n",
    "    \"//div[@class='restaurant']\")])\n",
    "\n",
    "print(\"\\nUsing the `text_content()` method \"\n",
    "      \"instead returns the text of the element \"\n",
    "      \"*and the text of its children*:\")\n",
    "print([e.text_content() for e in tree.xpath(\n",
    "    \"//div[@class='restaurant']\")])\n",
    "\n",
    "print(\"\\nThe same but using CSS Selectors (note \"\n",
    "      \"the .getroot() method, because the \"\n",
    "      \"selectors can only be applied to HTML \"\n",
    "      \"elements, not to DOM trees): \")\n",
    "print([e.text_content() for e in\n",
    "       tree.getroot().cssselect(\".restaurant\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "snippet:htmlparse3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'here', 'here']\n",
      "['review0001.html', 'review0002.html', 'review0003.html']\n"
     ]
    }
   ],
   "source": [
    "linkelements = tree.xpath(\"//a\")\n",
    "linktexts = [e.text for e in linkelements]\n",
    "links = [e.attrib[\"href\"] for e in linkelements]\n",
    "\n",
    "print(linktexts)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "snippet:htmlparse1useragent"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows \"\n",
    "    \"NT 10.0; Win64; x64; rv:60.0) \"\n",
    "    \"Gecko/20100101 Firefox/60.0\"}\n",
    "\n",
    "htmlsource = requests.get(\n",
    "    \"https://cssbook.net/d/eat/index.html\", \n",
    "    headers = headers).text\n",
    "tree = fromstring(htmlsource)\n",
    "print([e.text_content().strip() for e in \n",
    "       tree.xpath(\"//h3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "snippet:htmltofile"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"test.html\", mode=\"w\") as fo:\n",
    "    fo.write(htmlsource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true,
    "tags": [
     "snippet:createurls"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://reviews.com/?page=1', 'https://reviews.com/?page=2', 'https://reviews.com/?page=3', 'https://reviews.com/?page=4', 'https://reviews.com/?page=5', 'https://reviews.com/?page=6', 'https://reviews.com/?page=7', 'https://reviews.com/?page=8', 'https://reviews.com/?page=9', 'https://reviews.com/?page=10']\n"
     ]
    }
   ],
   "source": [
    "baseurl=\"https://reviews.com/?page=\"\n",
    "tenpages = [f\"{baseurl}{i+1}\" for i in range(10)]\n",
    "print(tenpages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "snippet:crawling"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving all restaurants...\n",
      "[('Pizzeria Roma', 'review0001.html'), ('Trattoria Napoli', 'review0002.html'), ('Curry King', 'review0003.html')]\n",
      "Processing Pizzeria Roma...\n",
      "Downloading https://cssbook.net/d/eat/review0001.html...\n",
      "No more pages found.\n",
      "Processing Trattoria Napoli...\n",
      "Downloading https://cssbook.net/d/eat/review0002.html...\n",
      "No more pages found.\n",
      "Processing Curry King...\n",
      "Downloading https://cssbook.net/d/eat/review0003.html...\n",
      "Processing next page\n",
      "Downloading https://cssbook.net/d/eat/review0003-1.html...\n",
      "Processing next page\n",
      "Downloading https://cssbook.net/d/eat/review0003-2.html...\n",
      "No more pages found.\n",
      "          username                                         reviewtext  rating  \\\n",
      "0     gourmet2536   The best thing to do is ordering a full menu, ...  7.0/10   \n",
      "1        foodie12                          The worst food I ever had!  1.0/10   \n",
      "2    mrsdiningout             If nothing else is open, you can do it.  6.5/10   \n",
      "3        foodie12                               Best Italian in town!  8.6/10   \n",
      "4           smith                                            Love it!  9.0/10   \n",
      "5        foodie12                                             Superb!  9.2/10   \n",
      "6      dontlikeit                       As expected, I didn't like it  4.0/10   \n",
      "7        otherguy                              Try the yoghurt curry!  7.7/10   \n",
      "8           tasty                    We went here for dinner once and  7.0/10   \n",
      "9            anna                I have mixed feeling about this one.  6.2/10   \n",
      "10           hans                                     Not much to say  5.0/10   \n",
      "11        bee1983                                    I am a huge fan!   10/10   \n",
      "12         rhebjf           The service is good, the food not so much  6.5/10   \n",
      "13  foodcritic555                              Once and never again!.  1.0/10   \n",
      "\n",
      "          restaurant  \n",
      "0      Pizzeria Roma  \n",
      "1      Pizzeria Roma  \n",
      "2   Trattoria Napoli  \n",
      "3   Trattoria Napoli  \n",
      "4         Curry King  \n",
      "5         Curry King  \n",
      "6         Curry King  \n",
      "7         Curry King  \n",
      "8         Curry King  \n",
      "9         Curry King  \n",
      "10        Curry King  \n",
      "11        Curry King  \n",
      "12        Curry King  \n",
      "13        Curry King  \n"
     ]
    }
   ],
   "source": [
    "BASEURL = \"https://cssbook.net/d/eat/\"\n",
    "\n",
    "def get_restaurants(url):\n",
    "  \"\"\"takes the URL of an overview page as input\n",
    "  returns a list of (name, link) tuples\"\"\"\n",
    "  tree = parse(urlopen(url))\n",
    "  names = [e.text.strip() for e in \n",
    "    tree.xpath(\"//div[@class='restaurant']/h3\")]\n",
    "  links = [e.attrib[\"href\"] for e in \n",
    "    tree.xpath(\"//div[@class='restaurant']//a\")]\n",
    "  return list(zip(names, links))\n",
    "\n",
    "def get_reviews(url):\n",
    "  \"\"\"yields reviews on the specified page\"\"\"\n",
    "  while True:\n",
    "    print(f\"Downloading {url}...\")\n",
    "    tree = parse(urlopen(url))\n",
    "    names = [e.text.strip() for e in \n",
    "      tree.xpath(\"//div[@class='review']/h3\")]\n",
    "    texts = [e.text.strip() for e in \n",
    "      tree.xpath(\"//div[@class='review']/p\")]\n",
    "    ratings = [e.text.strip() for e in tree.xpath(\n",
    "      \"//div[@class='rating']\")]\n",
    "    for u,txt,rating in zip(names,texts,ratings):\n",
    "      review = {}\n",
    "      review[\"username\"] = u.replace(\"wrote:\",\"\")\n",
    "      review[\"reviewtext\"] = txt\n",
    "      review[\"rating\"] = rating\n",
    "      yield review\n",
    "    bb=tree.xpath(\"//span[@class='backbutton']/a\")\n",
    "    if bb:\n",
    "      print(\"Processing next page\")\n",
    "      url = BASEURL+bb[0].attrib[\"href\"]\n",
    "    else:\n",
    "      print(\"No more pages found.\")\n",
    "      break\n",
    "        \n",
    "print(\"Retrieving all restaurants...\")\n",
    "links = get_restaurants(BASEURL+\"index.html\")\n",
    "print(links)\n",
    "\n",
    "with open(\"reviews.json\", mode = \"w\") as f:\n",
    "    for restaurant, link in links:\n",
    "        print(f\"Processing {restaurant}...\")\n",
    "        for r in get_reviews(BASEURL+link):\n",
    "            r[\"restaurant\"] = restaurant\n",
    "            f.write(json.dumps(r))\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "# You can process the results with pandas\n",
    "# (using lines=True since it\"s one json per line)\n",
    "df = pd.read_json(\"reviews.json\", lines=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "snippet:selenium"
    ]
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(\"https://www.duckduckgo.com\")\n",
    "element = driver.find_element_by_name(\"q\")\n",
    "# also check out other options such as \n",
    "# .find_element_by_xpath\n",
    "# or .find_element_by_css_selector\n",
    "element.send_keys(\"TinTin\")\n",
    "element.send_keys(Keys.RETURN)\n",
    "try:\n",
    "    driver.find_element_by_css_selector(\n",
    "        \"#links a\").click()\n",
    "    # let\"s be cautious and wait 10 seconds\n",
    "    # so that everything is loaded\n",
    "    time.sleep(10)\n",
    "    driver.save_screenshot(\"screenshotTinTin.png\")\n",
    "finally:\n",
    "    # whatever happens, close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "snippet:cookiewall"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Een kudtkoekiewall. Omdat dat moet, van de kudtkoekiewet.\n",
      "There are 318 comments.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.geenstijl.nl/5160019/page\"\n",
    "\n",
    "# circumvent cookie wall by setting a specific\n",
    "# cookie: the key-value pair (cpc: 10)\n",
    "client = requests.session()\n",
    "r = client.get(URL)\n",
    "\n",
    "cookies = client.cookies.items()\n",
    "cookies.append((\"cpc\",\"10\"))\n",
    "response = client.get(URL,cookies=dict(cookies))\n",
    "# end circumvention\n",
    "\n",
    "tree = fromstring(response.text)\n",
    "allcomments = [e.text_content().strip() for e in \n",
    "               tree.cssselect(\".cmt-content\")]\n",
    "print(f\"There are {len(allcomments)} comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": [
     "snippet:cookiewall2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 318 comments.\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(URL,cookies={\"cpc\": \"10\"})\n",
    "tree = fromstring(r.text)\n",
    "allcomments = [e.text_content().strip() for e in \n",
    "               tree.cssselect(\".cmt-content\")]\n",
    "print(f\"There are {len(allcomments)} comments.\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
