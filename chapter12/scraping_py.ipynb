{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import parse, fromstring\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "# we only use pandas to show you the scraped data\n",
    "import pandas as pd  \n",
    "from lxml.html import parse\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import (\n",
    "    WebDriverWait)\n",
    "from selenium.webdriver.support import (\n",
    "    expected_conditions as EC)\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "snippet:htmlparse1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n",
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n"
     ]
    }
   ],
   "source": [
    "tree=parse(urlopen(\n",
    "    \"https://cssbook.net/d/eat/index.html\"))\n",
    "\n",
    "# get the restaurant names via XPATH \n",
    "print([e.text_content().strip() for e in \n",
    "       tree.xpath(\"//h3\")])\n",
    "\n",
    "# get the restaurant names via CSS Selector\n",
    "print([e.text_content().strip() for e in\n",
    "       tree.getroot().cssselect(\"h3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "snippet:htmlparse2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending \"/text()\" to the XPATH gives youexactly the text that is in the elementitself, including line-breaks that happento be in the source code:\n",
      "[' ', '\\n      ', '\\n      ', '\\n    ', ' ', '\\n      ', '\\n      ', '\\n    ', ' ', '\\n      ', '\\n      ', '\\n    ']\n",
      "\n",
      "Using the \"text\" property of theelements in the list of elements that arematched by the XPATH expression gives youthe text of the elements themselveswithout the line breaks:\n",
      "[' ', ' ', ' ']\n",
      "\n",
      "Using the \"text_content()\" methodinstead returns the text of the element*and the text of its children*:\n",
      "['  Pizzeria Roma \\n       Here you can get ... ... \\n       Read the full review here\\n    ', '  Trattoria Napoli \\n       Another restaurant ... ... \\n       Read the full review here\\n    ', '  Curry King \\n       Some description. \\n       Read the full review here\\n    ']\n",
      "\n",
      "The same but using CSS Selectors (notethe .getroot() method, because theselectors can only be applied to HTMLelements, not to DOM trees):\n",
      "['  Pizzeria Roma \\n       Here you can get ... ... \\n       Read the full review here\\n    ', '  Trattoria Napoli \\n       Another restaurant ... ... \\n       Read the full review here\\n    ', '  Curry King \\n       Some description. \\n       Read the full review here\\n    ']\n"
     ]
    }
   ],
   "source": [
    "# three ways of extracting text\n",
    "print('Appending \"/text()\" to the XPATH gives you'\n",
    "      'exactly the text that is in the element'\n",
    "      'itself, including line-breaks that happen'\n",
    "      'to be in the source code:' )\n",
    "print(tree.xpath(\n",
    "    '//div[@class=\"restaurant\"]/text()'))\n",
    "\n",
    "print('\\nUsing the \"text\" property of the'\n",
    "      'elements in the list of elements that are'\n",
    "      'matched by the XPATH expression gives you'\n",
    "      'the text of the elements themselves'\n",
    "      'without the line breaks:')\n",
    "print([e.text for e in tree.xpath(\n",
    "    '//div[@class=\"restaurant\"]')])\n",
    "\n",
    "print('\\nUsing the \"text_content()\" method'\n",
    "      'instead returns the text of the element'\n",
    "      '*and the text of its children*:')\n",
    "print([e.text_content() for e in tree.xpath(\n",
    "    '//div[@class=\"restaurant\"]')])\n",
    "\n",
    "print('\\nThe same but using CSS Selectors (note'\n",
    "      'the .getroot() method, because the'\n",
    "      'selectors can only be applied to HTML'\n",
    "      'elements, not to DOM trees):')\n",
    "print([e.text_content() for e in\n",
    "       tree.getroot().cssselect('.restaurant')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "snippet:htmlparse3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'here', 'here']\n",
      "['review0001.html', 'review0002.html', 'review0003.html']\n"
     ]
    }
   ],
   "source": [
    "linkelements = tree.xpath(\"//a\")\n",
    "linktexts = [e.text for e in linkelements]\n",
    "links = [e.attrib[\"href\"] for e in linkelements]\n",
    "\n",
    "print(linktexts)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "snippet:htmlparse1useragent"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows \"\n",
    "    \"NT 10.0; Win64; x64; rv:60.0) \"\n",
    "    \"Gecko/20100101 Firefox/60.0\"}\n",
    "\n",
    "htmlsource = requests.get(\n",
    "    \"https://cssbook.net/d/eat/index.html\", \n",
    "    headers = headers).text\n",
    "tree = fromstring(htmlsource)\n",
    "print([e.text_content().strip() for e in \n",
    "       tree.xpath(\"//h3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "snippet:htmltofile"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'htmlsource' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-450e140faf40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.html\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtmlsource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'htmlsource' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"test.html\", mode=\"w\") as fo:\n",
    "    fo.write(htmlsource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": [
     "snippet:createurls"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://myreviews.com/nl/hotel.html?page=1', 'http://myreviews.com/nl/hotel.html?page=2', 'http://myreviews.com/nl/hotel.html?page=3', 'http://myreviews.com/nl/hotel.html?page=4', 'http://myreviews.com/nl/hotel.html?page=5', 'http://myreviews.com/nl/hotel.html?page=6', 'http://myreviews.com/nl/hotel.html?page=7', 'http://myreviews.com/nl/hotel.html?page=8', 'http://myreviews.com/nl/hotel.html?page=9', 'http://myreviews.com/nl/hotel.html?page=10']\n"
     ]
    }
   ],
   "source": [
    "baseurl=\"http://myreviews.com/nl/hotel.html?page=\"\n",
    "tenpages = [f\"{baseurl}{i+1}\" for i in range(10)]\n",
    "print(tenpages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "snippet:crawling"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving all restaurants and their links...\n",
      "[('Pizzeria Roma', 'review0001.html'), ('Trattoria Napoli', 'review0002.html'), ('Curry King', 'review0003.html')]\n",
      "Processing reviews for Pizzeria Roma...\n",
      "Downloading and parsing review page https://cssbook.net/d/eat/review0001.html...\n",
      "No more pages found.\n",
      "Processing reviews for Trattoria Napoli...\n",
      "Downloading and parsing review page https://cssbook.net/d/eat/review0002.html...\n",
      "No more pages found.\n",
      "Processing reviews for Curry King...\n",
      "Downloading and parsing review page https://cssbook.net/d/eat/review0003.html...\n",
      "Found page with older reviews! I'll process that one next\n",
      "Downloading and parsing review page https://cssbook.net/d/eat/review0003-1.html...\n",
      "Found page with older reviews! I'll process that one next\n",
      "Downloading and parsing review page https://cssbook.net/d/eat/review0003-2.html...\n",
      "No more pages found.\n",
      "         username                      reviewtext  rating        restaurant\n",
      "0     gourmet2536  The best thing to do is orderi  7.0/10     Pizzeria Roma\n",
      "1        foodie12      The worst food I ever had!  1.0/10     Pizzeria Roma\n",
      "2    mrsdiningout  If nothing else is open, you c  6.5/10  Trattoria Napoli\n",
      "3        foodie12           Best Italian in town!  8.6/10  Trattoria Napoli\n",
      "4           smith                        Love it!  9.0/10        Curry King\n",
      "5        foodie12                         Superb!  9.2/10        Curry King\n",
      "6      dontlikeit   As expected, I didn't like it  4.0/10        Curry King\n",
      "7        otherguy          Try the yoghurt curry!  7.7/10        Curry King\n",
      "8           tasty  We went here for dinner once a  7.0/10        Curry King\n",
      "9            anna  I have mixed feeling about thi  6.2/10        Curry King\n",
      "10           hans                 Not much to say  5.0/10        Curry King\n",
      "11        bee1983                I am a huge fan!   10/10        Curry King\n",
      "12         rhebjf  The service is good, the food   6.5/10        Curry King\n",
      "13  foodcritic555          Once and never again!.  1.0/10        Curry King\n"
     ]
    }
   ],
   "source": [
    "BASEURL = \"https://cssbook.net/d/eat/\"\n",
    "\n",
    "def get_restaurants(url):\n",
    "    '''takes the URL of an overview page as input and returns a list of\n",
    "    (restaurantname, link) tuples'''\n",
    "    tree = parse(urlopen(url))\n",
    "    restaurants_names = [e.text.strip() for e in tree.xpath('//div[@class=\"restaurant\"]/h3')]\n",
    "    restaurants_links = [e.attrib['href'] for e in tree.xpath('//div[@class=\"restaurant\"]//a')]\n",
    "    return list(zip(restaurants_names, restaurants_links))\n",
    "   \n",
    "def get_reviews(url):\n",
    "    '''takes the URL of a page with reviews as input and yields reviews on it '''\n",
    "    while True:\n",
    "        print(f\"Downloading and parsing review page {url}...\")\n",
    "        tree = parse(urlopen(url))\n",
    "        usernames = [e.text.strip() for e in tree.xpath('//div[@class=\"review\"]/h3')]\n",
    "        reviewtexts = [e.text.strip() for e in tree.xpath('//div[@class=\"review\"]/p')]\n",
    "        ratings = [e.text.strip() for e in tree.xpath(\n",
    "            '//div[@class=\"review\"]/div[@class=\"rating\"]')]\n",
    "        for u, rew, rat in zip(usernames, reviewtexts, ratings):\n",
    "            review = {}\n",
    "            review[\"username\"] = u.replace(\"wrote:\",\"\").strip()\n",
    "            review[\"reviewtext\"] = rew\n",
    "            review[\"rating\"] = rat\n",
    "            yield review\n",
    "        if len(tree.xpath('//span[@class=\"backbutton\"]')) > 0:\n",
    "            print(\"Found page with older reviews! I'll process that one next\")\n",
    "            url = BASEURL+tree.xpath('//span[@class=\"backbutton\"]/a')[0].attrib[\"href\"]\n",
    "        else:\n",
    "            print(\"No more pages found.\")\n",
    "            break\n",
    "        \n",
    "print(\"Retrieving all restaurants and their links...\")\n",
    "restaurantlinks = get_restaurants(BASEURL+\"index.html\")\n",
    "print(restaurantlinks)\n",
    "\n",
    "with open(\"reviews.json\", mode = \"w\") as f:\n",
    "    for restaurant, link in restaurantlinks:\n",
    "        print(f\"Processing reviews for {restaurant}...\")\n",
    "        for r in get_reviews(BASEURL+link):\n",
    "            r['restaurant'] = restaurant\n",
    "            f.write(json.dumps(r))\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "# you do not need to use pandas -- just added for illustration purposes here\n",
    "# Note that we stored one JSON object per line instead of per file\n",
    "df = pd.read_json(\"reviews.json\", lines=True)\n",
    "df[\"reviewtext\"] = df[\"reviewtext\"].map(lambda x: x[:30]) # shorten for printing\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "snippet:selenium"
    ]
   },
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: Element <a href=\"https://en.wikipedia.org/wiki/The_Adventures_of_Tintin\"> is not clickable at point (180,343) because another element <div class=\"jw8mI\"> obscures it\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-75e2cfe403c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0melement3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfind_element_by_partial_link_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tintin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0melement3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# let's be cautious and wait 10 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# so that everything is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/onderwijs_github/ccsbook/env/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36mclick\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/onderwijs_github/ccsbook/env/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/onderwijs_github/ccsbook/env/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/onderwijs_github/ccsbook/env/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mElementClickInterceptedException\u001b[0m: Message: Element <a href=\"https://en.wikipedia.org/wiki/The_Adventures_of_Tintin\"> is not clickable at point (180,343) because another element <div class=\"jw8mI\"> obscures it\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.get(\"https://www.google.com\")\n",
    "element = driver.find_element_by_name(\"q\")\n",
    "# also check out other options such as \n",
    "# .find_element_by_xpath\n",
    "# or .find_element_by_css_selector\n",
    "element.send_keys(\"TinTin\")\n",
    "element.send_keys(Keys.RETURN)\n",
    "try:\n",
    "    # let's wait until relevant stuff is loaded\n",
    "    element2 = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located(\n",
    "            (By.ID, \"rso\")))\n",
    "    element3 = driver.\\\n",
    "    find_element_by_partial_link_text(\"Tintin\")\n",
    "    element3.click()\n",
    "    # let's be cautious and wait 10 seconds\n",
    "    # so that everything is loaded\n",
    "    time.sleep(10)\n",
    "    driver.save_screenshot(\"screenshotTinTin.png\")\n",
    "finally:\n",
    "    # whatever happens, let's make sure that even\n",
    "    # if there is an error, we close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "snippet:cookiewall"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 84 comments.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.geenstijl.nl/5160019/\"\\\n",
    "\"altijd-maar-weer-die-kleine-groep-he/\"\n",
    "\n",
    "# circumvent cookie wall by setting a specific\n",
    "# cookie: the key-value pair (cpc: 10)\n",
    "client = requests.session()\n",
    "r = client.get(URL)\n",
    "cookies = client.cookies.items()\n",
    "cookies.append((\"cpc\",\"10\"))\n",
    "response = client.get(URL,cookies=dict(cookies))\n",
    "# end circumvention\n",
    "\n",
    "tree = fromstring(response.text)\n",
    "allcomments = [e.text_content().strip() for e in \n",
    "               tree.cssselect(\".cmt-content\")]\n",
    "print(f\"There are {len(allcomments)} comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "snippet:cookiewall2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 84 comments.\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(URL,cookies={\"cpc\": \"10\"})\n",
    "tree = fromstring(r.text)\n",
    "allcomments = [e.text_content().strip() for e in tree.cssselect(\".cmt-content\")]\n",
    "print(f\"There are {len(allcomments)} comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
