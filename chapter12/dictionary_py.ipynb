{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "snippet:sentsimple"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment: 0.39.\n",
      "Writing reviews and sentiment score to a csv file...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from glob import glob\n",
    "import csv\n",
    "import os\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from numpy import sign\n",
    "\n",
    "positive = set(requests.get('http://cssbook.net/d/positive.txt').text.split('\\n'))\n",
    "negative = set(requests.get('http://cssbook.net/d/negative.txt').text.split('\\n'))\n",
    "sentimentdict = {word:+1 for word in positive}\n",
    "sentimentdict.update({word:-1 for word in negative})\n",
    "\n",
    "# unpack the dataset from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz and store the folder 'aclImdb' in the same folder as this script\n",
    "reviews = []\n",
    "for file in glob(os.path.join('aclImdb','train','unsup','*.txt')):\n",
    "    with open(file) as f:\n",
    "        reviews.append(f.read())\n",
    "\n",
    "sent = []\n",
    "mytokenizer = TreebankWordTokenizer()\n",
    "# we only take the first 100 reviews to speed things up\n",
    "for review in reviews[:100]:\n",
    "    words = mytokenizer.tokenize(review)\n",
    "    # we look up each word in the sentiment dict and assign its value (if we don't find it, it gets 0)\n",
    "    # recode the sum of the values to [-1, 0, +1] with the sign function, and collect the results in the sent list\n",
    "    sent.append(sign(sum([sentimentdict.get(word,0) for word in words])))\n",
    "        \n",
    "print(f\"Average sentiment: {sum(sent)/len(sent)}.\")\n",
    "print('Writing reviews and sentiment score to a csv file...')\n",
    "with open('sentiment.csv',mode='w') as fo:\n",
    "    writer = csv.writer(fo)\n",
    "    writer.writerow(['review', 'sentiment'])\n",
    "    writer.writerows(zip(reviews, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "snippet_sentsimpleugly",
     "dontrun"
    ]
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from glob import glob\n",
    "import csv\n",
    "import os\n",
    "positive = requests.get('http://cssbook.net/d/positive.txt').text.split('\\n')\n",
    "negative = requests.get('http://cssbook.net/d/negative.txt').text.split('\\n')\n",
    "\n",
    "# unpack the dataset from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz and store the folder 'aclImdb' in the same folder as this script\n",
    "reviews = []\n",
    "for file in glob(os.path.join('aclImdb','train','unsup','*.txt')):\n",
    "    with open(file) as f:\n",
    "        reviews.append(f.read())\n",
    "\n",
    "sent = []\n",
    "# we only take the first 100 reviews to speed things up\n",
    "for review in reviews[:100]:\n",
    "    words = review.split()\n",
    "    number_of_pos_words = sum([sum([sentword==word for word in words]) for sentword in positive])\n",
    "    number_of_neg_words = sum([sum([sentword==word for word in words]) for sentword in negative])\n",
    "    if number_of_pos_words > number_of_neg_words:\n",
    "        sent.append(1)\n",
    "    elif number_of_pos_words < number_of_neg_words:\n",
    "        sent.append(-1)\n",
    "    else:\n",
    "        sent.append(0)\n",
    "        \n",
    "print(f\"Average sentiment: {sum(sent)/len(sent)}.\")\n",
    "print('Writing reviews and sentiment score to a csv file...')\n",
    "with open('sentiment.csv',mode='w') as fo:\n",
    "    writer = csv.writer(fo)\n",
    "    writer.writerow(['review', 'sentiment'])\n",
    "    writer.writerows(zip(reviews, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(['the'==word for word in words])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
