{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 12. Scraping online data\n",
    "#### Notebook for Python\n",
    "\n",
    "Van Atteveldt, W., Trilling, D. & Arcila, C. (2022). <a href=\"https://cssbook.net\" target=\"_blank\">Computational Analysis of Communication</a>. Wiley.\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ccs-amsterdam/ccsbook/blob/master/chapter12/chapter_12_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "snippet:chapter12install",
     "dontrun"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (2.25.0)\n",
      "Requirement already satisfied: geopandas in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: geopy in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (2.1.0)\n",
      "Requirement already satisfied: tweepy in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (3.10.0)\n",
      "Collecting selenium\n",
      "  Using cached selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests) (2020.11.8)\n",
      "Requirement already satisfied: fiona in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from geopandas) (1.8.18)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from geopandas) (3.0.0.post1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from geopandas) (1.1.4)\n",
      "Requirement already satisfied: shapely in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from geopandas) (1.7.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from pandas>=0.23.0->geopandas) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from pandas>=0.23.0->geopandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->geopandas) (1.15.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from geopy) (1.52)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests) (1.7.1)\n",
      "Requirement already satisfied: attrs>=17 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from fiona->geopandas) (20.3.0)\n",
      "Requirement already satisfied: munch in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from fiona->geopandas) (2.5.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from fiona->geopandas) (0.7.1)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from fiona->geopandas) (1.1.1)\n",
      "Requirement already satisfied: click<8,>=4.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from fiona->geopandas) (7.1.2)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests geopandas geopy selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "snippet:chapter12library"
    ]
   },
   "outputs": [],
   "source": [
    "# accessing APIs and URLs\n",
    "import requests\n",
    "\n",
    "# handling of JSON responses\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas import json_normalize\n",
    "\n",
    "# general data handling\n",
    "# note: you need to additionally install geopy\n",
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "\n",
    "# static web scraping\n",
    "from urllib.request import urlopen\n",
    "from lxml.html import parse, fromstring\n",
    "\n",
    "# selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import (\n",
    "    WebDriverWait)\n",
    "from selenium.webdriver.support import (\n",
    "    expected_conditions as EC)\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": [
     "snippet:googleapi1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['kind', 'totalItems', 'items'])\n",
      "{'accessInfo': {'accessViewStatus': 'NONE',\n",
      "                'country': 'NL',\n",
      "                'embeddable': False,\n",
      "                'epub': {'isAvailable': False},\n",
      "                'pdf': {'isAvailable': False},\n",
      "                'publicDomain': False,\n",
      "                'quoteSharingAllowed': False,\n",
      "                'textToSpeechPermission': 'ALLOWED',\n",
      "                'viewability': 'NO_PAGES',\n",
      "                'webReaderLink': 'http://play.google.com/books/reader?id=yijjwAEACAAJ&hl=&printsec=frontcover&source=gbs_api'},\n",
      " 'etag': 'zp/xhhsKukU',\n",
      " 'id': 'yijjwAEACAAJ',\n",
      " 'kind': 'books#volume',\n",
      " 'saleInfo': {'country': 'NL', 'isEbook': False, 'saleability': 'NOT_FOR_SALE'},\n",
      " 'searchInfo': {'textSnippet': 'With this handbook, you&#39;ll learn how to '\n",
      "                               'use: IPython and Jupyter: provide '\n",
      "                               'computational environments for data scientists '\n",
      "                               'using Python NumPy: includes the ndarray for '\n",
      "                               'efficient storage and manipulation of dense '\n",
      "                               'data arrays in Python Pandas: ...'},\n",
      " 'selfLink': 'https://www.googleapis.com/books/v1/volumes/yijjwAEACAAJ',\n",
      " 'volumeInfo': {'allowAnonLogging': False,\n",
      "                'authors': ['Jacob T. Vanderplas', 'Jake VanderPlas'],\n",
      "                'averageRating': 5,\n",
      "                'canonicalVolumeLink': 'https://books.google.com/books/about/Python_Data_Science_Handbook.html?hl=&id=yijjwAEACAAJ',\n",
      "                'categories': ['Computers'],\n",
      "                'contentVersion': 'preview-1.0.0',\n",
      "                'description': 'For many researchers, Python is a first-class '\n",
      "                               'tool mainly because of its libraries for '\n",
      "                               'storing, manipulating, and gaining insight '\n",
      "                               'from data. Several resources exist for '\n",
      "                               'individual pieces of this data science stack, '\n",
      "                               'but only with the Python Data Science Handbook '\n",
      "                               'do you get them all--IPython, NumPy, Pandas, '\n",
      "                               'Matplotlib, Scikit-Learn, and other related '\n",
      "                               'tools. Working scientists and data crunchers '\n",
      "                               'familiar with reading and writing Python code '\n",
      "                               'will find this comprehensive desk reference '\n",
      "                               'ideal for tackling day-to-day issues: '\n",
      "                               'manipulating, transforming, and cleaning data; '\n",
      "                               'visualizing different types of data; and using '\n",
      "                               'data to build statistical or machine learning '\n",
      "                               'models. Quite simply, this is the must-have '\n",
      "                               'reference for scientific computing in Python. '\n",
      "                               \"With this handbook, you'll learn how to use: \"\n",
      "                               'IPython and Jupyter: provide computational '\n",
      "                               'environments for data scientists using Python '\n",
      "                               'NumPy: includes the ndarray for efficient '\n",
      "                               'storage and manipulation of dense data arrays '\n",
      "                               'in Python Pandas: features the DataFrame for '\n",
      "                               'efficient storage and manipulation of '\n",
      "                               'labeled/columnar data in Python Matplotlib: '\n",
      "                               'includes capabilities for a flexible range of '\n",
      "                               'data visualizations in Python Scikit-Learn: '\n",
      "                               'for efficient and clean Python implementations '\n",
      "                               'of the most important and established machine '\n",
      "                               'learning algorithms',\n",
      "                'imageLinks': {'smallThumbnail': 'http://books.google.com/books/content?id=yijjwAEACAAJ&printsec=frontcover&img=1&zoom=5&source=gbs_api',\n",
      "                               'thumbnail': 'http://books.google.com/books/content?id=yijjwAEACAAJ&printsec=frontcover&img=1&zoom=1&source=gbs_api'},\n",
      "                'industryIdentifiers': [{'identifier': '1491912057',\n",
      "                                         'type': 'ISBN_10'},\n",
      "                                        {'identifier': '9781491912058',\n",
      "                                         'type': 'ISBN_13'}],\n",
      "                'infoLink': 'http://books.google.nl/books?id=yijjwAEACAAJ&dq=python&hl=&source=gbs_api',\n",
      "                'language': 'un',\n",
      "                'maturityRating': 'NOT_MATURE',\n",
      "                'pageCount': 529,\n",
      "                'panelizationSummary': {'containsEpubBubbles': False,\n",
      "                                        'containsImageBubbles': False},\n",
      "                'previewLink': 'http://books.google.nl/books?id=yijjwAEACAAJ&dq=python&hl=&cd=1&source=gbs_api',\n",
      "                'printType': 'BOOK',\n",
      "                'publishedDate': '2016',\n",
      "                'publisher': \"O'Reilly Media\",\n",
      "                'ratingsCount': 1,\n",
      "                'readingModes': {'image': False, 'text': False},\n",
      "                'subtitle': 'Essential Tools for Working with Data',\n",
      "                'title': 'Python Data Science Handbook'}}\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(\"https://www.googleapis.com/\"\n",
    "                 \"books/v1/volumes?q=python\")\n",
    "data = r.json()\n",
    "print(data.keys())  # \"items\" seems most promising\n",
    "pprint(data[\"items\"][0]) # let's print the 1st one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": [
     "snippet:googleapi2",
     "output:table"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>id</th>\n",
       "      <th>etag</th>\n",
       "      <th>selfLink</th>\n",
       "      <th>volumeInfo.title</th>\n",
       "      <th>volumeInfo.subtitle</th>\n",
       "      <th>volumeInfo.authors</th>\n",
       "      <th>volumeInfo.publisher</th>\n",
       "      <th>volumeInfo.publishedDate</th>\n",
       "      <th>volumeInfo.description</th>\n",
       "      <th>...</th>\n",
       "      <th>accessInfo.accessViewStatus</th>\n",
       "      <th>accessInfo.quoteSharingAllowed</th>\n",
       "      <th>searchInfo.textSnippet</th>\n",
       "      <th>saleInfo.listPrice.amount</th>\n",
       "      <th>saleInfo.listPrice.currencyCode</th>\n",
       "      <th>saleInfo.retailPrice.amount</th>\n",
       "      <th>saleInfo.retailPrice.currencyCode</th>\n",
       "      <th>saleInfo.buyLink</th>\n",
       "      <th>saleInfo.offers</th>\n",
       "      <th>accessInfo.pdf.acsTokenLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>yijjwAEACAAJ</td>\n",
       "      <td>zp/xhhsKukU</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/yi...</td>\n",
       "      <td>Python Data Science Handbook</td>\n",
       "      <td>Essential Tools for Working with Data</td>\n",
       "      <td>[Jacob T. Vanderplas, Jake VanderPlas]</td>\n",
       "      <td>O'Reilly Media</td>\n",
       "      <td>2016</td>\n",
       "      <td>For many researchers, Python is a first-class ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>With this handbook, you&amp;#39;ll learn how to us...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>9MS9BQAAQBAJ</td>\n",
       "      <td>+txFT+aZW0c</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/9M...</td>\n",
       "      <td>Black Hat Python</td>\n",
       "      <td>Python Programming for Hackers and Pentesters</td>\n",
       "      <td>[Justin Seitz]</td>\n",
       "      <td>No Starch Press</td>\n",
       "      <td>2014-12-14</td>\n",
       "      <td>In Black Hat Python, the latest from Justin Se...</td>\n",
       "      <td>...</td>\n",
       "      <td>SAMPLE</td>\n",
       "      <td>False</td>\n",
       "      <td>In Black Hat Python, the latest from Justin Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>4pgQfXQvekcC</td>\n",
       "      <td>INWaThnNbS4</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/4p...</td>\n",
       "      <td>Learning Python</td>\n",
       "      <td>Powerful Object-Oriented Programming</td>\n",
       "      <td>[Mark Lutz]</td>\n",
       "      <td>\"O'Reilly Media, Inc.\"</td>\n",
       "      <td>2013-06-12</td>\n",
       "      <td>Get a comprehensive, in-depth introduction to ...</td>\n",
       "      <td>...</td>\n",
       "      <td>SAMPLE</td>\n",
       "      <td>False</td>\n",
       "      <td>Get a comprehensive, in-depth introduction to ...</td>\n",
       "      <td>46.87</td>\n",
       "      <td>EUR</td>\n",
       "      <td>46.87</td>\n",
       "      <td>EUR</td>\n",
       "      <td>https://play.google.com/store/books/details?id...</td>\n",
       "      <td>[{'finskyOfferType': 1, 'listPrice': {'amountI...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>2ZggjwEACAAJ</td>\n",
       "      <td>fb9LNT4SJpE</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/2Z...</td>\n",
       "      <td>The Hitchhiker's Guide to Python</td>\n",
       "      <td>Best Practices for Development</td>\n",
       "      <td>[Kenneth Reitz, Tanya Schlusser]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>The Hitchhiker's Guide to Python takes the jou...</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>Ready to complete your trek from journeyman to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>books#volume</td>\n",
       "      <td>BP_WAgAAQBAJ</td>\n",
       "      <td>HEj9dFVwArM</td>\n",
       "      <td>https://www.googleapis.com/books/v1/volumes/BP...</td>\n",
       "      <td>Learning Python with Raspberry Pi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Alex Bradbury, Russel Winder, Ben Everard]</td>\n",
       "      <td>John Wiley &amp; Sons</td>\n",
       "      <td>2014-03-10</td>\n",
       "      <td>Explains how to leverage the revolutionary Ras...</td>\n",
       "      <td>...</td>\n",
       "      <td>SAMPLE</td>\n",
       "      <td>False</td>\n",
       "      <td>This approachable book serves as an ideal reso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           kind            id         etag  \\\n",
       "0  books#volume  yijjwAEACAAJ  zp/xhhsKukU   \n",
       "1  books#volume  9MS9BQAAQBAJ  +txFT+aZW0c   \n",
       "2  books#volume  4pgQfXQvekcC  INWaThnNbS4   \n",
       "3  books#volume  2ZggjwEACAAJ  fb9LNT4SJpE   \n",
       "4  books#volume  BP_WAgAAQBAJ  HEj9dFVwArM   \n",
       "\n",
       "                                            selfLink  \\\n",
       "0  https://www.googleapis.com/books/v1/volumes/yi...   \n",
       "1  https://www.googleapis.com/books/v1/volumes/9M...   \n",
       "2  https://www.googleapis.com/books/v1/volumes/4p...   \n",
       "3  https://www.googleapis.com/books/v1/volumes/2Z...   \n",
       "4  https://www.googleapis.com/books/v1/volumes/BP...   \n",
       "\n",
       "                    volumeInfo.title  \\\n",
       "0       Python Data Science Handbook   \n",
       "1                   Black Hat Python   \n",
       "2                    Learning Python   \n",
       "3   The Hitchhiker's Guide to Python   \n",
       "4  Learning Python with Raspberry Pi   \n",
       "\n",
       "                             volumeInfo.subtitle  \\\n",
       "0          Essential Tools for Working with Data   \n",
       "1  Python Programming for Hackers and Pentesters   \n",
       "2           Powerful Object-Oriented Programming   \n",
       "3                 Best Practices for Development   \n",
       "4                                            NaN   \n",
       "\n",
       "                            volumeInfo.authors    volumeInfo.publisher  \\\n",
       "0       [Jacob T. Vanderplas, Jake VanderPlas]          O'Reilly Media   \n",
       "1                               [Justin Seitz]         No Starch Press   \n",
       "2                                  [Mark Lutz]  \"O'Reilly Media, Inc.\"   \n",
       "3             [Kenneth Reitz, Tanya Schlusser]                     NaN   \n",
       "4  [Alex Bradbury, Russel Winder, Ben Everard]       John Wiley & Sons   \n",
       "\n",
       "  volumeInfo.publishedDate                             volumeInfo.description  \\\n",
       "0                     2016  For many researchers, Python is a first-class ...   \n",
       "1               2014-12-14  In Black Hat Python, the latest from Justin Se...   \n",
       "2               2013-06-12  Get a comprehensive, in-depth introduction to ...   \n",
       "3               2016-07-25  The Hitchhiker's Guide to Python takes the jou...   \n",
       "4               2014-03-10  Explains how to leverage the revolutionary Ras...   \n",
       "\n",
       "   ... accessInfo.accessViewStatus  accessInfo.quoteSharingAllowed  \\\n",
       "0  ...                        NONE                           False   \n",
       "1  ...                      SAMPLE                           False   \n",
       "2  ...                      SAMPLE                           False   \n",
       "3  ...                        NONE                           False   \n",
       "4  ...                      SAMPLE                           False   \n",
       "\n",
       "                              searchInfo.textSnippet  \\\n",
       "0  With this handbook, you&#39;ll learn how to us...   \n",
       "1  In Black Hat Python, the latest from Justin Se...   \n",
       "2  Get a comprehensive, in-depth introduction to ...   \n",
       "3  Ready to complete your trek from journeyman to...   \n",
       "4  This approachable book serves as an ideal reso...   \n",
       "\n",
       "   saleInfo.listPrice.amount saleInfo.listPrice.currencyCode  \\\n",
       "0                        NaN                             NaN   \n",
       "1                        NaN                             NaN   \n",
       "2                      46.87                             EUR   \n",
       "3                        NaN                             NaN   \n",
       "4                        NaN                             NaN   \n",
       "\n",
       "  saleInfo.retailPrice.amount  saleInfo.retailPrice.currencyCode  \\\n",
       "0                         NaN                                NaN   \n",
       "1                         NaN                                NaN   \n",
       "2                       46.87                                EUR   \n",
       "3                         NaN                                NaN   \n",
       "4                         NaN                                NaN   \n",
       "\n",
       "                                    saleInfo.buyLink  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  https://play.google.com/store/books/details?id...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                     saleInfo.offers  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [{'finskyOfferType': 1, 'listPrice': {'amountI...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "   accessInfo.pdf.acsTokenLink  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = json_normalize(data[\"items\"])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "snippet:googleapi3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kind': 'books#volumes', 'totalItems': 382}\n",
      "Retrieved 82,it seems like that's it\n"
     ]
    }
   ],
   "source": [
    "allitems = []\n",
    "i = 0\n",
    "while True:\n",
    "    r = requests.get(\"https://www.googleapis.com/\"\n",
    "        \"books/v1/volumes?q=python&maxResults=\"\n",
    "        f\"40&startIndex={i}\")\n",
    "    data = r.json()\n",
    "    if not \"items\" in data:\n",
    "        print(f\"Retrieved {len(allitems)},\"\n",
    "              \"it seems like that's it\")\n",
    "        break\n",
    "    allitems.extend(data[\"items\"])\n",
    "    i+=40\n",
    "d = json_normalize(allitems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "snippet:htmlparse1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n",
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n"
     ]
    }
   ],
   "source": [
    "tree=parse(urlopen(\n",
    "    \"https://cssbook.net/d/eat/index.html\"))\n",
    "\n",
    "# get the restaurant names via XPATH \n",
    "print([e.text_content().strip() for e in \n",
    "       tree.xpath(\"//h3\")])\n",
    "\n",
    "# get the restaurant names via CSS Selector\n",
    "print([e.text_content().strip() for e in\n",
    "       tree.getroot().cssselect(\"h3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "snippet:htmlparse2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending `/text()` to the XPATH gives you exactly the text that is in the element itself, including line-breaks that happen to be in the source code:\n",
      "[' ', '\\n      ', '\\n      ', '\\n    ', ' ', '\\n      ', '\\n      ', '\\n    ', ' ', '\\n      ', '\\n      ', '\\n    ']\n",
      "\n",
      "Using the `text` property of theelements in the list of elements that are matched by the XPATH expression gives you the text of the elements themselves without the line breaks: \n",
      "[' ', ' ', ' ']\n",
      "\n",
      "Using the `text_content()` method instead returns the text of the element *and the text of its children*:\n",
      "['  Pizzeria Roma \\n       Here you can get ... ... \\n       Read the full review here\\n    ', '  Trattoria Napoli \\n       Another restaurant ... ... \\n       Read the full review here\\n    ', '  Curry King \\n       Some description. \\n       Read the full review here\\n    ']\n",
      "\n",
      "The same but using CSS Selectors (note the .getroot() method, because the selectors can only be applied to HTML elements, not to DOM trees): \n",
      "['  Pizzeria Roma \\n       Here you can get ... ... \\n       Read the full review here\\n    ', '  Trattoria Napoli \\n       Another restaurant ... ... \\n       Read the full review here\\n    ', '  Curry King \\n       Some description. \\n       Read the full review here\\n    ']\n"
     ]
    }
   ],
   "source": [
    "# three ways of extracting text\n",
    "print(\"Appending `/text()` to the XPATH gives you \"\n",
    "      \"exactly the text that is in the element \"\n",
    "      \"itself, including line-breaks that happen \"\n",
    "      \"to be in the source code:\" )\n",
    "print(tree.xpath(\n",
    "    \"//div[@class='restaurant']/text()\"))\n",
    "\n",
    "print(\"\\nUsing the `text` property of the\"\n",
    "      \"elements in the list of elements that are \"\n",
    "      \"matched by the XPATH expression gives you \"\n",
    "      \"the text of the elements themselves \"\n",
    "      \"without the line breaks: \")\n",
    "print([e.text for e in tree.xpath(\n",
    "    \"//div[@class='restaurant']\")])\n",
    "\n",
    "print(\"\\nUsing the `text_content()` method \"\n",
    "      \"instead returns the text of the element \"\n",
    "      \"*and the text of its children*:\")\n",
    "print([e.text_content() for e in tree.xpath(\n",
    "    \"//div[@class='restaurant']\")])\n",
    "\n",
    "print(\"\\nThe same but using CSS Selectors (note \"\n",
    "      \"the .getroot() method, because the \"\n",
    "      \"selectors can only be applied to HTML \"\n",
    "      \"elements, not to DOM trees): \")\n",
    "print([e.text_content() for e in\n",
    "       tree.getroot().cssselect(\".restaurant\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "snippet:htmlparse3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'here', 'here']\n",
      "['review0001.html', 'review0002.html', 'review0003.html']\n"
     ]
    }
   ],
   "source": [
    "linkelements = tree.xpath(\"//a\")\n",
    "linktexts = [e.text for e in linkelements]\n",
    "links = [e.attrib[\"href\"] for e in linkelements]\n",
    "\n",
    "print(linktexts)\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "snippet:htmlparse1useragent"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizzeria Roma', 'Trattoria Napoli', 'Curry King']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows \"\n",
    "    \"NT 10.0; Win64; x64; rv:60.0) \"\n",
    "    \"Gecko/20100101 Firefox/60.0\"}\n",
    "\n",
    "htmlsource = requests.get(\n",
    "    \"https://cssbook.net/d/eat/index.html\", \n",
    "    headers = headers).text\n",
    "tree = fromstring(htmlsource)\n",
    "print([e.text_content().strip() for e in \n",
    "       tree.xpath(\"//h3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "snippet:htmltofile"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"test.html\", mode=\"w\") as fo:\n",
    "    fo.write(htmlsource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true,
    "tags": [
     "snippet:createurls"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://reviews.com/?page=1', 'https://reviews.com/?page=2', 'https://reviews.com/?page=3', 'https://reviews.com/?page=4', 'https://reviews.com/?page=5', 'https://reviews.com/?page=6', 'https://reviews.com/?page=7', 'https://reviews.com/?page=8', 'https://reviews.com/?page=9', 'https://reviews.com/?page=10']\n"
     ]
    }
   ],
   "source": [
    "baseurl=\"https://reviews.com/?page=\"\n",
    "tenpages = [f\"{baseurl}{i+1}\" for i in range(10)]\n",
    "print(tenpages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "snippet:crawling"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving all restaurants...\n",
      "[('Pizzeria Roma', 'review0001.html'), ('Trattoria Napoli', 'review0002.html'), ('Curry King', 'review0003.html')]\n",
      "Processing Pizzeria Roma...\n",
      "Downloading https://cssbook.net/d/eat/review0001.html...\n",
      "No more pages found.\n",
      "Processing Trattoria Napoli...\n",
      "Downloading https://cssbook.net/d/eat/review0002.html...\n",
      "No more pages found.\n",
      "Processing Curry King...\n",
      "Downloading https://cssbook.net/d/eat/review0003.html...\n",
      "Processing next page\n",
      "Downloading https://cssbook.net/d/eat/review0003-1.html...\n",
      "Processing next page\n",
      "Downloading https://cssbook.net/d/eat/review0003-2.html...\n",
      "No more pages found.\n",
      "          username                                         reviewtext  rating  \\\n",
      "0     gourmet2536   The best thing to do is ordering a full menu, ...  7.0/10   \n",
      "1        foodie12                          The worst food I ever had!  1.0/10   \n",
      "2    mrsdiningout             If nothing else is open, you can do it.  6.5/10   \n",
      "3        foodie12                               Best Italian in town!  8.6/10   \n",
      "4           smith                                            Love it!  9.0/10   \n",
      "5        foodie12                                             Superb!  9.2/10   \n",
      "6      dontlikeit                       As expected, I didn't like it  4.0/10   \n",
      "7        otherguy                              Try the yoghurt curry!  7.7/10   \n",
      "8           tasty                    We went here for dinner once and  7.0/10   \n",
      "9            anna                I have mixed feeling about this one.  6.2/10   \n",
      "10           hans                                     Not much to say  5.0/10   \n",
      "11        bee1983                                    I am a huge fan!   10/10   \n",
      "12         rhebjf           The service is good, the food not so much  6.5/10   \n",
      "13  foodcritic555                              Once and never again!.  1.0/10   \n",
      "\n",
      "          restaurant  \n",
      "0      Pizzeria Roma  \n",
      "1      Pizzeria Roma  \n",
      "2   Trattoria Napoli  \n",
      "3   Trattoria Napoli  \n",
      "4         Curry King  \n",
      "5         Curry King  \n",
      "6         Curry King  \n",
      "7         Curry King  \n",
      "8         Curry King  \n",
      "9         Curry King  \n",
      "10        Curry King  \n",
      "11        Curry King  \n",
      "12        Curry King  \n",
      "13        Curry King  \n"
     ]
    }
   ],
   "source": [
    "BASEURL = \"https://cssbook.net/d/eat/\"\n",
    "\n",
    "def get_restaurants(url):\n",
    "  \"\"\"takes the URL of an overview page as input\n",
    "  returns a list of (name, link) tuples\"\"\"\n",
    "  tree = parse(urlopen(url))\n",
    "  names = [e.text.strip() for e in \n",
    "    tree.xpath(\"//div[@class='restaurant']/h3\")]\n",
    "  links = [e.attrib[\"href\"] for e in \n",
    "    tree.xpath(\"//div[@class='restaurant']//a\")]\n",
    "  return list(zip(names, links))\n",
    "\n",
    "def get_reviews(url):\n",
    "  \"\"\"yields reviews on the specified page\"\"\"\n",
    "  while True:\n",
    "    print(f\"Downloading {url}...\")\n",
    "    tree = parse(urlopen(url))\n",
    "    names = [e.text.strip() for e in \n",
    "      tree.xpath(\"//div[@class='review']/h3\")]\n",
    "    texts = [e.text.strip() for e in \n",
    "      tree.xpath(\"//div[@class='review']/p\")]\n",
    "    ratings = [e.text.strip() for e in tree.xpath(\n",
    "      \"//div[@class='rating']\")]\n",
    "    for u,txt,rating in zip(names,texts,ratings):\n",
    "      review = {}\n",
    "      review[\"username\"] = u.replace(\"wrote:\",\"\")\n",
    "      review[\"reviewtext\"] = txt\n",
    "      review[\"rating\"] = rating\n",
    "      yield review\n",
    "    bb=tree.xpath(\"//span[@class='backbutton']/a\")\n",
    "    if bb:\n",
    "      print(\"Processing next page\")\n",
    "      url = BASEURL+bb[0].attrib[\"href\"]\n",
    "    else:\n",
    "      print(\"No more pages found.\")\n",
    "      break\n",
    "        \n",
    "print(\"Retrieving all restaurants...\")\n",
    "links = get_restaurants(BASEURL+\"index.html\")\n",
    "print(links)\n",
    "\n",
    "with open(\"reviews.json\", mode = \"w\") as f:\n",
    "    for restaurant, link in links:\n",
    "        print(f\"Processing {restaurant}...\")\n",
    "        for r in get_reviews(BASEURL+link):\n",
    "            r[\"restaurant\"] = restaurant\n",
    "            f.write(json.dumps(r))\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "# You can process the results with pandas\n",
    "# (using lines=True since it\"s one json per line)\n",
    "df = pd.read_json(\"reviews.json\", lines=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "snippet:selenium"
    ]
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(\"https://www.duckduckgo.com\")\n",
    "element = driver.find_element_by_name(\"q\")\n",
    "# also check out other options such as \n",
    "# .find_element_by_xpath\n",
    "# or .find_element_by_css_selector\n",
    "element.send_keys(\"TinTin\")\n",
    "element.send_keys(Keys.RETURN)\n",
    "try:\n",
    "    driver.find_element_by_css_selector(\n",
    "        \"#links a\").click()\n",
    "    # let\"s be cautious and wait 10 seconds\n",
    "    # so that everything is loaded\n",
    "    time.sleep(10)\n",
    "    driver.save_screenshot(\"screenshotTinTin.png\")\n",
    "finally:\n",
    "    # whatever happens, close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "snippet:cookiewall"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Een kudtkoekiewall. Omdat dat moet, van de kudtkoekiewet.\n",
      "There are 318 comments.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.geenstijl.nl/5160019/page\"\n",
    "\n",
    "# circumvent cookie wall by setting a specific\n",
    "# cookie: the key-value pair (cpc: 10)\n",
    "client = requests.session()\n",
    "r = client.get(URL)\n",
    "\n",
    "cookies = client.cookies.items()\n",
    "cookies.append((\"cpc\",\"10\"))\n",
    "response = client.get(URL,cookies=dict(cookies))\n",
    "# end circumvention\n",
    "\n",
    "tree = fromstring(response.text)\n",
    "allcomments = [e.text_content().strip() for e in \n",
    "               tree.cssselect(\".cmt-content\")]\n",
    "print(f\"There are {len(allcomments)} comments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": [
     "snippet:cookiewall2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 318 comments.\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(URL,cookies={\"cpc\": \"10\"})\n",
    "tree = fromstring(r.text)\n",
    "allcomments = [e.text_content().strip() for e in \n",
    "               tree.cssselect(\".cmt-content\")]\n",
    "print(f\"There are {len(allcomments)} comments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "snippet:textrazor"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': False, 'time': 0, 'error': 'Your TextRazor API Key was invalid.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://api.textrazor.com/account/\",\n",
    "  headers={\"x-textrazor-key\": \"SECRET\"}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "snippet:oauth"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please go here and authorize https://github.com/login/oauth//authorize?response_type=code&client_id=1d416a908fd48c411fae&state=awW61RpLrgLiuj6CAvq0rDqFi9fYEl\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste the full redirect URL here: https://example.com/?code=8a63e07489f3285669a5&state=awW61RpLrgLiuj6CAvq0rDqFi9fYEl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"login\":\"vanatteveldt\",\"id\":1736240,\"node_id\":\"MDQ6VXNlcjE3MzYyNDA=\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/1736240?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/vanatteveldt\",\"html_url\":\"https://github.com/vanatteveldt\",\"followers_url\":\"https://api.github.com/users/vanatteveldt/followers\",\"following_url\":\"https://api.github.com/users/vanatteveldt/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/vanatteveldt/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/vanatteveldt/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/vanatteveldt/subscriptions\",\"organizations_url\":\"https://api.github.com/users/vanatteveldt/orgs\",\"repos_url\":\"https://api.github.com/users/vanatteveldt/repos\",\"events_url\":\"https://api.github.com/users/vanatteveldt/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/vanatteveldt/received_events\",\"type\":\"User\",\"site_admin\":false,\"name\":\"Wouter van Atteveldt\",\"company\":\"VU University\",\"blog\":\"\",\"location\":\"Amsterdam\",\"email\":\"wouter@vanatteveldt.com\",\"hireable\":null,\"bio\":null,\"twitter_username\":null,\"public_repos\":98,\"public_gists\":259,\"followers\":80,\"following\":8,\"created_at\":\"2012-05-14T06:10:53Z\",\"updated_at\":\"2021-08-30T20:07:22Z\"}'\n"
     ]
    }
   ],
   "source": [
    "from requests_oauthlib import OAuth2Session\n",
    "\n",
    "client_id = 'xxxx'\n",
    "client_secret = 'xxxx'\n",
    "base_url=\"https://github.com/login/oauth/\"\n",
    "auth_url=f\"{base_url}/authorize\"\n",
    "token_url=f\"{base_url}/access_token\"\n",
    "\n",
    "github = OAuth2Session(client_id)\n",
    "\n",
    "url, state = github.authorization_url(auth_url)\n",
    "print(f\"Please go here and authorize {url}\")\n",
    "\n",
    "# Get auth. verifier code from callback url\n",
    "resp = input(\"Paste the full redirect URL here:\")\n",
    "\n",
    "# Fetch the access token\n",
    "github.fetch_token(token_url, \n",
    "        client_secret=client_secret,\n",
    "        authorization_response=resp)\n",
    "\n",
    "r = github.get(\"https://api.github.com/user\")\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
