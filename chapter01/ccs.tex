\section{The role of computational analysis in the social sciences}
\label{sec:ccs}

The use of computers is nothing new in the social sciences. In fact,
one could argue that some disciplines within the social sciences have
even be early adopters of computational approaches. Take the
gathering and analyzing of large-scale survey data, dating back until
the use of the Hollerith Machine in the 1890 US census. Long before
every scholar had a personal computer on their desk, social scientists
were using punch cards and mainframe computers to deal with such
data. And also if we think of the analysis of \emph{communication}
more specifically, we see attempts to automate content analysis
already in the 1960's \citep[see, e.g.][]{Scharkow2017}.

Yet, something has profundly changed in the last decades. The amount
and kind of data we can collect as well as the computational power we
have access to have increased dramatically. In particular, digital
traces that we leave when communicating online, from access logs to
comments we place, have required new approaches \citep[e.g.,][]{Trilling2017b}. At the same time, better computational
facilities now allow us to ask questions we could not answer before.

\citet{Gonzalez-Bailon2017}, for instance, argued that the
computational analysis of communication now allows us to test theories
that have been formulated a century ago, such as Tarde's theory of
social imitation. And \citet{Salganik2019} tells an impressive
methododoligical story of continuity in showing how new digital
research methods build on and relate to etablished methods such as
surveys and experiments, but offer new possibilities by observing
behavior in new ways.

A frequent misunderstanding, then, about computational approaches is
that they would somehow be a-theoretical. This is probably fueled by
clich\'{e}s coied during ``Big Data''-hype in the 2010's, such as the
infamous saying that in the age of Big Data, correlation is enough \citep{Mayer2013},
but one could not be more wrong: As the work of \cite{Kitchin2014,Kitchin2014data} shows, computational approaches can
be well situated within existing epistemologies.
For the field to advance, computational/empirical and theoretical work should be symbiotic with each informing the other
and with neither superior to the other \cite{margolin19}.
Thus, the computational
scientists' toolbox includes both more data-driven and more
theory-driven techniques; some are more bottom-up and inductive,
others are more top-down and deductive. What matters here, and what is
often overlooked, is in which stage of the research process they are
employed. In other words, both inductive and deductive approaches as
they are distinghuished in more traditional social-science textbooks
\citep[e.g.,][]{Bryman2012} have their equivalent in the computational
social sciences.

Therefore, we suggest to think of the data collection and data
analysis process as a pipeline. To test, for instance, a theoretically
grounded hypothesis about personalization in the news, we could
imagine a pipeline that starts with scraping online news, proceeds
with some natural-language processing techniques such as Named Entity
Recognition, and finally tests whether the mentioning of persons has
an influence on the placement of the stories. We can distinguish here
between parts of the pipeline that are just necessary but not
inherently interesting to us, and parts of the pipeline that answer a
genuinely interesting question. In this example, the inner workings of
the Named Entity Recognition step are not genuinly interesting for us
-- we just need to do it to answer our question.
We do care about how well it works and especially which biases it may have that could affect our substantive outcomes,
but we are not really evaluating any theory on named entitiy recognition here.
We are, however, answering a theoretically
interesting question when we look at the pipeline as a whole,
that is, when we apply the tools in order to tackle a social scientific problem. 
Of course, what is genuinely interesting depends on one's discipline: For a
computational linguist, the inner workings of the named entity recognition
may actually be the interesting part, and our research question just one
possible ``downstream task''.

This distinction is also sometimes referred to as ``building a better
mouse trap'' vs. ``understanding''. For instace, \cite{Breiman2001}
remarked: ``My attitude toward new and/or complicated methods is
pragmatic. Prove that you've got a better mousetrap and I'll buy
it. But the proof had better be concrete and convincing.''
(p.~230).
In contrast, many social scientists are using statistical
models to test theories and to understand social processes: they want
to specically understand how x relates to y, even if y may be better
predcited by another (theoretically uninteresting) variable instead.

This book here is to some extend about both building mouse traps and understanding. When you
are building a supervised machine learning classifier to determine the
topic of each text in a large collection of news articles or
parliamentary speeches, you are building a (better) mouse trap. But as
a social scientist, your work does not stop there. You need to use
the mouse trap to answer some theoretically interesting question.

Actually, we expect that the contents of this book can provide a background that helps you to face the current research challenges in both academia and professional field. On the one hand, the emerging field of Computational Social Science has become one of the most promising areas of knowledge and many universities and research institutes are looking for scholars with this profile.  On the other hand, it is widely known that nowadays the computational skills will increase your job opportunities in private companies, public organizations or ONGs, given the growing interest in data-driven solutions.

When planning this book, we needed to make a couple of tough
choices. We aimed to at least give an introduction to all techniques
that students and scholars that want to computationally analyze
communication probably will be confronted with. Of course, specific --
technical -- literature on techniques such as, for instance, machine
learning can go more in-depth, and the interested student may indeed
want to dive into one or several of the techniques we cover more
deeply. Our goal here is to offer enough working knowledge to apply
these techniques and to know what to look for.  While trying to cover
the breadth of the field without sacrificing too much depth when
covering each technique, we still needed to draw some boundaries. One
technique that some readers may miss is agent-based modeling
(ABM). Arguably, such simulation techniques are an important technique
in the computational social sciences more broadly
\citep{cioffi-revilla2014}, and they have recently been applied to the
analysis of communication as well
\citep{Waldherr2014,Wettstein2020}. Nevertheless, when reviewing the
curricula of current courses teaching the computational analysis of
communication, we found that simulation approaches do not seem to be at the core of
such analyses (yet).  Instead, when looking at the use of compuational
techniques in fields such as journalism studies
\citep[e.g.,][]{Boumans2016}, media studies \citep[e.g.,][]{Rieder2017}, or
the text-as-data movement \citep{Grimmer2013}, we see a core of
techniques that are used all-over again, and that we therefore
included in our book. In partiuclar, besides general data analysis and visualization techniques,
these are techniques for
gathering data such as web scraping or the use of API's; techniques
for dealing with text such as natural language processing and
different ways to turn text into numbers; supervised and unsupervised
machine learning techniques; and network analysis.
