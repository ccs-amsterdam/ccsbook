{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": [
     "snippet:chapter11install"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: scikit-learn in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: pandas in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (1.1.4)\n",
      "Requirement already satisfied: gensim in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: eli5 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: keras in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: attrs>16.0.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (20.3.0)\n",
      "Requirement already satisfied: graphviz in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (0.16)\n",
      "Requirement already satisfied: six in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: scipy in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.5.4)\n",
      "Requirement already satisfied: jinja2 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (2.11.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (0.8.9)\n",
      "Requirement already satisfied: scikit-learn in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: six in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: scipy in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.5.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: scipy in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: pyyaml in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: h5py in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: tqdm in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: joblib in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: click in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: joblib in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: six in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from jinja2->eli5) (1.1.1)\n",
      "Requirement already satisfied: six in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.19.4)\n",
      "Requirement already satisfied: requests in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.25.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.26.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/damian/onderwijs_github/ccsbook/env/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/damian/onderwijs_github/ccsbook/env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk scikit-learn pandas gensim eli5 keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "snippet:chapter11library"
    ]
   },
   "outputs": [],
   "source": [
    "# General packages and dictionary analysis\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import bz2\n",
    "import urllib.request\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# Supervised text classification\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "import eli5\n",
    "from nltk.sentiment import vader\n",
    "\n",
    "# Deep learning with Keras\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Conv1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Topic Modeling\n",
    "from gensim import matutils\n",
    "from gensim.models.ldamodel import LdaModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "snippet:reviewdata"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached file reviewdata.pickle.bz2\n"
     ]
    }
   ],
   "source": [
    "def get_review_data(filename = \"reviewdata.pickle.bz2\", url = \"http://cssbook.net/d/aclImdb_v1.tar.gz\"):\n",
    "    '''\n",
    "    Checks whether review dataset has already been downloaded.\n",
    "    If not, downloads it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        name of cached file\n",
    "    url : string\n",
    "        url of IMDB dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of lists of strings\n",
    "        reviews_train, reviews_test, label_train, label_test\n",
    "    '''\n",
    "\n",
    "    if Path(filename).exists():\n",
    "        print(f\"Using cached file {filename}\")\n",
    "        with bz2.BZ2File(filename, 'r') as f:\n",
    "            reviews_train, reviews_test, label_train, label_test = pickle.load(f)\n",
    "    else:\n",
    "        print(f\"Downloading from {url}\")\n",
    "        fn, _headers = urllib.request.urlretrieve(url, filename=None)\n",
    "        t = tarfile.open(fn, mode=\"r:gz\")\n",
    "        reviews_train, reviews_test, label_train, label_test = [], [], [], []\n",
    "        for file in t.getmembers():\n",
    "            try:\n",
    "                _imdb, dataset, label, _fn = Path(file.name).parts\n",
    "            except ValueError:\n",
    "                # if the Path cannot be parsed, e.g. because it does not consist of exactly four parts, then it is not a part of the dataset but for instance a folder name. Let's skip it then\n",
    "                continue\n",
    "            if dataset == \"train\" and (label=='pos' or label=='neg'):\n",
    "                reviews_train.append(t.extractfile(file).read().decode(\"utf-8\"))\n",
    "                label_train.append(label)\n",
    "            elif dataset == \"test\" and (label=='pos' or label=='neg'):\n",
    "                reviews_test.append(t.extractfile(file).read().decode(\"utf-8\"))\n",
    "                label_test.append(label)\n",
    "        print(f\"Saving {len(label_train)} training and {len(label_test)} test cases to {filename}\")\n",
    "        with bz2.BZ2File(filename, 'w') as f:\n",
    "            pickle.dump((reviews_train, reviews_test, label_train, label_test), f)\n",
    "    return reviews_train, reviews_test, label_train, label_test\n",
    "\n",
    "reviews_train, reviews_test, y_train, y_test = get_review_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "snippet:sentsimple"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3,\n",
       " -4,\n",
       " 1,\n",
       " 3,\n",
       " -2,\n",
       " -7,\n",
       " -6,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 5,\n",
       " -1,\n",
       " 2,\n",
       " 7,\n",
       " -4,\n",
       " 2,\n",
       " 21,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " -3,\n",
       " -2,\n",
       " -11,\n",
       " -2,\n",
       " -3,\n",
       " -7,\n",
       " 2,\n",
       " 4,\n",
       " -22,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " -5,\n",
       " -8,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " -4,\n",
       " 3,\n",
       " -7,\n",
       " -11,\n",
       " -6,\n",
       " 0,\n",
       " 3,\n",
       " -1,\n",
       " 0,\n",
       " 6,\n",
       " -1,\n",
       " -8,\n",
       " 7,\n",
       " -5,\n",
       " 2,\n",
       " 10,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " -8,\n",
       " 4,\n",
       " 3,\n",
       " 18,\n",
       " 2,\n",
       " 0,\n",
       " -3,\n",
       " -2,\n",
       " 5,\n",
       " 0,\n",
       " -2,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " -3,\n",
       " -4,\n",
       " -6,\n",
       " -2,\n",
       " 2,\n",
       " -7,\n",
       " -1,\n",
       " -10,\n",
       " -5,\n",
       " 3,\n",
       " 4,\n",
       " -3,\n",
       " -17,\n",
       " 1,\n",
       " -1,\n",
       " 7,\n",
       " -3,\n",
       " 4,\n",
       " 12,\n",
       " 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = set(requests.get('http://cssbook.net/d/positive.txt').text.split('\\n'))\n",
    "negative = set(requests.get('http://cssbook.net/d/negative.txt').text.split('\\n'))\n",
    "sentimentdict = {word:+1 for word in positive}\n",
    "sentimentdict.update({word:-1 for word in negative})\n",
    "\n",
    "scores = []\n",
    "mytokenizer = TreebankWordTokenizer()\n",
    "# we only take the first 100 reviews to speed things up\n",
    "for review in reviews_train[:100]:\n",
    "    words = mytokenizer.tokenize(review)\n",
    "    # we look up each word in the sentiment dict and assign its value (if we don't find it, it gets 0)\n",
    "    scores.append(sum(sentimentdict.get(word,0) for word in words))\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
