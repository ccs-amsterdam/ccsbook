{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": [
     "snippet:chapter11install"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/wva/ccsbook/env/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: scikit-learn in /home/wva/ccsbook/env/lib/python3.8/site-packages (0.24.2)\n",
      "Requirement already satisfied: pandas in /home/wva/ccsbook/env/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: click in /home/wva/ccsbook/env/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /home/wva/ccsbook/env/lib/python3.8/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: tqdm in /home/wva/ccsbook/env/lib/python3.8/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: joblib in /home/wva/ccsbook/env/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from scikit-learn) (1.7.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: gensim in /home/wva/ccsbook/env/lib/python3.8/site-packages (4.0.1)\n",
      "Requirement already satisfied: eli5 in /home/wva/ccsbook/env/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: keras in /home/wva/ccsbook/env/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: tensorflow in /home/wva/ccsbook/env/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from gensim) (1.7.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from gensim) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: six in /home/wva/ccsbook/env/lib/python3.8/site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: graphviz in /home/wva/ccsbook/env/lib/python3.8/site-packages (from eli5) (0.16)\n",
      "Requirement already satisfied: jinja2 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from eli5) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from eli5) (0.24.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from eli5) (0.8.9)\n",
      "Requirement already satisfied: attrs>16.0.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from eli5) (21.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from scikit-learn>=0.20->eli5) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
      "Requirement already satisfied: pyyaml in /home/wva/ccsbook/env/lib/python3.8/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: h5py in /home/wva/ccsbook/env/lib/python3.8/site-packages (from keras) (3.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (44.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (1.32.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wva/ccsbook/env/lib/python3.8/site-packages (from jinja2->eli5) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk scikit-learn pandas \n",
    "!pip3 install gensim eli5 keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "snippet:chapter11library"
    ]
   },
   "outputs": [],
   "source": [
    "# General packages and dictionary analysis\n",
    "import os\n",
    "import tarfile\n",
    "import bz2\n",
    "import urllib.request\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supervised text classification\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, TfidfVectorizer)\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import (\n",
    "    make_pipeline, Pipeline)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "import eli5\n",
    "from nltk.sentiment import vader\n",
    "\n",
    "# Deep learning with Keras\n",
    "from keras.layers import (Dense, Input, \n",
    "    GlobalMaxPooling1D, Conv1D, Embedding)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.sequence import (\n",
    "    pad_sequences)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models.keyedvectors import (\n",
    "    KeyedVectors)\n",
    "\n",
    "# Topic Modeling\n",
    "from gensim import matutils\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import (\n",
    "    CoherenceModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "snippet:reviewdata"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://cssbook.net/d/aclImdb_v1.tar.gz\n",
      "Saving to reviewdata.pickle.bz2\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "filename = \"reviewdata.pickle.bz2\"\n",
    "if os.path.exists(filename):\n",
    "  print(f\"Using cached file {filename}\")\n",
    "  with bz2.BZ2File(filename, \"r\") as zipfile:\n",
    "    data = pickle.load(zipfile)\n",
    "    text_train, text_test, y_train, y_test = data\n",
    "else:\n",
    "  url = \"https://cssbook.net/d/aclImdb_v1.tar.gz\"\n",
    "  print(f\"Downloading from {url}\")\n",
    "  fn, _headers = urllib.request.urlretrieve(url, \n",
    "                     filename=None)\n",
    "  t = tarfile.open(fn, mode=\"r:gz\")\n",
    "  text_train,text_test = [], []\n",
    "  y_train, y_test = [], []\n",
    "  for f in t.getmembers():\n",
    "    m=re.match(\"aclImdb/(\\w+)/(pos|neg)/\", f.name)\n",
    "    if not m:\n",
    "        # skip folder names, other categories\n",
    "        continue\n",
    "    dataset, label = m.groups()\n",
    "    text = t.extractfile(f).read().decode(\"utf-8\")\n",
    "    if dataset == \"train\":\n",
    "      text_train.append(text)\n",
    "      y_train.append(label)\n",
    "    elif dataset == \"test\":\n",
    "      text_test.append(text)\n",
    "      y_test.append(label)\n",
    "  print(f\"Saving to {filename}\")\n",
    "  with bz2.BZ2File(filename, \"w\") as zipfile:\n",
    "    data = text_train, text_test, y_train, y_test\n",
    "    pickle.dump(data, zipfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "snippet:sentsimple"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3,\n",
       " -4,\n",
       " 1,\n",
       " 3,\n",
       " -2,\n",
       " -7,\n",
       " -6,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 5,\n",
       " -1,\n",
       " 2,\n",
       " 7,\n",
       " -4,\n",
       " 2,\n",
       " 21,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " -3,\n",
       " -2,\n",
       " -11,\n",
       " -2,\n",
       " -3,\n",
       " -7,\n",
       " 2,\n",
       " 4,\n",
       " -22,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " -5,\n",
       " -8,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " -4,\n",
       " 3,\n",
       " -7,\n",
       " -11,\n",
       " -6,\n",
       " 0,\n",
       " 3,\n",
       " -1,\n",
       " 0,\n",
       " 6,\n",
       " -1,\n",
       " -8,\n",
       " 7,\n",
       " -5,\n",
       " 2,\n",
       " 10,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " -8,\n",
       " 4,\n",
       " 3,\n",
       " 18,\n",
       " 2,\n",
       " 0,\n",
       " -3,\n",
       " -2,\n",
       " 5,\n",
       " 0,\n",
       " -2,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " -3,\n",
       " -4,\n",
       " -6,\n",
       " -2,\n",
       " 2,\n",
       " -7,\n",
       " -1,\n",
       " -10,\n",
       " -5,\n",
       " 3,\n",
       " 4,\n",
       " -3,\n",
       " -17,\n",
       " 1,\n",
       " -1,\n",
       " 7,\n",
       " -3,\n",
       " 4,\n",
       " 12,\n",
       " 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poswords = \"https://cssbook.net/d/positive.txt\"\n",
    "negwords = \"https://cssbook.net/d/negative.txt\"\n",
    "pos = set(requests.get(poswords).text.split(\"\\n\"))\n",
    "neg = set(requests.get(negwords).text.split(\"\\n\"))\n",
    "sentimentdict = {word:+1 for word in pos}\n",
    "sentimentdict.update({word:-1 for word in neg})\n",
    "\n",
    "scores = []\n",
    "mytokenizer = TreebankWordTokenizer()\n",
    "# For speed, we only take the first 100 reviews\n",
    "for review in text_train[:100]:\n",
    "    words = mytokenizer.tokenize(review)\n",
    "    # we look up each word in the sentiment dict \n",
    "    # and assign its value (with default 0)\n",
    "    scores.append(sum(sentimentdict.get(word,0) \n",
    "                      for word in words))\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
