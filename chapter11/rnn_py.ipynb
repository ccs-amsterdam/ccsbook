{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wva/ccsbook/env/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import (Dense, Input, \n",
    "    GlobalMaxPooling1D, Conv1D, Embedding)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.sequence import (\n",
    "    pad_sequences)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from gensim.models.keyedvectors import (\n",
    "    KeyedVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "snippet:rnndata",
     "output:table"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>lemmata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10007</td>\n",
       "      <td>0</td>\n",
       "      <td>Rabobank voorspellen flink stijging hypotheekr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027</td>\n",
       "      <td>0</td>\n",
       "      <td>D66 willen reserve provincie aanspreken voor g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10037</td>\n",
       "      <td>1</td>\n",
       "      <td>UWV dit jaar veel baan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10059</td>\n",
       "      <td>1</td>\n",
       "      <td>proost op geslaagd beursgang bols</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10099</td>\n",
       "      <td>0</td>\n",
       "      <td>helft werknemer gaan na 65ste met pensioen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  value                                            lemmata\n",
       "0  10007      0  Rabobank voorspellen flink stijging hypotheekr...\n",
       "1  10027      0  D66 willen reserve provincie aanspreken voor g...\n",
       "2  10037      1                             UWV dit jaar veel baan\n",
       "3  10059      1                  proost op geslaagd beursgang bols\n",
       "4  10099      0         helft werknemer gaan na 65ste met pensioen"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://cssbook.net/d/dutch_sentiment.csv\"\n",
    "h = pd.read_csv(url)\n",
    "h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "snippet:rnnmodel"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RNN model\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1000, 320)         2176640   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 998, 128)          123008    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,307,969\n",
      "Trainable params: 2,307,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tokenize texts\n",
    "tokenizer=Tokenizer(num_words=9999)\n",
    "tokenizer.fit_on_texts(h.lemmata)\n",
    "word_index=tokenizer.word_index\n",
    "sequences=tokenizer.texts_to_sequences(h.lemmata)\n",
    "tokens=pad_sequences(sequences, maxlen=1000)\n",
    "\n",
    "# Prepare embeddings layer\n",
    "fn = \"w2v_320d_trimmed\"\n",
    "if not os.path.exists(fn):\n",
    "    url = f\"https://cssbook.net/d/{fn}\"\n",
    "    print(f\"Downloading embeddings from {url}\")\n",
    "    urllib.request.urlretrieve(url, fn)\n",
    "embeddings = KeyedVectors.load_word2vec_format(fn)\n",
    "emb_matrix = np.zeros(\n",
    "    (len(tokenizer.word_index) + 1, \n",
    "     embeddings.vector_size))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in embeddings:\n",
    "        emb_matrix[i] = embeddings[word]\n",
    "embedding_layer = Embedding(\n",
    "    emb_matrix.shape[0], emb_matrix.shape[1],\n",
    "    input_length=tokens.shape[1], trainable=True,\n",
    "    weights=[emb_matrix])\n",
    "    \n",
    "print(\"Building RNN model\")\n",
    "sequence_input = Input(shape=(tokens.shape[1],), \n",
    "                       dtype=\"int32\")\n",
    "seq = embedding_layer(sequence_input)\n",
    "m = Conv1D(filters=128, kernel_size=3,\n",
    "           activation=\"relu\")(seq)\n",
    "m = GlobalMaxPooling1D()(m)\n",
    "m = Dense(64, activation=\"relu\")(m)\n",
    "preds = Dense(1, activation=\"tanh\")(m)\n",
    "m = Model(sequence_input, preds)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "snippet:rnn"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "32/32 [==============================] - 27s 828ms/step - loss: 0.6807\n",
      "Validate against test data\n",
      "Accuracy: 0.46468561584840656\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_data = tokens[:4000]\n",
    "test_data = tokens[4000:]\n",
    "train_labels = h.value[:4000]\n",
    "test_labels = h.value[4000:]\n",
    "\n",
    "# Train model\n",
    "m.compile(loss=\"mean_absolute_error\", \n",
    "          optimizer=RMSprop(lr=.004))\n",
    "labels = np.asarray([[x] for x in train_labels])\n",
    "m.fit(train_data,labels,epochs=5,batch_size=128)\n",
    "\n",
    "# Validate against test data\n",
    "output = m.predict(test_data)\n",
    "# Bin output into -1, 0, 1\n",
    "pred=[1 if x[0]>.3 else (0 if x[0]>-.3 else -1) \n",
    "      for x in output]\n",
    "correct=[x==y for (x,y) in zip(pred,test_labels)]\n",
    "acc = sum(correct) / len(pred)\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
