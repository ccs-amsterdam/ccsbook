{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "snippet:listvsdict"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# A list with multiple values\n",
    "mylist = [4, 6, 3, 9]\n",
    "\n",
    "# A dict with one value per key\n",
    "mydict = {'Anna': 40, 'Peter': 33, 'Sarah': 40, 'Kees': 70}\n",
    "\n",
    "# A nested dict\n",
    "mydict = {'Anna': {'street': 'Herengracht', 'city': 'Amsterdam'}, 'Peter': {'street': 'Unter den Linden', 'city': 'Berlin'} }\n",
    "\n",
    "\n",
    "print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "snippet:createdataframe"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "      0     1\n",
      "0  True  True\n",
      "1  True  True\n",
      "2  True  True\n",
      "3  True  True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create two lists that will be columns\n",
    "list1 = ['Anna', 'Peter', 'Sarah', 'Kees']\n",
    "list2 = [40, 33, 40, 77]\n",
    "\n",
    "# or we could have a list of lists instead\n",
    "mytable = [['Anna', 40],\n",
    "           ['Peter', 33],\n",
    "           ['Sarah', 40],\n",
    "           ['Kees', 77]]\n",
    "\n",
    "# In fact, we could also create it automatically\n",
    "mytable2 = [[u,v] for u, v in zip(list1, list2)]\n",
    "\n",
    "# If you don't believe us, check whether they are the same:\n",
    "print(mytable2 == mytable)\n",
    "\n",
    "\n",
    "# We can convert this array to a dataframe...\n",
    "df1=pd.DataFrame(mytable)\n",
    "\n",
    "# ... or create the data frame directly from the vectors\n",
    "df2=pd.DataFrame.from_records(zip(list1,list2))\n",
    "\n",
    "print(df1 == df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": [
     "snippet:readfiles"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE NEED TO CHECK THAT ALL THESE TEST FILES ARE AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# If the csv file looks like pandas expects it, this simple command works:\n",
    "df = pd.read_csv('../datasets/mediause.csv')\n",
    "\n",
    "# But we can also explicitly specify the encoding, delimiters, and so on\n",
    "# (which is what we should do if we know it):\n",
    "df = pd.read_csv('../datasets/mediause.csv', encoding = 'utf-8', delimiter = ';')\n",
    "\n",
    "# There are many other options you could specifiy (for instance, whether your\n",
    "# data have a header row. Just enter pd.read_csv? to get an overview.\n",
    "\n",
    "# Similarily, we can also read other files. Use tab completion (type pd.read and then press TAB)\n",
    "# to get a list of all supported files. For instance:\n",
    "\n",
    "#df2 = pd.read_excel('test.xlsx')\n",
    "\n",
    "#df3 = pd.read_stata('test.dta')\n",
    "\n",
    "#df4 = pd.read_json('test.json')\n",
    "\n",
    "# Writing a dataframe to a file is easy: If we want to save\n",
    "# df3 (which we read from a stata file) as a csv, we can\n",
    "# simply do:\n",
    "\n",
    "# df3.to_csv('mynewfile.csv')\n",
    "\n",
    "# again, we can specify encodings, delimiter, and so on, or\n",
    "# use other file formats using .to_excel etc.\n",
    "\n",
    "print('WE NEED TO CHECK THAT ALL THESE TEST FILES ARE AVAILABLE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "snippet:stopwords"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# bad: define stopword list in the code itself\n",
    "stopwords_in_code = ['and', 'or', 'a', 'an', 'the']\n",
    "\n",
    "# good: read stopword list from external text file\n",
    "stopwords_from_file =  [f.strip() for f in open('../datasets/stopwords.txt').readlines()]\n",
    "print(stopwords_in_code == stopwords_from_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": [
     "snippet:stopwordsextensive"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "with open('../datasets/stopwords.txt', mode = 'r', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        stopwords.append(line.strip())\n",
    "\n",
    "# The \\texttt{mode = 'r'} specifies that we want to read from the file. \\texttt{mode = 'w'} would open the file for writing, create it if necessary, and immediately deletes all content that may have been in there if the file already existed (!).\n",
    "\n",
    "# Note that the \\texttt{.strip()} is necessary to remove the line ending itself, and also possible whitespace at the beginning or end of a line.\n",
    "\n",
    "# If we wanted to save our stopwords, we could do this as follows: \n",
    "\n",
    "with open('newstopwords.txt', mode = 'w', encoding = 'utf-8') as f:\n",
    "    f.writelines(stopwords)\n",
    "\n",
    "# We can use the same to read json files into a python dict or to store a python dict into a json file:\n",
    "\n",
    "\n",
    "# import json\n",
    "\n",
    "# with open('test.json', mode = 'r', encoding = 'utf-8') as f:\n",
    "#    mydict = json.load(f)\n",
    "\n",
    "#with open('test2.json', mode = 'w', encoding = 'utf-8') as f:\n",
    "#    json.dump(mydict, f)\n",
    "\n",
    "\n",
    "\n",
    "             \n",
    "# We could also combine this with a for loop that goes over all files in a dictionary.\n",
    "# Imagine we have a folder full of positive movie reviews, and another one full of negative movie reviews that we want to use to train a machine learning classifier (see CHAPTERXXXXXXXXXX). Let's further assume that all these reviews are saved as \\texttt{.txt} files:\n",
    "\n",
    "# We could read them as follows into a list of strings:\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "positivereviews = []\n",
    "\n",
    "for fn in glob('/path/to/positive/reviews/*.txt'):\n",
    "    with open(fn, mode='r', encoding='utf-8') as f:\n",
    "        positivereviews.append(f.read())\n",
    "\n",
    "\n",
    "# And then do the same for negative reviews.\n",
    "\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
