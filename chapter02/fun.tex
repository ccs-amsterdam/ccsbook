\section{Fun with tweets}

The goal of this chapter is to showcase how you can use R or Python to quickly and easily
run some impressive analyses of real world data.
For this purpose, we will be using a data set of tweets about the COVID pandemic that is
engulfing much of the world at the time this book is written.
Of course, tweets are probably only representative for what is said on Twitter,
but the data are (semi-)public and rich, containing text, location, and network characteristics.
This makes them ideal for exploring the many ways in which we can analyze and visualize information
with Python and R. 

\refex{funtweets} shows how you can read this data set into memory using a single command.
Note that this does not retrieve the tweets from Twitter itself, but rather downloads
our cached version of the tweets.
In \refchap{scraping} we will show how you can download tweets and location data yourself, but to make sure
we can get down to business immediately we will start from this cached version. 

\begin{ccsexample}
  \doublecodex{chapter02/tweets}
\codex[caption=Output]{chapter02/tweetsb.r.out}
\caption{Retrieving cached tweets about COVID}\label{ex:funtweets}
\end{ccsexample}

As you can see, the dataset contains almost ten thousand tweets, listing their
sender, their location and language, the text, the number of retweets, and whether it was a reply (retweet).
You can read the start of the three most retweeted messages, which contain one (political) tweet from India
and two seemingly political and factual tweets from the United States.

\paragraph{My first bar plot} Before diving into the textual, network, and geographic data in the data set,
let's first make a simple visualization of the date at which the tweets are posted.
\refex{funtime} does this in two steps:
First, the number of tweets per hour is counted with an aggregation command.
Next, a bar plot is made of this calculated value with some options to make it look relatively clean and professional.
If you want to play around with this, you can for example try to plot the amount of tweets per language,
or create a line plot instead of a bar plot. 
For more information on visualization, please see \refchap{eda}.
See \refchap{datawrangling} for an in-depth explanation of the aggregation command. 

\pyrex[caption=Barplot of tweets over time,input=both,output=r,format=png]{chapter02/funtime}

\section{Fun with textual data}

\paragraph{Corpus Analysis} Next, we can analyze which hash tags are most frequently used in this data set.
\refex{funcloud} does this by creating a \concept{document-term matrix} using the package \pkg{quanteda} (in R)
or \sklearn (in Python).
The code shows a number of steps that are made to create the final results, each of which represent
researcher choices about which data to keep and what to discard as noise.
In this case,  we select English tweets, convert text to lower case, remove stop words, and keep only words that start with \#,
while dropping words starting with \verb+#corona+ and \verb+#covid+.
To play around with this example,
see if you can adjust the code to e.g. include all words or only at-mentions instead of the hash tags
and make a different selection of tweets, for example Spanish language tweets or only popular (retweeted) tweets.
Please see \refchap{dtm} if you want to learn more about corpus analysis,
and see \refchap{datawrangling} for more information on how to select subsets of your data.

\pyrex[caption=My First Tag Cloud,input=both,output=r,format=png]{chapter02/funcloud}

\paragraph{Topic Model}
Where a word cloud (or tag cloud) shows which words occur most frequently,
a \concept{topic model} analysis shows which words co-occur in the same documents.
Using the most common topic modeling algorithm, Latent Dirichlet Allocation or LDA,
\refex{funlda} explores the tweets by automatically clustering the tags selected earlier into 10 \emph{topics}.
Topic modeling is non-deterministic -- if you run it again you can get slightly different topics,
and topics are swapped around randomly as the topic numbers have no special meaning.
By setting the computer's \concept{random seed} you can ensure that if you run it again you get the same results.
As you can see, some topics seem easily interpretable (such as topic 6 about economic consequences,
and topic 7 about masks and prevention), it is always recommended to inspect the clustered documents
and edge cases in addition to the top words (or tags) as shown here.
You can play around with this example, for example by using a different selection of words
(modifying the code in \refex{funcloud}) or changing the number of topics.
You can also change (or remove) the random seed and see how running the same model multiple times give different results. 
See \refsec{unsupervised} for more information about fitting, interpreting, and validating topic models.

\pyrex[caption=Topic Model of the COVID tags,input=both,output=r,format=table]{chapter02/funlda}

\section{Fun with visualizing geographic information}
For the final set of examples, we will use the location information contained in the twitter data.
This information is based on what twitter users enter into their profile, and as such it is incomplete and noisy
with many users giving a nonsensical location such as `Ethereally here' or not filling in any location at all.
However, if we assume that most users that do enter a proper location (such as Lahore or Florida in the top tweets displayed above),
we can use it to map where most tweets are coming from.

The first step in this analysis is to resolve a name such as `Lahore, Pakistan' to its geographical coordinates (in this case, about 31 degrees north and 74 degrees east). This is called geocoding, and both Google maps and Open Street Maps can be used
to perform this automatically.
As with the tweets themselves, we will use a cached version of the geocoding results here so we can proceed directly.
At the end of this chapter we will show the code that was used to create this file so you can play around with it as well. 

\refex{funmap} shows how this data can be used to create a map of twitter activity.
First, the cached user data is retrieved, showing the correct location for Lahore but also
illustrating the noisiness of the data with the location `Un peu partout'.
Next, this data is \concept[joining]{joined} to the twitter data, so the coorinates are filled in where known.
Finally, we plot this information on a map, showing tweets with more retweets as larger dots.
See \refchap{eda} for more information on visualization.

\pyrex[caption=Location of COVID tweets,input=both,output=r,format=png]{chapter02/funmap}


\paragraph{Combining textual and structured information}
Since we know the location of a subset of our tweet's users,
we can differentiate between e.g. American, European, and Asian tweets.
\refex{funcompare} creates a very rough identification of North American tweets,
and uses that to compute the relative frequency of words in those tweets compared to the rest.
Not surprisingly, those tweets are much more about American politics, locations, and institutions.
The other tweets talk about UK politics but also use a variety of names to refer to the pandemic.
To play around with this, see if you can isolate e.g. Asian or South American tweets,
or compare Spanish tweets from different locations.

\pyrex[caption=Corpus comparison: North American tweets vs. the rest,input=both,output=r,format=png]{chapter02/funcompare}

% TODO CITE THIS FOR PYTHON EXAMPLE? Gallagher, R. J., Frank, M. R., Mitchell, Lewis, Schwartz, A. J., Reagan, A. J., Danforth, C. M., Dodds, P. S.. (2020). Generalized Word Shift Graphs: A Method for Visualizing and Explaining Pairwise Comparisons Between Texts. arXiv preprint 2008.02250.

\section{Fun with networks}

Twitter, of course, is a social network as well as a microblogging service:
users are connected to other users because they follow each other and retweet and like each others' tweets.
Using the \verb+reply_to_screen_name+ column, we can inspect the retweet network contained in the COVID tweet data set.
\refex{fungraph} first uses the data summarization commands from \tidyverse\ (R) and \pandas\ (Python) to
create a data frame of connections or \concept{edges} listing how often each user retweets each other user.
The second code block shows how the \pkg{igraph} package is used to convert this edge list into a graph.
From this graph, we select only the largest connected component and use a clustering algorithm to analyze which
nodes (users) form cohesive subnetworks.
Finally, a number of options are used to set the color and size of the edges, nodes, and labels,
and the resulting network is plotted.
As you can see, the central node is Donald Trump, who is retweeted by a large number of users,
some of which are then retweeted by other users.
You can play around with different settings for the plot options,
or try to filter e.g. only tweets from a certain language. 
You could also easily compute social network metrics such as centrality on this network,
and/or export the network for further analysis in specialized social network analysis software.
See \refchap{network} for more information on network analysis,
and \refchap{datawrangling} for the summarization commands used to create the edge list.

\begin{ccsexample}
  \doublecodex{chapter02/fungraph}
  \codexoutputtable{chapter02/fungraph.r}
  \doublecodex{chapter02/fungraphb}
  \codexoutputpng{chapter02/fungraphb.r}
\caption{Retweet nework in the COVID tweets}\label{ex:fungraph}
\end{ccsexample}

\paragraph{Geographic networks}
In the final example of this chapter, we will combine the geographic and network information to
show which regions of the world interact with each other.
For this, in \refex{fungeonet} we join the user information to the edges data frame created above twice:
once for the sender, once for the replied-to user.
Then, we adapt the earlier code for plotting the map by adding a line for each node in the network.
As you can see, users in the main regions (US, EU, India) mostly interact with each other,
with almost all regions also interacting with the US.

\pyrex[caption=Reply Network of Tweets,output=r,format=png]{chapter02/fungeonet}
