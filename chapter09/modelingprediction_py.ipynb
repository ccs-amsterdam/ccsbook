{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "snippet:ols"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -0.089560\n",
       "age          0.067620\n",
       "gender       0.176665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "df = pd.read_csv('http://cssbook.net/d/mediause.csv')\n",
    "model = smf.ols(formula = 'newspaper ~ age + gender', data = df).fit()\n",
    "# model.summary() would give a lot more info, but we only care about the coefficients:\n",
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "snippet:olspredict"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.439508\n",
       "1    2.615248\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = pd.DataFrame([{'gender':1, 'age':20}, {'gender': 0, 'age':40} ])\n",
    "model.predict(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "snippet:preparedata"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many people used online news at all?\n",
      "user        1262\n",
      "non-user     803\n",
      "Name: uses-internet, dtype: int64\n",
      "We have 1652 training and 413 test cases.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('http://cssbook.net/d/mediause.csv')\n",
    "\n",
    "df['uses-internet'] = (df['internet']>0).replace({True:'user', False:'non-user'})\n",
    "df.dropna(inplace=True)\n",
    "print(\"How many people used online news at all?\")\n",
    "print(df['uses-internet'].value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['age', 'education', 'gender']], df['uses-internet'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'We have {len(X_train)} training and {len(X_test)} test cases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "snippet:nb"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "myclassifier = GaussianNB()\n",
    "myclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = myclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "snippet:classificationreport"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 55 106]\n",
      " [ 40 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-user       0.58      0.34      0.43       161\n",
      "        user       0.67      0.84      0.74       252\n",
      "\n",
      "    accuracy                           0.65       413\n",
      "   macro avg       0.62      0.59      0.59       413\n",
      "weighted avg       0.63      0.65      0.62       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "snippet:logreg"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "myclassifier = LogisticRegression(solver='lbfgs')\n",
    "myclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = myclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "snippet:svm"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# !!! We normalize our features to have M = 0 and SD = 1\n",
    "# This is necessary as our features are not measured on the same scale, which SVM requires\n",
    "# It may also be OK to rescale to a range of [0:1] or [-1:1]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "myclassifier = SVC(gamma='scale')\n",
    "myclassifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = myclassifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "snippet:randomforest"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "myclassifier = RandomForestClassifier(n_estimators=100)\n",
    "myclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = myclassifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "snippet:cutoffpoint"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With default cutoff point (.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-user       0.58      0.37      0.45       161\n",
      "        user       0.67      0.83      0.74       252\n",
      "\n",
      "    accuracy                           0.65       413\n",
      "   macro avg       0.63      0.60      0.60       413\n",
      "weighted avg       0.64      0.65      0.63       413\n",
      "\n",
      "[[ 59 102]\n",
      " [ 42 210]]\n",
      "\n",
      "With the optimal probability threshold is -0.3880564601305959, which is equivalent to a cutoff of 0.6783740410958884, we get:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-user       0.50      0.80      0.61       161\n",
      "        user       0.79      0.49      0.61       252\n",
      "\n",
      "    accuracy                           0.61       413\n",
      "   macro avg       0.64      0.64      0.61       413\n",
      "weighted avg       0.68      0.61      0.61       413\n",
      "\n",
      "[[128  33]\n",
      " [128 124]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "myclassifier = LogisticRegression(solver='lbfgs')\n",
    "myclassifier.fit(X_train, y_train)\n",
    "\n",
    "print('With default cutoff point (.5):')\n",
    "y_pred = myclassifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# get all predicted probabilities\n",
    "predprobs = myclassifier.predict_log_proba(X_test)\n",
    "\n",
    "fpr,tpr, thresholds = roc_curve(y_test, predprobs[:,1], pos_label='user')\n",
    "\n",
    "# You can uncomment the following lines to print a table,\n",
    "# determine a False Positive/True Positive combination\n",
    "# you like, and take that cutoff from the third column\n",
    "# and the threshold (which is its logarithm) from the\n",
    "# forth column\n",
    "\n",
    "#print(\"False Positive Rate\\tTrue Positive Rate\\tCutoff\\tThreshold\")\n",
    "#for f, t, th in zip(fpr,tpr, thresholds):\n",
    "#    print('{}\\t{}\\t{}'.format(f,t,np.exp(th)),th)\n",
    "\n",
    "# or, choose the cutoff point where the difference between \n",
    "# False Positive Rate and True Positive Rate is maximal\n",
    "\n",
    "optimal_threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "\n",
    "print(f\"\\nWith the optimal probability threshold is {optimal_threshold}, which is equivalent to a cutoff of {np.exp(optimal_threshold)}, we get:\")\n",
    "y_pred_alternative = np.where(predprobs[:,1] > optimal_threshold, 'user', 'non-user')\n",
    "print(classification_report(y_test, y_pred_alternative))\n",
    "print(confusion_matrix(y_test, y_pred_alternative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "snippet:crossval"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64652568 0.64048338 0.62727273 0.64242424 0.63636364]\n",
      "M = 0.64, SD = 0.007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "myclassifier = LogisticRegression(solver='lbfgs')\n",
    "accuracy = cross_val_score(estimator=myclassifier, X=X_train, y=y_train, scoring='accuracy', cv=5)\n",
    "print(accuracy)\n",
    "print(f\"M = {accuracy.mean():.2f}, SD = {accuracy.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09304265 0.13409553 0.06261019 0.05477517 0.07530192]\n",
      "M = 0.08, SD = 0.028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer, f1_score\n",
    "f1scores = cross_val_score(estimator=myclassifier, X=X_train, y=y_train, scoring=make_scorer(cohen_kappa_score), cv=5)\n",
    "print(f1scores)\n",
    "print(f\"M = {f1scores.mean():.2f}, SD = {f1scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "snippet:gridsearch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using these hyperparameters {'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 50}, we get the best performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-user       0.41      0.37      0.39       161\n",
      "        user       0.62      0.66      0.64       252\n",
      "\n",
      "    accuracy                           0.54       413\n",
      "   macro avg       0.51      0.51      0.51       413\n",
      "weighted avg       0.54      0.54      0.54       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "myclassifier = RandomForestClassifier()\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"user\")\n",
    "\n",
    "grid = {\n",
    "    'n_estimators' : [10, 50, 100, 200], \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False],\n",
    "    }\n",
    "search = GridSearchCV(estimator=myclassifier,\n",
    "                     param_grid=grid,\n",
    "                     scoring=f1_scorer,\n",
    "                     cv=5)\n",
    "search.fit(X_train, y_train)\n",
    "print(f'Using these hyperparameters {search.best_params_}, we get the best performance:')\n",
    "print(classification_report(y_test, search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "snippet:gridsearch2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  8.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using these hyperparameters {'C': 100, 'degree': 3, 'kernel': 'poly'}, we get the best performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-user       0.58      0.04      0.08       161\n",
      "        user       0.62      0.98      0.76       252\n",
      "\n",
      "    accuracy                           0.62       413\n",
      "   macro avg       0.60      0.51      0.42       413\n",
      "weighted avg       0.60      0.62      0.49       413\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myclassifier = SVC(gamma='scale')\n",
    "\n",
    "grid = {\n",
    "    'C' : [100, 1e4], \n",
    "    'kernel': ['linear','rbf', 'poly'],\n",
    "    'degree': [3,4]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(estimator=myclassifier,\n",
    "                      param_grid=grid,\n",
    "                      scoring=f1_scorer,\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,  # use all cpus\n",
    "                      verbose=10)\n",
    "search.fit(X_train_scaled, y_train)\n",
    "print(f'Using these hyperparameters {search.best_params_}, we get the best performance:')\n",
    "print(classification_report(y_test, search.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
