\chapter{Statistical Modeling and Supervised Machine Learning}
\label{chap:introsml}

\begin{abstract}{Abstract} This chapter introduces the reader to the world of supervised machine learning. It starts by outlining how classical statistical techniques such as regression models can be used for prediction. It then provides an overview of frequently-used techniques from Na\"ive Bayes classifiers to neural networks.
\end{abstract}

\keywords{supervised machine learning}


\begin{objectives}
\item Understand the principles of supervised machine learning
\item Be able to run a predictive model
\item Be able to evaluate the performance of a predictive model
\end{objectives}

\newpage
\begin{feature}

 %TODO FIX
In this chapter, we use the Python package \pkg{statsmodels} for classical statistical modeling, before we move on to use a dedicated machine learning package, \pkg{scikit-learn}. In R, we use base R for statistical modeling, \pkg{rsample} for splitting our dataset, and \pkg{caret} for machine learning. Caret, however, requires additional packages for the actual machine learning models. We will use \pkg{naivebayes}, \pkg{LiblineaR}, and \pkg{randomforest}. You can install them as follows (see \refsec{installing} for more details):

\doublecodex{chapter09/chapter09install}

\noindent After installing, you need to import (activate) the packages every session:

\doublecodex{chapter09/chapter09library}

Note that in Python, we could also simply write \ttt{import sklearn} once instad of all the \ttt{from sklearn import ...} lines. But our approach saves a lot of typing later on, as we can simply write (\ttt{classification\_report}) instead of \ttt{sklearn.metrics.classification\_report}, for instance.
\end{feature}





In this chapter, we introduce the basic concepts and ideas behind
machine learning.  We will outline how machine learning relates to
traditional statistical approaches that you already might now (and as
you will see, there is a lot of overlap), present different types of
models, and discuss how to validate them.
Later in this book (\refsec{supervised}), we will 
specifically apply the knowledge you gained from this chapter to the
analysis of textual data, arguably one of the most interesting tasks
in the computational analysis of communication.

In this chapter, we focus on \emph{supervised} machine learning (SML) 
-- a form of machine learning, where we aim to predict a variable
that, for at least a part of our data, is known. SML is usually applied to \textit{classification} and \textit{regression}  problems. To illustrate the
idea, imagine that you are interested in predicting the gender based
on Twitter biographies. You determine the gender for some of the
biographies yourself and hand these examples over to the computer. The
computer ``learns'' this \textit{classification} from your examples, and can then be used to predict the gender for other Twitter biographies for which you do not
know the gender.

In unsupervised machine learning (UML), in contrast, you do not have such
examples. Therefore, UML is usually applied to \textit{clustering} and \textit{associations} problems. We have discussed some of such techniques in \refsec{clustering}, in particular cluster analysis and
principal component analysis (PCA).
Later, in \refsec{unsupervised}, we will discuss topic modeling, an unsupervised method to extract so-called topics from textual data.



Even though both approaches can be combined (for instance, one could
first reduce the amount of data using PCA or SVD, and then predict some
outcome), they can be seen as fundamentally different, also from a
theoretical and conceptual point of view.  Unsupervised machine
learning is a bottom-up approach and corresponds to an inductive
reasoning: you do not have a hypothesis of, for instance, which topics
are present in a corpus of text; you rather let the topics emerge from
the data.  Supervised machine learning, in contrast, is a top-down
approach and can be seen as more deductive: you define a priori which
topics to predict.


\input{chapter09/modelingprediction}
\input{chapter09/principles}
\input{chapter09/nbtodnn}
\input{chapter09/deeplearning}
\input{chapter09/validation}
