\section{Statistical modeling and prediction}
\label{sec:prediction}
Machine learning, many people joke, is nothing else than a fancy name
for statistics.  And, in fact, there is some truth to this: If you say
``logistic regression,'' this will sound familiar to both
statisticians and machine learning practitioners.  Hence, it does not
make much sense to distinguish between statistics on the one hand and
machine learning on the other hand.

Still, there are some differences between traditional statistical
approaches that you may have learned about in your statistics classes
and the machine learning approach, even if they use some of the same
mathematical tools. One may say that  the focus is a different
one, and the objective we want to achieve may differ.

Let us illustrate this with an example.
\texttt{mediause.csv}\footnote{You can download the file from
  \url{http://cssbook.nl/d/mediause.csv}} contains a few columns from
survey data on how many days per week respondents turn to different
media types (\emph{radio}, \emph{newspaper}, \emph{tv} and \emph{internet}) in order to follow the news\footnote{For a detailed
  description of the dataset, see \citet{Trilling2013phd}.}. It also
contains their \emph{age} (in years), their \emph{gender} (coded as female = 0, male = 1), and their \emph{education} (on a 5-point scale).

A straightforward question to ask is how far the
sociodemographic characteristics of the respondents explain their
media use.  Social scientists would typically approach this question
by running a regression analysis.  Such an analysis tells us how some
independent variables $x_1, x_2 \ldots x_n$ can explain $y$.  In an
ordinary least square regression (OLS), we would estimate $y=\beta_0 +
\beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n$.

In a typical social-science paper, we would then interpret the coefficients
that we estimated, and say something like: When $x_1$ increases by one unit,
$y$ increases by $\beta_1$.
We sometimes call this ``the effect of $x_1$ on $y$ (even though, of course,
it depends on the study design weather the relationship can really be interpreted
as a causal effect).
Additionally, we might look at the explained variance $R^2$, to assess how good the model fits our data. In \refex{ols} we use this regression approach to model the relationship of \emph{age} and \emph{gender} over the number of days per week a person reads a \emph{newspaper}. We fit the linear model using the \pkg{stats} function \fn{lm} in R and the \pkg{statsmodels} (module formula.api) function \fn{ols} in Python.

\pyrex[output=py, caption=Obtaining a model through estimating an OLS regression]{chapter09/ols}

Most traditional social-scientific analyses stop after reporting and
interpreting the coefficients of \emph{age} ($\beta = 0.0676$) and \emph{gender} ($\beta = -0.0896$), as well as the total explained variance (19\%) of such a model for our dependent variable \emph{newspaper}.

But we can go a step further. Given that we have already estimated our
regression equation, why not use it to do some \textit{prediction}?

We have just estimated that

$\textrm{newspaperreading} = -0.0896 + 0.0676 \cdot \textrm{age} + 0.1767 \cdot \textrm{gender}$

By just filling in the values for a 20 year old man, or a 40 year old
woman, we can easily calculate the expected number of days such a
person reads the newspaper per week, \emph{even if no such person
  exists in the original dataset}.

We learn that

$\hat{y}_{man20} = -0.0896 + 0.0676 \cdot 20 + 1 \cdot 0.1767 = 1.4391$

$\hat{y}_{woman40} = -0.0896 + 0.0676 \cdot 40 + 0 \cdot 0.1767 = 2.6144$

This was easy to do by hand, but of course, we could do this automatically for a large and essentially unlimited number of cases.
This could be as simple as shown in \refex{olspredict}.

\pyrex[output=py, caption=Using the OLS model we estimated before to predict the dependent variable for new data where the dependent variable is unknown.]{chapter09/olspredict}

In doing so, we shift our attention from the interpretation of coefficients to the prediction of the dependent variable for new, unknown cases. We do not
care about the actual values of the coefficents, we just need them for our prediction.
In fact, in many machine learning models, we will have so many of them that
we do not even bother to report them.

As you see, this implies that we proceed in two steps: First, we use some data
to estimate our model. Second, we use that model to make predictions.

We used an OLS regression for our first example, because it is very
straightforward to interpret, and most of our readers will be familiar
with it.  However, a model can take the form of \emph{any} function,
as long as it takes some characteristics (or ``features'') of the
cases (in this case, people) as input and returns a prediction.

Using such a simple OLS regression approach for prediction, as we did in our example, can come with a couple of problems, though. One problem is that in some cases, such predictions can be unlogical. For instance, even though we know that the output should be something between 0 and 7 (as that is the number of days in a week), our model will happily predict that once a man reaches the age of 105 (rare, but not impossible), he will read a newspaper on 7.185 out of 7 days. Similarly, a one year old girl will even have a negative amount of newspaper reading. A second problem relates to the models' inherent assumptions. For instance, in our example it is quite an assumption to make that the relationships between these variables are linear â€“ we will therefore discuss multiple models that do not make such assumptions later in this chapter. And, finally, in many cases, we are actually not interested in getting an accurate prediction of a continuous number (a \textit{regression} task), but rather in predicting a category. We may want to predict whether a tweet goes viral or not, whether a user comment is likely to contain offensive language or not, whether an article is more likely to be about politics, sports, economy, or lifestyle. In machine learning terms, these tasks are known as \textit{classification}.

In the next section, we will outline key terms and concepts in machine
learning. After that, we will discuss specific models that you
can use for different use applications.
