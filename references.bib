@article{Codd1970,
author = {Codd, Edgar F.},
title = {A Relational Model of Data for Large Shared Data Banks},
year = {1970},
issue_date = {June 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {6},
issn = {0001-0782},
doi = {10.1145/362384.362685},
journal = {Communications of the ACM},
pages = {377–387},
numpages = {11},
keywords = {redundancy, networks of data, data organization, predicate calculus, data integrity, retrieval language, relations, data structure, security, composition, hierarchies of data, derivability, data bank, join, consistency, data base}
}

  



@book{Kirk2016,
author = {Andy Kirk},
title = {Data visualisation: A handbook for data driven design},
publisher = {SAGE},
address = {London, UK},
year = 2016
}


@book{Bryman2012,
author = {Alan Bryman},
title = {Social research methods},
edition = {4th edition},
publisher = {Oxford University Press},
address= {New York, NY}
}


@Book{crawley2012r,	
author = {Crawley, Michael J},
title = {The R book},
publisher = {Wiley},
year = {2012},
edition = {2nd Edition},
}

@book{riffe2019analyzing,
author = {Daniel Riffe and Stephen Lacy and Frederick Fico and Brendan Watson},
title = {Analyzing Media Messages. {Using} Quantitative Content Analysis in Research},
edition = {4th edition},
year = {2019},
address = {New York, NY},
publisher = {Routledge}
}

@Book{field2012discovering,
author = {Field, Andy and Miles, Jeremy and Field, Zo{\"e}},
title = {{Discovering statistics using R}},
publisher = {Sage},
year = {2012}
}


@Book{lutz2013learning,
author = {Lutz, Mark},
title = {Learning {Python}: Powerful object-oriented programming},
publisher = {O'Reilly},
year = {2013}
}

@Book{vanderplas2016python,
author = {VanderPlas, Jake},
title = {Python data science handbook: essential tools for working with data},
publisher = {O'Reilly},
year = {2016},
}

@phdthesis{Trilling2013phd,
author = {Trilling, Damian},
school = {University of Amsterdam},
title = {{Following the news: Patterns of online and offline news consumption}},
type = {{PhD} Theses},
url = {https://hdl.handle.net/11245/1.394551},
year = {2013}
}

@article{Burscher2014,
author = {Burscher, Bj{\"{o}}rn and Odijk, Daan and Vliegenthart, Rens and de Rijke, Maarten and de Vreese, Claes H.},
doi = {10.1080/19312458.2014.937527},
file = {:home/damian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burscher et al. - 2014 - Teaching the computer to code frames in news Comparing two supervised machine learning approaches to frame anal.pdf:pdf},
issn = {1931-2458},
journal = {Communication Methods and Measures},
mendeley-groups = {papers/damianpetro},
number = {3},
pages = {190--206},
title = {{Teaching the computer to code frames in news: Comparing two supervised machine learning approaches to frame analysis}},
volume = {8},
year = {2014}
}

@article{vermeer2019seeing,
author = {Vermeer, Susan A. M. and Araujo, Theo and Bernritter, Stefan F. and van Noort, Guda},
doi = {10.1016/j.ijresmar.2019.01.010},
issn = {01678116},
journal = {International Journal of Research in Marketing},
keywords = {Automated content analysis,Digital marketing strategies,Machine learning,Sentiment analysis,Social media,Webcare,eWOM},
number = {3},
pages = {492--508},
publisher = {Elsevier B.V.},
title = {{Seeing the wood for the trees: How machine learning can help firms in identifying relevant electronic word-of-mouth in social media}},
volume = {36},
year = {2019}
}

@misc{Vermeer2018,
author = "Susan A. M. Vermeer",
title = "{A supervised machine learning method to classify Dutch-language news items}",
year = "2018",
month = "11",
url = "https://figshare.com/articles/A_supervised_machine_learning_method_to_classify_Dutch-language_news_items/7314896",
doi = "10.6084/m9.figshare.7314896.v1"
}

@book{tukey1977exploratory,
  title={Exploratory data analysis},
  author={Tukey, John W},
  volume={2},
  year={1977},
  publisher={Reading, Mass.}
}

@book{cairo2019charts,
  title={How charts lie},
  author={Cairo, Alberto},
  year={2019},
  publisher={WW Norton \& Company}
}

@article{kahle2013ggmap,
  title={ggmap: Spatial Visualization with ggplot2},
  author={Kahle, David and Wickham, Hadley},
  journal={The R journal},
  volume={5},
  number={1},
  pages={144--161},
  year={2013}
}

@book{tufte2006beautiful,
  title={Beautiful evidence},
  author={Tufte, Edward R},
  volume={1},
  year={2006},
  publisher={Graphics Press Cheshire, CT}
}

@article{Scharkow2011,
author = {Scharkow, Michael},
doi = {10.1007/s11135-011-9545-7},
file = {:home/damian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scharkow - 2011 - Thematic content analysis using supervised machine learning An empirical evaluation using German online news.pdf:pdf},
issn = {0033-5177},
journal = {Quality {\&} Quantity},
keywords = {bayesian classifier,content analysis,machine learning,online news},
month = {jul},
number = {2},
pages = {761--773},
title = {{Thematic content analysis using supervised machine learning: An empirical evaluation using German online news}},
url = {http://link.springer.com/10.1007/s11135-011-9545-7},
volume = {47},
year = {2011}
}


@article{Haselmayer2016,
abstract = {? 2016 The Author(s)Sentiment is important in studies of news values, public opinion, negative campaigning or political polarization and an explosive expansion of digital textual data and fast progress in automated text analysis provide vast opportunities for innovative social science research. Unfortunately, tools currently available for automated sentiment analysis are mostly restricted to English texts and require considerable contextual adaption to produce valid results. We present a procedure for collecting fine-grained sentiment scores through crowdcoding to build a negative sentiment dictionary in a language and for a domain of choice. The dictionary enables the analysis of large text corpora that resource-intensive hand-coding struggles to cope with. We calculate the tonality of sentences from dictionary words and we validate these estimates with results from manual coding. The results show that the crowdbased dictionary provides efficient and valid measurement of sentiment. Empirical examples illustrate its use by analyzing the tonality of party statements and media reports.},
author = {Haselmayer, Martin and Jenny, Marcelo},
doi = {10.1007/s11135-016-0412-4},
file = {:home/damian/SURFdrive/literatuur-mendeley/Haselmayer, Jenny{\_}2016.pdf:pdf},
issn = {15737845},
journal = {Quality and Quantity},
keywords = {Crowdcoding,Media negativity,Negative campaigning,Political communication,Sentiment analysis},
pages = {1--24},
publisher = {Springer Netherlands},
title = {{Sentiment analysis of political communication: combining a dictionary approach with crowdcoding}},
year = {2016}
}


@article{Gonzalez-Bailon2015,
abstract = {This study offers a systematic comparison of automated content analysis tools. The ability of different lexicons to correctly identify affective tone (e.g., positive vs. negative) is assessed in different social media environments. Our comparisons examine the reliability and validity of publicly available, off-the-shelf classifiers. We use datasets from a range of online sources that vary in the diversity and formality of the language used, and we apply different classifiers to extract information about the affective tone in these datasets. We first measure agreement (reliability test) and then compare their classifications with the benchmark of human coding (validity test). Our analyses show that validity and reliability vary with the formality and diversity of the text; we also show that ready-to-use methods leave much space for improvement when analyzing domain-specific content and that a machine-learning approach offers more accurate predictions across communication domains.},
author = {Gonzalez-Bailon, S. and Paltoglou, G.},
doi = {10.1177/0002716215569192},
file = {:home/damian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonzalez-Bailon, Paltoglou - 2015 - Signals of Public Opinion in Online Communication A Comparison of Methods and Data Sources.pdf:pdf},
issn = {0002-7162},
journal = {The ANNALS of the American Academy of Political and Social Science},
keywords = {analysis,content analysis,diversity,information,language formality,lexicon-based methods,machine,sentiment,text mining},
number = {1},
pages = {95--107},
title = {{Signals of Public Opinion in Online Communication: A Comparison of Methods and Data Sources}},
url = {http://ann.sagepub.com/content/659/1/95.abstract?rss=1},
volume = {659},
year = {2015}
}


@inproceedings{Hutto2014,
	title={Vader: A parsimonious rule-based model for sentiment analysis of social media text},
	author={Hutto, Clayton J and Gilbert, Eric},
	booktitle={Eighth International AAAI Conference on Weblogs and Social Media},
	year={2014}
}



@article{Thelwall2012,
	Author = {Thelwall, Mike and Buckley, Kevan and Paltoglou, Georgios},
	Date-Added = {2015-03-16 13:31:47 +0000},
	Date-Modified = {2015-03-16 13:32:09 +0000},
	Doi = {10.1002/asi.21662},
	Issn = {1532-2890},
	Journal = {Journal of the American Society for Information Science and Technology},
	Number = {1},
	Pages = {163--173},
	Title = {Sentiment strength detection for the social web},
	Volume = {63},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/asi.21662}}

@article{DeSmedt2012,
author = {{De Smedt}, Tom and Daelemans, W and Smedt, Tom De},
file = {:home/damian/SURFdrive/literatuur-mendeley//De Smedt, Daelemans, Smedt{\_}2012.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {data mining,graph networks,machine learning,natural language processing,python},
mendeley-groups = {papers/damianpetro},
pages = {2063--2067},
title = {{Pattern for Python}},
url = {http://dl.acm.org/citation.cfm?id=2343710},
volume = {13},
year = {2012}
}


@InProceedings{aclimdb,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}


@book{kelleher2015fundamentals,
  title={Fundamentals of machine learning for predictive data analytics: algorithms, worked examples, and case studies},
  author={Kelleher, John D and Mac Namee, Brian and D'arcy, Aoife},
  year={2015},
  publisher={MIT press}
}

@book{geron2019hands,
  title={Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems},
  author={G{\'e}ron, Aur{\'e}lien},
  year={2019},
  publisher={O'Reilly Media}
}

@article{welbers2017text,
  title={Text analysis in R},
  author={Welbers, Kasper and Van Atteveldt, Wouter and Benoit, Kenneth},
  journal={Communication Methods and Measures},
  volume={11},
  number={4},
  pages={245--265},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{Reagan2017,
abstract = {The emergence and global adoption of social media has rendered possible the real-time estimation of population-scale sentiment, an extraordinary capacity which has profound implications for our understanding of human behavior. Given the growing assortment of sentiment-measuring instruments, it is imperative to understand which aspects of sentiment dictionaries contribute to both their classification accuracy and their ability to provide richer understanding of texts. Here, we perform detailed, quantitative tests and qualitative assessments of 6 dictionary-based methods applied to 4 different corpora, and briefly examine a further 20 methods. We show that while inappropriate for sentences, dictionary-based methods are generally robust in their classification accuracy for longer texts. Most importantly they can aid understanding of texts with reliable and meaningful word shift graphs if (1) the dictionary covers a sufficiently large portion of a given text's lexicon when weighted by word usage frequency; and (2) words are scored on a continuous scale.},
author = {Reagan, Andrew J. and Danforth, Christopher M. and Tivnan, Brian and Williams, Jake Ryland and Dodds, Peter Sheridan},
doi = {10.1140/epjds/s13688-017-0121-9},
issn = {21931127},
journal = {EPJ Data Science},
keywords = {data visualization,language,natural language processing,sentiment,sentiment analysis,sentiment dictionaries,text visualization},
number = {1},
title = {{Sentiment analysis methods for understanding large-scale texts: a case for using continuum-scored words and word shift graphs}},
volume = {6},
year = {2017}
}


@article{Boukes2019,
abstract = {This article scrutinizes the method of automated content analysis to measure the tone of news coverage. We compare a range of off-the-shelf sentiment analysis tools to manually coded economic news as well as examine the agreement between these dictionary approaches themselves. We assess the performance of five off-the-shelf sentiment analysis tools and two tailor-made dictionary-based approaches. The analyses result in five conclusions. First, there is little overlap between the off-the-shelf tools; causing wide divergence in terms of tone measurement. Second, there is no stronger overlap with manual coding for short texts (i.e., headlines) than for long texts (i.e., full articles). Third, an approach that combines individual dictionaries achieves a comparably good performance. Fourth, precision may increase to acceptable levels at higher levels of granularity. Fifth, performance of dictionary approaches depends more on the number of relevant keywords in the dictionary than on the number of valenced words as such; a small tailor-made lexicon was not inferior to large established dictionaries. Altogether, we conclude that off-the-shelf sentiment analysis tools are mostly unreliable and unsuitable for research purposes–at least in the context of Dutch economic news–and manual validation for the specific language, domain, and genre of the research project at hand is always warranted.},
author = {Boukes, Mark and van de Velde, Bob and Araujo, Theo and Vliegenthart, Rens},
doi = {10.1080/19312458.2019.1671966},
file = {:home/damian/SURFdrive/literatuur-mendeley/Boukes et al.{\_}2019.pdf:pdf},
issn = {19312466},
journal = {Communication Methods and Measures},
number = {00},
pages = {1--22},
publisher = {Routledge},
title = {{What's the Tone? Easy Doesn't Do It: Analyzing Performance and Agreement Between Off-the-Shelf Sentiment Analysis Tools}},
volume = {00},
year = {2019}
}

@incollection{Scharkow2017,
address = {Hoboken, NJ},
author = {Scharkow, Michael},
booktitle = {The International Encyclopedia of Communication Research Methods},
doi = {10.1002/9781118901731.iecrm0043},
editor = {Matthes, J{\"{o}}rg and Davis, Christine S. and Potter, Robert F.},
file = {:home/damian/SURFdrive/literatuur-mendeley/Scharkow{\_}2017.pdf:pdf},
isbn = {9781118901731},
pages = {1--14},
publisher = {Wiley},
title = {{Content Analysis, Automatic}},
year = {2017}
}


@incollection{Trilling2017b,
address = {Hoboken, NJ, USA},
author = {Trilling, Damian},
booktitle = {The International Encyclopedia of Communication Research Methods},
doi = {10.1002/9781118901731.iecrm0014},
file = {:home/damian/SURFdrive/literatuur-mendeley/Trilling{\_}2017(2).pdf:pdf},
isbn = {9781118901731},
keywords = {communication research methods,computer science,content analysis,digital,media,new media,quantitative methods,social networks},
month = {nov},
pages = {1--20},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Big Data, Analysis of}},
year = {2017}
}


@article{Wettstein2020,
abstract = {Abstract Linkage analyses use data from panel surveys and content analyses to assess media effects under field conditions and are able to close the gap between experimental and survey-based media effects research. Results from current studies and simulations indicate, however, that these studies systematically under-estimate real media effects as they aggregate measurement errors and reduce the complexity of media content. In response to these issues, we propose a new method for linkage analysis which applies agent-based simulations to directly assess short-term media effects using empirical data as guideposts. Results from an example study modeling opinion dynamics in the run-up of a Swiss referendum show that this method outperforms traditional regression-based linkage analyses in detail and explanatory power. In spite of the time-consuming modeling and computation process, this approach is a promising tool to study individual media effects under field conditions.},
author = {Wettstein, Martin},
doi = {10.5117/CCR2020.1.001.WETT},
file = {:home/damian/SURFdrive/literatuur-mendeley/Wettstein{\_}2020.pdf:pdf},
issn = {2665-9085},
journal = {Computational Communication Research},
keywords = {agent-based modeling,linkage analysis,simulation},
month = {feb},
number = {1},
pages = {1--33},
title = {{Simulating hidden dynamics : Introducing Agent-Based Models as a tool for linkage analysis}},
volume = {2},
year = {2020}
}


@article{Waldherr2014,
author = {Waldherr, Annie},
doi = {10.1111/jcom.12117},
isbn = {1460-2466},
issn = {14602466},
journal = {Journal of Communication},
number = {5},
pages = {852--873},
title = {{Emergence of News Waves: A Social Simulation Approach}},
volume = {64},
year = {2014}
}



@book{cioffi-revilla2014,
author = {Claudio Cioffi-Revilla},
title = {Introduction to Computational Social Science: Principles and Applications},
address = {London, UK},
publisher = {Springer},
year = {2014}
}

@article{Boumans2016,
abstract = {{\textcopyright} 2015 Taylor {\&} Francis. When analyzing digital journalism content, journalism scholars are confronted with a number of substantial differences compared to traditional journalistic content. The sheer amount of data and the unique features of digital content call for the application of valuable new techniques. Various other scholarly fields are already applying computational methods to study digital journalism data. Often, their research interests are closely related to those of journalism scholars. Despite the advantages that computational methods have over traditional content analysis methods, they are not commonplace in digital journalism studies. To increase awareness of what computational methods have to offer, we take stock of the toolkit and show the ways in which computational methods can aid journalism studies. Distinguishing between dictionary-based approaches, supervised machine learning, and unsupervised machine learning, we present a systematic inventory of recent applications both inside as well as outside journalism studies. We conclude with suggestions for how the application of new techniques can be encouraged.},
author = {Boumans, Jelle W. and Trilling, Damian},
doi = {10.1080/21670811.2015.1096598},
file = {:home/damian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boumans, Trilling - 2016 - Taking stock of the toolkit An overview of relevant automated content analysis approaches and techniques for.pdf:pdf},
issn = {2167-0811},
journal = {Digital Journalism},
keywords = {Automated content analysis,Computational social science,Digital data,Journalism studies,Review},
number = {1},
pages = {8--23},
title = {{Taking stock of the toolkit: An overview of relevant autmated content analysis approaches and techniques for digital journalism scholars}},
volume = {4},
year = {2016}
}


@book{Gonzalez-Bailon2017,
address = {Cambridge, MA},
author = {Gonz{\'{a}}lez-Bail{\'{o}}n, Sandra},
isbn = {9780262037075},
publisher = {MIT},
title = {{Decoding the social world: Data science and the unintended consequences of communication}},
year = {2017}
}


@book{Salganik2019,
  title={Bit by bit: Social research in the digital age},
  author={Salganik, Matthew},
  year={2019},
  publisher={Princeton University Press}
}


@article{Kitchin2014,
abstract = {This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory', the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology. Keywords},
author = {Kitchin, Rob},
doi = {10.1177/2053951714528481},
file = {:home/damian/SURFdrive/literatuur-mendeley/Kitchin{\_}2014.pdf:pdf},
issn = {2053-9517},
journal = {Big Data {\&} Society},
keywords = {big data,computational,data analytics,data-driven science,digital humanities,end of theory,epistemology,paradigms},
mendeley-groups = {papers/bigdatahoofdstuk},
number = {1},
pages = {1--12},
title = {{Big Data, new epistemologies and paradigm shifts}},
volume = {1},
year = {2014}
}


@book{Kitchin2014data,
  title={The data revolution: Big data, open data, data infrastructures and their consequences},
  author={Kitchin, Rob},
  year={2014},
  publisher={Sage}
}

@article{moreno1934shall,
  title={Who shall survive?: A new approach to the problem of human interrelations.},
  author={Moreno, Jacob Levy},
  year={1934},
  publisher={Nervous and mental disease publishing co}
}

@book{christakis2009connected,
  title={Connected: The surprising power of our social networks and how they shape our lives},
  author={Christakis, Nicholas A and Fowler, James H},
  year={2009},
  publisher={Little, Brown Spark}
}

@book{watts2004six,
  title={Six degrees: The science of a connected age},
  author={Watts, Duncan J},
  year={2004},
  publisher={WW Norton \& Company}
}

@article{vosoughi2018spread,
  title={The spread of true and false news online},
  author={Vosoughi, Soroush and Roy, Deb and Aral, Sinan},
  journal={Science},
  volume={359},
  number={6380},
  pages={1146--1151},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{Breiman2001,
abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated bya given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical communityhas been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theoryand practice, has developed rapidlyin fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move awayfrom exclusive dependence on data models and adopt a more diverse set of tools. {\textcopyright} 2001 Institute of Mathematical Statistics.},
author = {Breiman, Leo},
doi = {10.1214/ss/1009213726},
file = {:home/damian/SURFdrive/literatuur-mendeley/Breiman{\_}2001.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
number = {3},
pages = {199--215},
title = {{Statistical modeling: The two cultures}},
volume = {16},
year = {2001}
}



@article{Grimmer2013,
author = {Grimmer, J. and Stewart, B. M.},
doi = {10.1093/pan/mps028},
issn = {1047-1987},
journal = {Political Analysis},
number = {3},
pages = {267--297},
title = {Text as Data: {The} Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts},
volume = {21},
year = {2013}
}


@article{Rieder2017,
abstract = {This paper outlines the notion of ‘algorithmic technique' as a middle ground between concrete, implemented algorithms and the broader study and theorization of software. Algorithmic techniques specify principles and methods for doing things in the medium of software and they thus constitute units of knowledge and expertise in the domain of software making. I suggest that algorithmic techniques are a suitable object of study for the humanities and social science since they capture the central technical principles behind actual software, but can generally be described in accessible language. To make my case, I focus on the field of information ordering and, first, discuss the wider historical trajectory of formal or ‘mechanical' reasoning applied to matters of commerce and government before, second, moving to the investigation of a particular algorithmic technique, the Bayes classifier. This technique is explicated through a reading of the original work of M. E. Maron in the early 1960 and presented as a means to subject empirical, ‘datafied' reality to an interested reading that confers meaning to each variable in relation to an operational goal. After a discussion of the Bayes classifier in relation to the question of power, the paper concludes by coming back to its initial motive and argues for increased attention to algorithmic techniques in the study of software.},
author = {Rieder, Bernhard},
doi = {10.1080/1369118X.2016.1181195},
issn = {14684462},
journal = {Information Communication and Society},
keywords = {Algorithmic techniques,Bayes classifier,power relations,statistics},
number = {1},
pages = {100--117},
publisher = {Taylor {\&} Francis},
title = {Scrutinizing an algorithmic technique: the {Bayes} classifier as interested reading of reality},
volume = {20},
year = {2017}
}


@incollection{Gunther2018,
  title     = {But how do we store it? {D}ata architecture in the social-scientific research process},
  author    = "Elisabeth G{\"u}nther and Damian Trilling and {van de Velde}, Bob",
  year      = "2018",
  language  = "English",
  pages     = "161--187",
  editor    = "C.M. Stuetzer and M. Welker and M. Egger",
  booktitle = {Computational social science in the age of {Big Data}. {C}oncepts, methodologies, tools, and applications},
  publisher = "Herbert von Halem",
}


@article{Trilling2018b,
  title     = "Scaling up content analysis",
  author    = "Damian Trilling and Jeroen G.F. Jonkman",
  year      = "2018",
  doi       = "10.1080/19312458.2018.1447655",
  language  = "English",
  volume    = "12",
  pages     = "158--174",
  journal   = "Communication Methods and Measures",
  publisher = "Taylor & Francis",
  number    = "2-3"
}


@article{VanAtteveldt2019,
author = {{Van Atteveldt}, Wouter and Strycharz, Joanna and Trilling, Damian and Welbers, Kasper},
journal = {International Journal of Communication},
pages = {3935--3954},
title = {{Toward Open Computational Communication Science : A Practical Road Map for Reusable Data and Code University of Amsterdam , the Netherlands}},
volume = {13},
year = {2019}
}

@article{Puschmann2019,
author = {Puschmann, Cornelius},
doi = {10.1080/1369118X.2019.1646300},
file = {:home/damian/SURFdrive/literatuur-mendeley/Puschmann{\_}2019.pdf:pdf},
issn = {1369-118X},
journal = {Information, Communication {\&} Society},
keywords = {APIs,Facebook,Social Science One,Social media},
month = {sep},
number = {11},
pages = {1582--1589},
publisher = {Taylor {\&} Francis},
title = {{An end to the wild west of social media research: a response to Axel Bruns}},
volume = {22},
year = {2019}
}

@article{Freelon2018,
author = {Freelon, Deen},
doi = {10.1080/10584609.2018.1477506},
file = {:home/damian/SURFdrive/literatuur-mendeley/Freelon{\_}2018.pdf:pdf},
isbn = {0805837744},
issn = {1058-4609},
journal = {Political Communication},
keywords = {api,computational,facebook,social media,twitter},
number = {4},
pages = {665--668},
publisher = {Routledge},
title = {{Computational Research in the Post-API Age}},
volume = {35},
year = {2018}
}

@inproceedings{eppstein2010listing,
  title={Listing all maximal cliques in sparse graphs in near-optimal time},
  author={Eppstein, David and L{\"o}ffler, Maarten and Strash, Darren},
  booktitle={International Symposium on Algorithms and Computation},
  pages={403--414},
  year={2010},
  organization={Springer}
}

@article{cazals2008note,
  title={A note on the problem of reporting maximal cliques},
  author={Cazals, Fr{\'e}d{\'e}ric and Karande, Chinmay},
  journal={Theoretical Computer Science},
  volume={407},
  number={1-3},
  pages={564--568},
  year={2008},
  publisher={Elsevier}
}

@article{newman2004finding,
  title={Finding and evaluating community structure in networks},
  author={Newman, Mark EJ and Girvan, Michelle},
  journal={Physical review E},
  volume={69},
  number={2},
  pages={026113},
  year={2004},
  publisher={APS}
}

@article{blondel2008fast,
  title={Fast unfolding of communities in large networks},
  author={Blondel, Vincent D and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne},
  journal={Journal of statistical mechanics: theory and experiment},
  volume={2008},
  number={10},
  pages={P10008},
  year={2008},
  publisher={IOP Publishing}
}

@article{raghavan2007near,
  title={Near linear time algorithm to detect community structures in large-scale networks},
  author={Raghavan, Usha Nandini and Albert, R{\'e}ka and Kumara, Soundar},
  journal={Physical review E},
  volume={76},
  number={3},
  pages={036106},
  year={2007},
  publisher={APS}
}

@article{clauset2004finding,
  title={Finding community structure in very large networks},
  author={Clauset, Aaron and Newman, Mark EJ and Moore, Cristopher},
  journal={Physical review E},
  volume={70},
  number={6},
  pages={066111},
  year={2004},
  publisher={APS}
}

